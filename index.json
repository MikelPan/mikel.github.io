[{"categories":["数据库"],"content":"Mysql基础命令02","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"一、Msql数据类型 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:1:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"1、整型 tinyint, 占 1字节 ,有符号： -128~127,无符号位 :0~255 smallint, 占 2字节 ,有符号： -32768~32767无符号位 :0~65535 mediumint 占 3字节 ,有符号： -8388608~8388607,无符号位:0~16777215: int, 占 4字节 ,有符号： -2147483648~2147483647,无符号位 无符号位 :0~4 284967295 bigint, bigint,bigint, 占 8字节 bool 等价于 tinyint ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:1:1","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"2、浮点型 float([m[,d]]) 占 4字节 ,1.17E-38~3.4E+3838~3.4E double([m[,d]]) 占 8字节 decimal([m[,d]]) 以字符串形式表示的浮点数 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:1:2","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"3、字符型 char([m]): :定长的字符 ,占用 m字节 varchar[(m)]: :变长的字符 ,占用 m+1m+1 字节，大于 255 个字符：占用 m+2m+2 tinytext,255 个字符 (2 的 8次方 ) text,65535 个字符 (2 的 16 次方 ) mediumtext,16777215字符 (2 的 24 次方 ) longtext (2的 32 次方 ) enum(value,value,…)占 1/2个字节 最多可以有 65535 个成员 个成员 set(value,value,…) 占 1/2/3/4/8个字节，最多可以 有 64个成员 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:1:3","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"二、Mysql数据运算 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"1、逻辑运算 and or not for example： 选择出 书籍价格 为（30,60,40，50）的记录 sql\u003e select bName,publishing,price from books where price=30 or price=40 or price=50 or price=60; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:1","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"2、in 运算符 in 运算符用于 WHERE 表达式，以列表的形式支持多个选择，语法如下 where colunmm in （value1，value2，…….） where colunmm not in (value1,value2,……….) 当in前面加上not时，表示与in相反，既不在结果中 sql\u003e select bName,publishing,price from books where price in （30，40，50，60）order by price asc； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:2","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"3、算术运算符 \u003e= | \u003c=| \u003c\u003e |= for example 找出价格小于70的记录 mysql\u003e select bName,price from books where price \u003c= 70; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:3","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"4、模糊查询 like ‘%…%’ 字段名 [not] like ‘%……%’ 通配符 任意多个字符 查询书中包含程序字样的记录 mysql\u003e select bName,price from books where bName like ‘%程序%’ ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:4","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"5、范围运算 [not] between …….and 查找价格不在30和60之间的书名和价格 mysql\u003e select bName,price from books where price not between 30 and 60 order by price desc; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:5","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"6、Mysql 子查询 select where条件中又出现select 查询类型为网络技术的图书 mysql\u003e select bName,bTypeId from books where bTypeId=(select bTypeId from category where bTypeName=‘网络技术’); ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:6","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"7、limit 限定显示的条目 LIMIT子句可以被用于强制 SELECT语句返回指定的记录数。 LIMIT 接受一个或两数字参。必 须是一个整数常量。如果给定两 个数，第一指定返 回记录行的偏移量，第二个参数返回记录行的最大数目。初始偏移量是 0( 而不是 1)。 语法 ： select * from limit m，n 其中 m是指记录开始的 index indexindex，从 0开始，表示第一条记录，n是指从第 m+1 条开始，取 n。 查询books表中第2条到六行的记录 mysql\u003eselect * from books limit 1,6; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:7","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"8、连接查询 以一个共同的字段，求两张表当中符合条件并集。 通过 共同字段把这两张表的共同字段把这两张表连 接起来。 常用的连接： 内连接：根据表中的共同字段进行匹配 外连接：现实某数据表的 全部记录和另外数据表中符合连接条件的记录。 外连接：左连接、右连接 内连接：for exmaple create table student（sit int(4) primary key auto_increment,name varchar(40)）; insert into student values(1,‘张三’），（2，‘李四’），（3，‘王五’），（4，‘mikel’）; create table teachers（sit int(4)，id int(4) primary key auto_increment,score varchar(40)）; insert into teachers values(1,1,‘1234’)，（1,2,‘2345’），（3,3,‘2467’），（4,4，‘2134’）； select s.* ,t.* from student as s,teachers as t where s.sid=t.sid; 左连接： select 语句 a表 left[outer] join b 表 on 连接条件 ，a表是主，都显示。 b表是从，主表内容全都有，主表多出来的字段，从表没有的就显示 null，从表多出主表的字段不显示。 select * from student as s left join teachers as t on s.sit=t.sit; 右连接：select 语句 a表 right[outer] join b 表 on 连接条件 ，b表是主，都显示。 a表是从，主表内容全都有，主表多出来的字段，从表没有的就显示 null，从表多出主表的字段不显示。 select * from student as sright join teachers as t on s.sit=t.sit; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:2:8","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"三、聚合函数 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"1、sam() 求和 select sum (id+score) as g from teachers; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:1","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"2、avg() 求平均值 select avg (id+score) as g from teachers; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:2","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"3、max() 最大值 select max (id) as g from teachers; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:3","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"4、min() 最小值 select min(id) as g from teachers; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:4","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"5、substr（string，start，len） 截取 select substr(soucr,1,2) as g from teachers; 从start开始，截取len长度，start从1开始 concat（str1,str2,str3………………….）字符串拼接，将多个字符串拼接在一起 select concat(id,score,sit) as g from teachers; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:5","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"6、count() 统计计数 记录字段数据条数 select count(id) as g from teachers; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:6","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"7、upper() 大写 select upper(name) as g from student; #将字段name中英文全部变为大写，但不改变原值 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:7","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"8、lower() 小写 **select lower(name) as g from student; ** #将字段name中英文全部变为小写，但不改变原值 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:3:8","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"四、索引 mysql中索引是以文件形式存放的，对表进行增删改，会同步到索引，索引和表保持一致，常用在where 后字段查询就加索引。 优点：加快查询速度，减少查询时间 缺点：索引占据一定磁盘空间，会影响insert，delete，update执行时间 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:4:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"1、索引类型 普通索引：最基本索引，不具备唯一性 唯一索引：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一 主键索引：记录值唯一，主键字段很少被改动，不能为空，不能修改，可用于一个字段或者多个字段 全文索引：检索文本信息的, 针对较大的数据，生成全文索引查询速度快，但也很浪费时间和空间 组合索引：一个索引包含多个列 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:4:1","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"2、创建索引 普通索引： # 创建普通索引 create table demo(id int(4),uName varchar(20),uPwd varchar(20),index (uPwd)); # 查看建表过程 show create table demo； demo | CREATE TABLE demo ( id int(4) DEFAULT NULL, uName varchar(20) DEFAULT NULL, uPwd varchar(20) DEFAULT NULL, KEY uPwd (uPwd) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | 唯一索引：字段值只允许出现一次，可以有空值 # 创建唯一索引 create table demo1（id int(4),uName varchar(20),uPwd varchar(20),unique index (uName)）; # 查看建表过程 show create table demo1; demo1 | CREATE TABLE demo1 ( id int(4) DEFAULT NULL, uName varchar(20) DEFAULT NULL, uPwd varchar(20) DEFAULT NULL, UNIQUE KEY uName (uName) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | 主键索引：字段记录值唯一，字段很少被修改，一般主键约束为auto_increment或者not null unique，不能为空，不能重复。 # 创建主键索引 create table demo2(id int(4) auto_increment primary key,uName varchar(20),uPwd varchar(20)); # 查看建表语句 demo2 | CREATE TABLE demo2 ( id int(4) NOT NULL AUTO_INCREMENT, uName varchar(20) DEFAULT NULL, uPwd varchar(20) DEFAULT NULL, PRIMARY KEY (id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | 全文索引：提高全文检索效率，解决模糊查询 # 创建全文索引 create table demo3(id int(4),uName varchar(20),uPwd varchar(20),fulltext(uName,uPwd)); # 查看建表语句 | demo3 | CREATE TABLE demo3 ( id int(4) DEFAULT NULL, uName varchar(20) DEFAULT NULL, uPwd varchar(20) DEFAULT NULL, FULLTEXT KEY uName (uName,uPwd) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 | ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:4:2","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"五、外键约束 外键约束：foreign key 表与表之间的一种约定关系，由于这种关系存在，让表与表之间的数据更加具有完整性，更加具有关联性。 1、创建外键约束 创建user主表 create table user1(id int(11)auto_increment primary key,name varchar(50),sex int(1)); 插入数据 insert into user1(name,sex)values(“mikel”,4),(“plyx”,6); 创建order外键表 create table order(order_id int(11)auto_increment primary key,u_id int(11),username varchar(50),monery int(11),foreign key(u_id) references user1(id) on delete cascade on update cascade )engine=innodb); 插入数据 INSERT INTO order (order_id,u_id,username,monery)values(1,1,‘mikel’,2345),(2,2,‘plyx’,3456) 在order表中插入一条u_id为6的记录 insert into orser (u_id)values(6); Cannot add or update a child row: a foreign key constraint fails (school.order, CONSTRAINT order_ibfk_1 FOREIGN KEY (u_id) REFERENCES user1 (id) ON DELETE CASCADE ON UPDATE CASCADE) user1中不存在id为6的记录，现在添加一条id为6的记录 insert into user1(id)values(6); 2、视图 是一张虚拟表，由 select select select语句指定的数据结构和数据，不生成真实文件 create view mikel as select * from school.books; select * from mikel; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:5:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"六、存储过程 存储过程用来封装mysql代码，相当于函数，一次编译，生成二进制文件，永久有效，提高效率。 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:6:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"1、定义存储过程 create procedure 过程名（参数1，参数2，………….） begin ​ sql语句 end ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:6:1","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"2、调用存储过程 call 过程名（参数1，参数2，……………….） example:定义一个存储过程查看books表中所有数据 ​ 1. 修改sql默认执行符号 ​ delimiter // create procedure seebooks(); begin ​ select * from sctudent.books; ​ end // call seebooks() // ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:6:2","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"3、存储过程参数传递 in 传入参数 int 赋值 IN输入参数：表示调用者向过程传入值（传入值可以是字面量或变量） OUT输出参数：表示过程向调用者传出值(可以返回多个值)（传出值只能是变量） INOUT输入输出参数：既表示调用者向过程传入值，又表示过程向调用者传出值（值只能是变量） create procedure seebook(in b int) begin select * from school.books where bId=b; end // call seebook(4) 16 out ————–传出参数 select into 在过程中赋值传给变量，并查看变量值 create procedure seebook2(out b varchar(100)) begin select bName into b from school.books where bId=4; end // 17 过程内的变量使用方法 声明变量名称，类型，declare 过程内的变量没有@ 赋值 set 变量名=（select 语句） create procedure seebook3() begin ​ declare str varchar(100);**** ​ set str=(select bName from school.books where bId=20); ​ select str; end// call seebook3() // 18 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:6:3","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"七、触发器 与数据表有关，当表出现（增，删，改，查）时，自动执行其特定的操作 语法：create trigger 触发器名称 触发器时机 触发器动作 on 表名 for each row 触发器名称：自定义 触发器时机：after/before 之后/之前 触发器动作：insert update delete 创建触发器： create trigger delstudent after delete on grade for each now delete from student where sid=‘4’; delete from grade where sid=4; mysql\u003e select sid from student where sid=4; Empty set 查看是否还有sid=4的值，可以发现已经被删除 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:7:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"八、事务 单个逻辑单元执行的一系列操作，通过将一组操作组成一个，执行的时要么全部成功，要么全部失败，使程序更可靠，简化错误恢复。 MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。事务用来管理 insert,update,delete 语句。 MYSQL 事务处理主要有两种方法： 1、用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 2、直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 创建事务 begin; update books set bName=“plyx” where bId=1； update books set bName=“plyx” where bId=2； commit// 查看记录，已经修改了 select * from books; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:8:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"九、mysql数据结构 主配置文件 my.cnf 数据目录：/var/lib/mysql 进程通信sock文件 ：/var/lib/mysql/mysql.sock 错误日志文件 [mysqld_safe] log-error=/var/log/mysqld.log 进程PID文件：pid-file=/var/run/mysqld/mysqld.pid 二进制文件：log-bin=mysql-bin.log ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:9:0","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"十.常见的存储引擎介绍 myisam : 特性： 1、不支持事务，不支持外键，宕机时会破坏表 2、使用较小的内存和磁盘空间，访问速度快 3、基于表的锁，表级锁 4、mysql 只缓存index索引， 数据由OS缓存 适用场景：日志系统，门户网站，低并发。 Innodb： 特性： 1、具有提交，回滚，崩溃恢复能力的事务安全存储引擎 2、支持自动增长列，支持外键约束 3、占用更多的磁盘空间以保留数据和索引 4、不支持全文索引 适用场景：需要事务应用，高并发，自动恢复，轻快基于主键操作 MEMORY： 特性： 1、Memory存储引擎使用存在于内存中的内容来创建表。 2、每个memory表只实际对应一个磁盘文件，格式是.frm。memory类型的表访问非常的快，因为它的数据是放在内存中的，并且默认使用HASH索引，但是一旦服务关闭，表中的数据就会丢失掉。 ​3、MEMORY存储引擎的表可以选择使用BTREE索引或者HASH索引。 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/:9:1","tags":["Mysql"],"title":"Mysql基础命令02","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A402/"},{"categories":["数据库"],"content":"Mysql基础命令01","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"一.Mysql简介 MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，目前属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件。 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:1:0","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"二.Mysql基本命令 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:0","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"I.库 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:1","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"1. 创建数据库 语法 ：create database 数据库名 创建数据库ab create database ab； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:2","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"2. 查看数据库 显示所有的数据库 show databases； 以行显示所有数据库 show databases \\G ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:3","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"3.删除数据库 语法:drop database 数据库名 删除数据库ab drop database ab； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:4","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"II.表 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:5","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"1. 创建表 语法:create table 表名 （字段名，类型，字段名，类型，字段名，类型）; create table book（idint（10），namechar（40），age int）; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:6","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"2.查看表结构 desclist； explain food.list; show columns from food .list; show columns from food. list like'%id'; #查看表的创建过程，指定存储引擎，字符集 show create table list； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:7","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"3.mysql存储引擎 mysql的存储引擎包括：MyISAM、InnoDB、BDB、MEMORY、MERGE、EXAMPLE、NDBCluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:8","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"4. 删除表 语法：drop table 表名 drop table list； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:9","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"5.修改表名 语法：alter table 表名 rename 新表名； alter table list rename lists； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:10","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"6. 修改表中的字段类型 语法：alter table 表名 modify 要修改的字段名 字段名的新字段类型 alter table lists modifyid char（40）； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:11","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"7.修改表中字段名称和类型 语法：altertable 表名 change 原字段名 新字段名 新字段类型 alter table lists change id ids int（40）； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:12","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"8.表中添加字段 1.表中添加字段 语法：alter table 表名 add 字段名 字段类型 alter table lists add sum int（50）； 2.表第一行添加字段 语法：alter table 表名 add 字段名 字段类型 first 第一行添加字段 alter table lists add sum int（50）first； 3.在字段后添加字段 语法：alter table 表名 add 字段名 字段类型 after su 字段su后添加字段 alter table lists add so char（30）after su; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:13","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"9.删除表中字段 语法：alter table 表名 drop 字段名 alter table lists drop so； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:14","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"III.记录 1.字段中插入记录 语法：insert into 表名 values（1,‘zhangshan’,2）; 后面记录指定为空 insert into lists values（1，2，‘shanshi’，null，null）； 插入多条记录中间用分号隔开 insert into lists valus （1，2，‘lisi’，null，null），（2，3，‘siji’，1，1）； 指定字段插入 insert into lists （su，ids）values（1，1）； 2.查询表中记录 语法：select * from 表名 表示所有记录 select * from lists； 查询ids中记录 select ids from lists； 查询ids，su中记录 select ids，su from lists； 查看指定数据库中表内容 select * from food.lists; ` 3.删除表中记录 语法：delete from表名 where 字段名=xx delete from lists where ids=2； 删除字段name记录为空的行 delete from lists where name is null； 4.更新记录 语法：update 表名 set 字段名1=xx where 字段名2=xx update lists set ids=1 where name=null； 所有都变成2 update lists set ids=2 同时更新多个字段用分号隔开 update lists set ids=3，name=‘lisi’ where su=1； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:2:15","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"三.SQL基本语句查询 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:0","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"1. 多字段查询 语法：select 字段1，字段2 from 表名 select ids，name from lists； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:1","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"2. 去重复查询 语法：select distinct 字段1，字段2 from 表名 select distinct ids，name from lists； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:2","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"3.使用and和or多条件查询 语法：select 字段1，字段2 from 表名 where 字段1\u003e3 and 字段2\u003c5 select ids,name from lists where ids\u003e3 and name \u003c5; select ids,name from lists where ids\u003e3 or name \u003c5; and与or同时存在时，先算and左右两边的，逻辑与先执行 select * from lists where ids=3 and(su=1 or name =5); ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:3","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"4.mysql区分大小写查询 语法：select * from 表名 where binary 字段1=‘xxx’ binary区分大小写 select *from lists where binary name=‘LK’ ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:4","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"5.排序查询 语法：select distinct 字段1，字段2 from 表名 orderby 字段名 默认是升序排列 select distinct ids，su from lists orderby ids； 降序排列 select distinct ids，su from lists orderby ids desc； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:5","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"6.查询引用别名 语法：select * from 旧表名 新表名 select * from lists s； 语法：select 旧字段名 as 新字段名 from 表名 指定字段别名 select ids as s from lists； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:6","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"7.like查询 语法：select 字段名1 字段名2 … from 表名 where 字段名1 like ‘%abc’ or 字段名2 like ‘%ABC’ select abc ABC from abc1 where abc like ‘%abc’ or ABC like ‘%ABC’ ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:3:7","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"四.常用select查询 打印当前的日期和时间 selectnow（）； 打印当前的日期 selectcurdate（）； 打印当前的时间 selectcurtime（） 打印当前数据库 selectdatabase（）； 打印数据库版本 selectversion（）； 打印当前用户 selectuser（）； ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:4:0","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"五.导入导出数据库 ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:5:0","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"1.导入数据库 方法一 创建数据库 ：mysql -e ‘create database book’ -uroot -p123456 导入数据库 ：mysql -uroot -p123456 book 方法二 创建数据库 ：mysql -e ‘create database book’ -uroot -p123456 导入数据库 ：source /root/book.sql ** // 数据库所在路径** ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:5:1","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"2.导出数据库 mysqldump -uroot -p123456 数据库名\u003e数据库文件名 mysqldump -uroot -p123456 book\u003ebook.sql 导出包含建库语句 mysqldump -uroot -p123456 -B book\u003ebook.sql 导出所有数据库 mysqldump -uroot -p123456 -A book\u003ebook.sql 导出数据库到文件 select * from lists outfile ‘/tmp/123.txt' ; ","date":"2021-02-15","objectID":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/:5:2","tags":["Mysql"],"title":"Mysql基础命令01","uri":"/mysql%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A401/"},{"categories":["数据库"],"content":"Mysql备份与恢复","date":"2021-02-15","objectID":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","tags":["Mysql"],"title":"Mysql备份与恢复","uri":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["数据库"],"content":"一、mysql冷备及恢复 1.1、冷备 # 停止mysql mysqladmin -uroot -proot123 shutdown # 拷贝数据文件 scp -r /data/mysql root@back ip:/root cp -r /data/mysql /本地新目录 1.2、恢复 将已经备份的数据目录替换到原有的目录, 重启mysql服务 ","date":"2021-02-15","objectID":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:0:1","tags":["Mysql"],"title":"Mysql备份与恢复","uri":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["数据库"],"content":"二、mysql热备及恢复 2.1、mysqldump备份及恢复 1、mysqldump 参数说明 –single-transaction 用于保证InnoDB备份数据时的一致性，配合RR隔离级别一起使用；当发起事务时，读取一个数据的快照，直到备份结束，都不会读取到本事务开始之后提交的任何数据 –all-databases （-A） 备份所有的数据库 –master-data 该值有两个，如果等于1，在备份文件中添加一个CHANGE MASTER的语句，如果等于2，在备份的文件中添加一个CHANGE MASTER的语句，并在语句前添加注释 2、mysqldump备份与恢复 备份全库 mysqldump --single-transaction -uroot -proot123 -A \u003e all.sql mysqldump --single-transaction -uroot -proot123 --set-gtid-purged=OFF -A \u003e all.sql # 开启gtid同步 mysqldump --single-transaction -uroot -proot123 --skip-gtids -A \u003e all.sql # 开启gtid同步 恢复全库 mysql -uroot -proot123 \u003c all.sql 备份单个库 mysqldump --single-transaction -uroot -proot123 db1 \u003e db1.sql 恢复单个库 mysql -uroot -proot123 db1 \u003c db1.sql # 如果db1 不存在，需要到数据库中创建数据库db1 create database db1 备份单表 mysqldump --single-transaction -uroot -proot123 db1 t \u003et.sql 恢复单表 mysql -uroot -proot123 db1 \u003c t.sql 备份db1库t表中的表结构信息 mysqldump --single-transcation -uroot -proot123 db1 t -d \u003e t.sql 备份db1库t表中的数据信息 mysqldump --single-transcation -uroot -proot123 db1 t -t \u003e t.sql 备份db1库t表中id\u003e3 的记录 mysqldump --single-transcation -uroot -proot123 db1 t --where=\"id\u003e3\" \u003e t.sql 3、select … into outfile 备份tt 表中的数据全部导出到/tmp目录下 select * from tt into outfile '/tmp/tt.sql' load data 导入数据 # 删除数据 delete from tt load data infile '/tmp/tt.sql' into table db1.tt # 在服务器上直接执行导入数据 mysql -uroot -proot123 -e \"load data infile '/tmp/test1.sql' into table db1.test1\" 4、mydumper mydumper安装 # 安装依赖 yum install -y glib2-devel mysql-devel zlib-devel pcre-devel openssl-devel # 安装mydumper wget https://github.com/maxbube/mydumper/releases/download/v0.9.5/mydumper-0.9.5-2.el7.x86_64.rpm yum install -y mydumper-0.9.5-2.el7.x86_64.rpm mydumper备份 # 备份全库 mydumper -u root -p root123 -h host -P port -o /data/backup # 还原全库 myloader -u root -p root123 -h host -P port -d /data/backup mydumper备份db1库下tt表 # 备份 mydumper -u root -p root123 -h host -P port -B db1 -T tt -o /data/backup # 恢复 myloader -u root -p root123 -h host -P port -B db1 -o tt -d /data/backup 5、XtraBackup备份 XtraBackup 安装 下载地址： https://www.percona.com/downloads/Percona-XtraBackup-LATEST/ # 安装8.0 wget https://www.percona.com/downloads/Percona-XtraBackup-LATEST/Percona-XtraBackup-8.0.4/binary/redhat/7/x86_64/percona-xtrabackup-80-8.0.4-1.el7.x86_64.rpm yum install -y percona-xtrabackup-80-8.0.4-1.el7.x86_64.rpm # 安装2.4 wget https://www.percona.com/downloads/Percona-XtraBackup-2.4/Percona-XtraBackup-2.4.13/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.13-1.el7.x86_64.rpm yum install -y percona-xtrabackup-24-2.4.13-1.el7.x86_64.rpm 全备 # 创建备份用户名和密码 create user 'repl'@'192.168.5.%' identified by 'repl@back' # 添加权限 grant reload,lock tables,replication client,process,super on *.* to 'repl'@'192.168.5.%' # 添加权限最小化 grant reload,lock tables,replication client,process on *.* to 'replback'@'localhost' identified by 'repl@2019#back'; flush privileges # 创建备份目录 mkdir -p /data/mysql_backup # 备份 innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user repl --host 172.16.5.123 --password Password1 /data/mysql_back/all-20190216bak # 流试压缩备份 innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user replback --host 192.168.0.12 --password --stream=tar /work/Monitoring | gzip - \u003e /work/Monitoring/all-20190528.tgz 全备恢复 # 校验 innobackupex --defaults-file=/etc/my.cnf --user repl --host 172.16.5.123 --password repl --apply-log /data/mysql_back/all-20190216bak # 停止mysql mysqladmin -uroot -proot123 shutdown # 数据拷贝 mv /data/mysql /data/mysql_back cd /data/ mv all-20190216bak/ mysql chown -R mysql:mysql mysql # 启动mysql mysqld_safe --defaults-file=/etc/my.cnf \u0026 增量备份 # 创建全备 innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user repl --host 172.16.5.123 --password Password1 /data/mysql_back/all-20190216bak # 创建增量备份 innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user repl --host 172.16.5.123 --password Password1 --incremental /data/mysql_back/all-20190217incr --incremental-basedir=/data/mysql_back/all-20190216bak 增量恢复 # 恢复全备 innobackupex --defaults-file=/etc/my.cnf --no-timestamp --user repl --host 172.16.5","date":"2021-02-15","objectID":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:0:2","tags":["Mysql"],"title":"Mysql备份与恢复","uri":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["数据库"],"content":"三、msyql误删恢复 3.1、使用binlog2sql删除表恢复 安装binlog2sql软件 # 安装pip curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python get-pip.py git clone https://github.com/danfengcao/binlog2sql.git \u0026\u0026 cd binlog2sql pip install -r requirements.txt # 修改my.cnf配置文件 max_binlog_size = 1G binlog_row_image = full # 添加权限 create user 'binlog2sql'@'172.16.5.%' identified by 'Password1' GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'binlog2sql'@'172.16.5.%' flush privileges 使用binlog2sql解析mysql 解析出标准SQL python binlog2sql/binlog2sql.py -h172.16.5.123 -P3306 -ubinlog2sql -pPassword1 -dtest -t test_account --start-file='mysql-bin.000008' 选项 mysql连接配置 -h host; -P port; -u user; -p password 解析模式 –stop-never 持续解析binlog。可选。默认False，同步至执行命令时最新的binlog位置。 -K, –no-primary-key 对INSERT语句去除主键。可选。默认False -B, –flashback 生成回滚SQL，可解析大文件，不受内存限制。可选。默认False。与stop-never或no-primary-key不能同时添加。 –back-interval -B模式下，每打印一千行回滚SQL，加一句SLEEP多少秒，如不想加SLEEP，请设为0。可选。默认1.0。 解析范围控制 –start-file 起始解析文件，只需文件名，无需全路径 。必须。 –start-position/–start-pos 起始解析位置。可选。默认为start-file的起始位置。 –stop-file/–end-file 终止解析文件。可选。默认为start-file同一个文件。若解析模式为stop-never，此选项失效。 –stop-position/–end-pos 终止解析位置。可选。默认为stop-file的最末位置；若解析模式为stop-never，此选项失效。 –start-datetime 起始解析时间，格式'%Y-%m-%d %H:%M:%S'。可选。默认不过滤。 –stop-datetime 终止解析时间，格式'%Y-%m-%d %H:%M:%S'。可选。默认不过滤。 对象过滤 -d, –databases 只解析目标db的sql，多个库用空格隔开，如-d db1 db2。可选。默认为空。 -t, –tables 只解析目标table的sql，多张表用空格隔开，如-t tbl1 tbl2。可选。默认为空。 –only-dml 只解析dml，忽略ddl。可选。默认False。 –sql-type 只解析指定类型，支持INSERT, UPDATE, DELETE。多个类型用空格隔开，如–sql-type INSERT DELETE。可选。默认为增删改都解析。用了此参数但没填任何类型，则三者都不解析。 应用案例 误删除整张表数据，需要紧急回滚 # 查看表数据 select count（1） from auth_menu; +----------+ | count(1) | +----------+ | 42 | +----------+ # 清楚记录 delete from auth_menu; # 查看记录 +----------+ | count(1) | +----------+ | 0 | +----------+ 恢复数据步骤 1、查看binlog日志 show master status; +------------------+----------+--------------+------------------+---------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+---------------------------------------------+ | mysql-bin.000012 | 3005 | | | be9d0501-30fb-11e9-b2ec-000c29e37447:1-4085 | +------------------+----------+--------------+------------------+---------------------------------------------+ 2、通过大致时间定位binlog位置 python binlog2sql/binlog2sql.py -h172.16.5.123 -P3306 -ubinlog2sql -pPassword1 -dtest -tauth_menu --start-file='mysql-bin.000012' --start-datetime='2019-02-19 15:33:00' --stop-datetime='2019-02-19 15:40:00' # 输出 #start 902 end 2974 time 2019-02-19 15:35:36 3、过滤生成要回滚的sql python binlog2sql/binlog2sql.py -h172.16.5.123 -P3306 -ubinlog2sql -pPassword1 -dtest -tauth_menu --start-file='mysql-bin.000012' --start-position=902 --stop-position=2974 -B \u003e rollback.sql | cat 4、执行回滚语句，并检查是否正确 # 执行回滚语句 mysql -uroot -p \u003c rollback.sql # 登录数据库查看记录条数 mysql -uroot -p select count(1) from auth_menu; +----------+ | count(1) | +----------+ | 42 | +----------+ 3.2、使用binlog恢复误删除表 1、删除表 delete from auth_menu; 2、全备库 mysqldump -uroot -pPassword1 --single-transaction --master-data=2 db1 \u003e /root/db.sql # 查看post cat db.sql |grep -i \"change\" -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000012', MASTER_LOG_POS=28945; 3、 解析binlog # 通过binlog mysqlbinlog -vv --base64-output=DECODE-ROWS --start-position=28945 -d db1 mysql-bin.000012 \u003e /root/test1.sql # 通过grep mysqlbinlog -vv --base64-output=decode-rows server08-relay-bin.000752 | grep -C 60 '503948823' 3.3、使用mysqlfrm恢复数据表结构 # 下载安装mysqlfrm wget https://cdn.mysql.com/archives/mysql-utilities/mysql-utilities-1.6.5-1.el7.noarch.rpm # 获取表结构 mysqlfrm --diagnostic ./frm/ # 创建表结构 # 卸载表空间 ALTER TABLE 表名 DISCARD TABLESPACE systemctl stop mysqld # 拷贝ibd文件到数据目录 chmod -R mysql. /data systemctl start mysqld # 装载表空间 ALTER TABLE 表名 IMPORT TABLESPACE ","date":"2021-02-15","objectID":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/:0:3","tags":["Mysql"],"title":"Mysql备份与恢复","uri":"/mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/"},{"categories":["linux"],"content":"Shell编程基础03","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"for循环语句 在计算机科学中，for循环（英语：for loop）是一种编程语言的迭代陈述，能够让程式码反复的执行。它跟其他的循环，如while循环，最大的不同，是它拥有一个循环计数器，或是循环变数。这使得for循环能够知道在迭代过程中的执行顺序。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:1:0","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"shell中的for循环 shell中的for 循环与在c中不同，它包含三种形式： 第一种结构是列表for 循环; 第二种结构就是不带列表的for循环； 第三种就类似于C语言。 1、列表for循环(常用) #！/bin/bash for i in 取值列表 do 循环主体/命令 done 2、不带列表for循环(示例) #!/bin/absh echo \"今天是什么日子：\" for i do echo \"$i\" done 脚本执行结果： [root@kube-master ~]# sh test.sh 好日子 今天是什么日子： 好日子 3、类似C语言的风格（这种用法常在C语语言中使用） for((i=0;i\u003c=3;i++)) do echo $i done ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:1:1","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"while循环语句 在编程语言中，while循环（英语：while loop）是一种控制流程的陈述。利用一个返回结果为布林值（Boolean）的表达式作为循环条件，当这个表达式的返回值为“真”（true）时，则反复执行循环体内的程式码；若表达式的返回值为“假”（false），则不再执行循环体内的代码，继续执行循环体下面的代码。 因为while循环在区块内代码被执行之前，先检查陈述是否成立，因此这种控制流程通常被称为是一种前测试循环（pre-test loop）。相对而言do while循环，是在循环区块执行结束之后，再去检查陈述是否成立，被称为是后测试循环。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:2:0","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"shell中while语法 while 条件 do 命令 done sleep 单位 秒 sleep 1 休息1秒 usleep 单位 微秒 usleep 1000000 休息1s 1微秒等于百万分之一秒（10的负6次方秒） ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:2:1","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"break continue exit return 条件与循环控制及程序返回值命令表 命令 说明　 break n 如果省略n，则表示跳出整个循环，n表示跳出循环的层数 continue n 如果省略n，则表示跳过本次循环，忽略本次循环的剩余代码，进人循环的下一次循环。 n表示退到第n层继续循环 exit n 退出当前Shell程序，n为上一次程序执行的状态返回值。n也可以省略，在下一个Shell里可通过\"$?“接收exit n的n值 return n 用于在函数里作为函数的返回值，以判断函数执行是否正确。在下一个Shell里可通过”$?“接收exit n的n值 简单来说即： break 跳出循环 continue 跳出本次循环 exit 退出脚本 return 与 exit 相同，在函数中使用 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:3:0","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"break命令说明 [root@k8s-master] # help break break: break [n] 退出 for、while、或 until 循环 退出一个 FOR、WHILE 或 UNTIL 循环。如果指定了N，则打破N重 循环 退出状态： 退出状态为0除非 N 不大于或等于 1。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:3:1","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"continue命令说明 [root@k8s-master]# help continue continue: continue [n] 继续 for、while、或 until 循环。 继续当前 FOR、WHILE 或 UNTIL 循环的下一步。 如果指定了 N， 则继续当前的第 N 重循环。 退出状态： 退出状态为 0 除非 N 不大于或等于1。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:3:2","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"exit命令说明 [root@k8s-master]# help exit exit: exit [n] 退出shell。 以状态 N 退出 shell。 如果 N 被省略，则退出状态 为最后一个执行的命令的退出状态。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:3:3","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"return命令说明 [root@k8s-master]# help return return: return [n] 从一个 shell 函数返回。 使一个函数或者被引用的脚本以指定的返回值 N 退出。 如果 N 被省略，则返回状态就是 函数或脚本中的最后一个执行的命令的状态。 退出状态： 返回 N，或者如果 shell 不在执行一个函数或引用脚本时，失败。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:3:4","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"shell中的数组 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:4:0","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"为什么会产生Shell数组 通常在开发Shell脚本时，定义变量采用的形式为“a=l;b=2;C=3”，可如果有多个 变量呢？这时再逐个地定义就会很费劲，并且要是有多个不确定的变量内容，也会难以 进行变量定义，此外，快速读取不同变量的值也是一件很痛苦的事情，于是数组就诞生 了，它就是为了解决上述问题而出现的。 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:4:1","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"什么是Shell数组 Shell的数组就是一个元素集合，它把有限个元素（变量或字符内容）用一个名字来 命名，然后用编号对它们进行区分。这个名字就称为数组名，用于区分不同内容的编 号就称为数组下标。组成数组的各个元素（变量）称为数组的元素，有时也称为下标变量. ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:4:2","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"数组中的增删改查 Shell的数组就是一个元素集合，它把有限个元素（变量或字符内容）用一个名字来 命名，然后用编号对它们进行区分。这个名字就称为数组名，用于区分不同内容的编 号就称为数组下标。组成数组的各个元素（变量）称为数组的元素，有时也称为下标变量. shell数组的定义 # 使用小括号将变量括起来赋值 array=(1 2 3) echo ${array[*]} 1 2 3 # 使用小括号将变量括起来赋值,同时采用键值对的方式赋值 array=([1]=one [2]=two [3]=three) echo ${array[*]} one two three 数组增加与修改 # 通过添加下标的方式增加数组 array[4]=four array[3]=five echo ${array[*]} one two five four 数组的删除 # 通过unset[]下标删除 unset array[1] ehco ${array[*]} two three ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:4:3","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"shell 函数 ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:5:0","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["linux"],"content":"shell 函数语法 # 第一种写法 function main() { 函数体 return n } # 第二种写法 main () { 函数体 return n } ","date":"2021-02-15","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/:5:1","tags":["Linux"],"title":"Shell编程基础03","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8003/"},{"categories":["日志收集"],"content":"EFK日志平台部署","date":"2021-02-05","objectID":"/efk%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/","tags":["efk"],"title":"EFK日志平台部署","uri":"/efk%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/"},{"categories":["日志收集"],"content":"EFK 架构说明 日志收集方案是采用 Elasticsearch、Fluentd、Filebeat 和 Kibana（EFK）技术栈。 Fluented主要用来收集k8s组件和docker容器日志，Filebeat主要用来收集应用日志，主要因为目前项目中应用日志并未全部通过stdout方式输出到docker日志驱动中，导致flunted收集日志并不全面，需要通过Filebeat来将应用日志收集到es中，再由kibana来展示。 Elasticsearch 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。 Elasticsearch 通常与 Kibana 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。 Fluentd是一个流行的开源数据收集器，我们将在 Kubernetes 集群节点上安装 Fluentd，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。 Filebeat 内置有多种模块（auditd、Apache、NGINX、System、MySQL 等等），可针对常见格式的日志大大简化收集、解析和可视化过程，只需一条命令即可。之所以能实现这一点，是因为它将自动默认路径（因操作系统而异）与 Elasticsearch 采集节点管道的定义和 Kibana 仪表板组合在一起。不仅如此，数个 Filebeat 模块还包括预配置的 Machine Learning 任务。 将官方提供的yaml下载到本地，如EFK目录下 https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch wget \\ https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/es-statefulset.yaml wget \\ https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/es-service.yaml wget \\ https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/fluentd-es-configmap.yaml wget \\ https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/fluentd-es-ds.yaml wget \\ https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/kibana-service.yaml wget \\ https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/kibana-deployment.yaml 下载filebeat官方提供的yaml文件到本地目录下如EFK https://github.com/elastic/beats/blob/master/deploy/kubernetes/filebeat-kubernetes.yaml ","date":"2021-02-05","objectID":"/efk%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/:0:1","tags":["efk"],"title":"EFK日志平台部署","uri":"/efk%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/"},{"categories":["日志收集"],"content":"EFK 部署 创建 Elasticsearch 集群 在创建 Elasticsearch 集群之前，先创建一个命名空间，我们将在其中安装所有日志相关的资源对象。 新建一个 kube-logging_ns.yaml 文件： apiVersion:v1kind:Namespacemetadata:name:logging 然后通过 kubectl 创建该资源清单，创建一个名为 logging 的 namespace： # kubectl get ns NAME STATUS AGE default Active 115d kube-node-lease Active 115d kube-public Active 115d kube-system Active 115d logging Active 62d 修改定义 Pod 模板部分内容,添加java_opts环境变量 env: - name: \"NAMESPACE\" valueFrom: fieldRef: fieldPath: metadata.namespace - name: ES_JAVA_OPTS value: \"-Xms512m -Xmx512m\" 该部分是定义 StatefulSet 中的 Pod，我们这里使用一个-oss后缀的镜像，该镜像是 Elasticsearch 的开源版本，如果你想使用包含X-Pack之类的版本，可以去掉该后缀。然后暴露了9200和9300两个端口，注意名称要和上面定义的 Service 保持一致。然后通过 volumeMount 声明了数据持久化目录，下面我们再来定义 VolumeClaims。最后就是我们在容器中设置的一些环境变量了： ES_JAVA_OPTS：这里我们设置为-Xms512m -Xmx512m，告诉JVM使用512 MB的最小和最大堆。 接下来添加关于 initContainer 的内容 initContainers: - name: fix-permissions image: busybox command: [\"sh\", \"-c\", \"chown -R 1000:1000 /usr/share/elasticsearch/data\"] securityContext: privileged: true volumeMounts: - name: data mountPath: /usr/share/elasticsearch/data - name: elasticsearch-logging-init image: alpine:3.6 command: [\"/sbin/sysctl\", \"-w\", \"vm.max_map_count=262144\"] securityContext: privileged: true - name: increase-fd-ulimit image: busybox command: [\"sh\", \"-c\", \"ulimit -n 65536\"] securityContext: privileged: true 这里定义了几个在主应用程序之前运行的 Init 容器，这些初始容器按照定义的顺序依次执行，执行完成后才会启动主应用容器。 第一个名为 fix-permissions 的容器用来运行 chown 命令，将 Elasticsearch 数据目录的用户和组更改为1000:1000（Elasticsearch 用户的 UID）。因为默认情况下，Kubernetes 用 root 用户挂载数据目录，这会使得 Elasticsearch 无法方法该数据目录，可以参考 Elasticsearch 生产中的一些默认注意事项相关文档说明：https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults。 第二个名为 elasticsearch-logging-init 的容器用来增加操作系统对mmap计数的限制，默认情况下该值可能太低，导致内存不足的错误，要了解更多关于该设置的信息，可以查看 Elasticsearch 官方文档说明：https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html。 最后一个初始化容器是用来执行ulimit命令增加打开文件描述符的最大数量的。 修改数据目录持久化 volumeMounts: - name: elasticsearch-logging mountPath: /usr/share/elasticsearch/data volumes: - name: elasticsearch-logging hostPath: path: /data/elasticsearch-logs/data 通过hostPath模式将es数据持久化到宿主机上。 完整的配置文件如下： # RBAC authn and authzapiVersion:v1kind:ServiceAccountmetadata:name:elasticsearch-loggingnamespace:logginglabels:k8s-app:elasticsearch-loggingaddonmanager.kubernetes.io/mode:Reconcile---kind:ClusterRoleapiVersion:rbac.authorization.k8s.io/v1metadata:name:elasticsearch-logginglabels:k8s-app:elasticsearch-loggingaddonmanager.kubernetes.io/mode:Reconcilerules:- apiGroups:- \"\"resources:- \"services\"- \"namespaces\"- \"endpoints\"verbs:- \"get\"---kind:ClusterRoleBindingapiVersion:rbac.authorization.k8s.io/v1metadata:namespace:loggingname:elasticsearch-logginglabels:k8s-app:elasticsearch-loggingaddonmanager.kubernetes.io/mode:Reconcilesubjects:- kind:ServiceAccountname:elasticsearch-loggingnamespace:loggingapiGroup:\"\"roleRef:kind:ClusterRolename:elasticsearch-loggingapiGroup:\"\"---# Elasticsearch deployment itselfapiVersion:apps/v1kind:StatefulSetmetadata:name:elasticsearch-loggingnamespace:logginglabels:k8s-app:elasticsearch-loggingversion:v7.2.0addonmanager.kubernetes.io/mode:Reconcilespec:serviceName:elasticsearch-loggingreplicas:1selector:matchLabels:k8s-app:elasticsearch-loggingversion:v7.2.0template:metadata:labels:k8s-app:elasticsearch-loggingversion:v7.2.0spec:serviceAccountName:elasticsearch-loggingcontainers:- image:quay.io/fluentd_elasticsearch/elasticsearch:v7.2.0name:elasticsearch-loggingimagePullPolicy:IfNotPresentresources:# need more cpu upon initialization, therefore burstable classlimits:cpu:1000mrequests:cpu:100mports:- containerPort:9200name:dbprotocol:TCP- containerPort:9300name:transportprotocol:TCPvolumeMounts:- name:datamountPath:/usr/share/elasticsearch/dataenv:- name:ES_JAVA_OPTSvalue:\"-Xms512m -Xmx512m\"- name:TZvalue:Asia/Shanghai- name:\"NAMESPACE\"valueFrom:fieldRef:fieldPath:metadata.namespacevolumes:- name:datahostPath:path:/data/elasticsearch-logs/data# Elasticsearch requires vm.max_map_count to be at leas","date":"2021-02-05","objectID":"/efk%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/:0:2","tags":["efk"],"title":"EFK日志平台部署","uri":"/efk%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E9%83%A8%E7%BD%B2/"},{"categories":["监控"],"content":"Prometheus监控规则说明","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"prometheus operator 监控指标 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:0","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"kubernetes 资源相关 CPUThrottlingHigh 关于 CPU 的 limit 合理性指标。查出最近5分钟，超过25%的 CPU 执行周期受到限制的容器。表达式： sum(increase(container_cpu_cfs_throttled_periods_total{container!=\"\", }[5m])) by (container, pod, namespace) / sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace) \u003e ( 25 / 100 ) 相关指标： container_cpu_cfs_periods_total：容器生命周期中度过的 cpu 周期总数 container_cpu_cfs_throttled_periods_total：容器生命周期中度过的受限的 cpu 周期总数 KubeCPUOvercommit 集群 CPU 过度使用。CPU 已经过度使用无法容忍节点故障，节点资源使用的总量超过节点的 CPU 总量，所以如果有节点故障将影响集群资源运行因为所需资源将无法被分配。表达式： sum(namespace:kube_pod_container_resource_requests_cpu_cores:sum{}) / sum(kube_node_status_allocatable_cpu_cores) \u003e (count(kube_node_status_allocatable_cpu_cores)-1) / count(kube_node_status_allocatable_cpu_cores) 相关指标： kube_pod_container_resource_requests_cpu_cores：资源 CPU 使用的 cores 数量 kube_node_status_allocatable_cpu_cores：节点 CPU cores 数量 KubeMemoryOvercommit 集群内存过度使用。内存已经过度使用无法容忍节点故障，节点资源使用的总量超过节点的内存总量，所以如果有节点故障将影响集群资源运行因为所需资源将无法被分配。表达式： sum(namespace:kube_pod_container_resource_requests_memory_bytes:sum{}) / sum(kube_node_status_allocatable_memory_bytes) \u003e (count(kube_node_status_allocatable_memory_bytes)-1) / count(kube_node_status_allocatable_memory_bytes) 相关指标： kube_pod_container_resource_requests_memory_bytes：资源内存使用的量 kube_node_status_allocatable_memory_bytes：节点内存量 KubeCPUQuotaOvercommit 集群CPU是否超分。查看 CPU 资源分配的额度是否超过进群总额度 表达式： sum(kube_pod_container_resource_limits_cpu_cores{job=\"kube-state-metrics\"}) / sum(kube_node_status_allocatable_cpu_cores) \u003e 1.1 相关指标： kube_pod_container_resource_limits_cpu_cores：资源分配的 CPU 资源额度 kube_node_status_allocatable_cpu_cores：节点 CPU 总量 KubeMemoryQuotaOvercommit 集群超分内存，查看内存资源分配的额度是否超过进群总额度 表达式： sum(kube_pod_container_resource_limits_memory_bytes{job=\"kube-state-metrics\"}) / sum(kube_node_status_allocatable_memory_bytes{job=\"kube-state-metrics\"}) \u003e 1.1 相关指标: kube_pod_container_resource_limits_memory_bytes：资源配额内存量 kube_node_status_allocatable_memory_bytes：节点内存量 KubeMEMQuotaExceeded 命名空间级内存资源使用的比例，关乎资源配额。当使用 request 和 limit 限制资源时，使用值和最大值还是有一点区别，当有 request 时说明最低分配了这么多资源。需要注意当 request 等于 limit 时那么说明资源已经是100%已经分配使用当监控告警发出的时候需要区分。表达式： sum (kube_pod_container_resource_requests_memory_bytes{job=\"kube-state-metrics\"} ) by (namespace)/ (sum(kube_pod_container_resource_limits_memory_bytes{job=\"kube-state-metrics\"}) by (namespace)) \u003e 0.8 相关指标: kube_pod_container_resource_requests_memory_bytes：内存资源使用量 kube_pod_container_resource_limits_memory_bytes：内存资源最大值 KubeCPUQuotaExceeded 命名空间级 CPU 资源使用的比例，关乎资源配额。当使用 request 和 limit 限制资源时，使用值和最大值还是有一点区别，当有 request 时说明最低分配了这么多资源。需要注意当 request 等于 limit 时那么说明资源已经是100%已经分配使用当监控告警发出的时候需要区分。表达式： sum (kube_pod_container_resource_requests_cpu_cores{job=\"kube-state-metrics\"} ) by (namespace)/ (sum(kube_pod_container_resource_limits_cpu_cores{job=\"kube-state-metrics\"}) by (namespace)) \u003e 0.8 相关指标: kube_pod_container_resource_requests_cpu_cores：CPU 使用量 kube_pod_container_resource_limits_cpu_cores：CPU 限额最大值 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:1","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"Kubernetes 存储相关 KubePersistentVolumeFillingUp PVC 容量监控，表达式： kubelet_volume_stats_available_bytes{job=\"kubelet\", metrics_path=\"/metrics\"} / kubelet_volume_stats_capacity_bytes{job=\"kubelet\", metrics_path=\"/metrics\"} \u003c 0.3 相关指标： kubelet_volume_stats_available_bytes：剩余空间 kubelet_volume_stats_capacity_bytes：空间总量 KubePersistentVolumeFillingUp 磁盘空间耗尽预测：通过PVC资源使用6小时变化率预测 接下来4天的磁盘使用率,表达式： (kubelet_volume_stats_available_bytes{job=\"kubelet\", metrics_path=\"/metrics\"} / kubelet_volume_stats_capacity_bytes{job=\"kubelet\", metrics_path=\"/metrics\"} ) \u003c 0.4 and predict_linear(kubelet_volume_stats_available_bytes{job=\"kubelet\", metrics_path=\"/metrics\"}[6h], 4 * 24 * 3600) \u003c 0 相关指标: kubelet_volume_stats_available_bytes：剩余空间 kubelet_volume_stats_capacity_bytes：空间总量 KubePersistentVolumeErrors PV 使用状态监控。表达式： kube_persistentvolume_status_phase{phase=~\"Failed|Pending\",job=\"kube-state-metrics\"} 相关指标： kube_persistentvolume_status_phase：PV 使用状态 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:2","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"kubernetes system 相关 KubeVersionMismatch 组件版本与当前集群版本是否有差异。对比组件版本是否有差异，默认为1 。表达式： count(count by (gitVersion) (label_replace(kubernetes_build_info{job!~\"kube-dns|coredns\"},\"gitVersion\",\"$1\",\"gitVersion\",\"(v[0-9]*.[0-9]*.[0-9]*).*\"))) 相关指标： kubernetes_build_info：获取组件信息 KubeClientErrors 客户端访问某些接口的错误率。表达式： (sum(rate(rest_client_requests_total{code=~\"5..\"}[5m])) by (instance, job) / sum(rate(rest_client_requests_total[5m])) by (instance, job)) \u003e 0.01 相关指标： rest_client_requests_total：状态码 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:3","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"APIServer 相关 KubeAPIErrorsHigh APIServer 请求错误率。5分钟内 APIServer 请求错误率。表达式： sum(rate(apiserver_request_total{job=\"apiserver\",code=~\"5..\"}[5m])) by (resource,subresource,verb) / sum(rate(apiserver_request_total{job=\"apiserver\"}[5m])) by (resource,subresource,verb) \u003e 0.05 相关指标： apiserver_request_total：APIServer 请求数 KubeClientCertificateExpiration kubelet 客户端证书过期。监测证书状态30天告警和7天告警。表达式： # 30天 apiserver_client_certificate_expiration_seconds_count{job=\"apiserver\"} \u003e 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\"apiserver\"}[5m]))) \u003c 2592000 # 7天 apiserver_client_certificate_expiration_seconds_count{job=\"apiserver\"} \u003e 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\"apiserver\"}[5m]))) \u003c 604800 相关指标： apiserver_client_certificate_expiration_seconds_count：证书有效剩余时间 AggregatedAPIErrors 自定义注册的 APIServer 服务可用性监控，当检测到自定义注册的 APIServer 五分钟不用次数达到2次。表达式： sum by(name, namespace)(increase(aggregator_unavailable_apiservice_count[5m])) \u003e 2 相关指标: aggregator_unavailable_apiservice_count：监测自定义注册的 APIService 不可用次数。 KubeAPIDown APIserver 失联，监控 APIServer 服务，失联原因可能是服务 down 还可能是网络出现状况。表达式： absent(up{job=\"apiserver\"} == 1) ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:4","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"kubelet 相关 KubeNodeNotReady 节点是否处于就绪状态。检测节点是否为就绪状态，或者可能是 kubelet 服务down 了。表达式： kube_node_status_condition{job=\"kube-state-metrics\",condition=\"Ready\",status=\"true\"} == 0 相关指标： kube_node_status_condition：节点状态监测 KubeNodeUnreachable 节点状态为 Unreachable。表达式： kube_node_spec_unschedulable{job=\"kube-state-metrics\"} == 1 KubeletTooManyPods 节点运行过多的 Pod，监测节点上运行的 Pods 数量。表达式： max(max(kubelet_running_pod_count{job=\"kubelet\", metrics_path=\"/metrics\"}) by(instance) * on(instance) group_left(node) kubelet_node_name{job=\"kubelet\", metrics_path=\"/metrics\"}) by(node) / max(kube_node_status_capacity_pods{job=\"kube-state-metrics\"} != 1) by(node) \u003e 0.95 相关指标： kubelet_running_pod_count：节点运行的 Pods 数量 kubelet_node_name：节点名称 kube_node_status_capacity_pods：节点可运行的最大 Pod 数量 KubeNodeReadinessFlapping 监测集群状态，查看集群内节点状态改变的频率。表达式: sum(changes(kube_node_status_condition{status=\"true\",condition=\"Ready\"}[15m])) by (node) \u003e 2 KubeletDown 监控 kubelet 服务，down 或者网络出现问题。表达式： absent(up{job=\"kubelet\", metrics_path=\"/metrics\"} == 1) ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:5","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"集群组件 KubeSchedulerDown KubeScheduler 失联，监测 KubeScheduler 是否正常。表达式： absent(up{job=\"kube-scheduler\"} == 1) KubeControllerManagerDown 监测 KubeControllerManager 服务，Down 或者网络不通。表达式： absent(up{job=\"kube-controller-manager\"} == 1) ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:6","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"应用相关 KubePodCrashLooping Pod 重启时间，重启时间超过3m告警。表达式： rate(kube_pod_container_status_restarts_total{job=\"kube-state-metrics\"}[5m]) * 60 * 3 \u003e 0 相关指标: kube_pod_container_status_restarts_total：重启状态0为正常 KubePodNotReady Pods 没有就绪，检测 Pod 是否就绪。表达式： sum by (namespace, pod) (max by(namespace, pod) (kube_pod_status_phase{job=\"kube-state-metrics\", phase=~\"Pending|Unknown\"}) * on(namespace, pod) group_left(owner_kind) max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!=\"Job\"})) \u003e 0 相关指标： kube_pod_status_phase：Pod 状态 KubeDeploymentGenerationMismatch Deployment 部署失败，Deployment 生成的资源与定义的资源不匹配。表达式： kube_deployment_status_observed_generation{job=\"kube-state-metrics\"} != kube_deployment_metadata_generation{job=\"kube-state-metrics\"} 相关指标： kube_deployment_status_observed_generation：Deployment 生成资源数 kube_deployment_metadata_generation：Deployment 定义资源数 KubeDeploymentReplicasMismatch 查看 Deplyment 副本是否达到预期。表达式： ( kube_deployment_spec_replicas{job=\"kube-state-metrics\"} != kube_deployment_status_replicas_available{job=\"kube-state-metrics\"} ) and ( changes(kube_deployment_status_replicas_updated{job=\"kube-state-metrics\"}[3m]) == 0 ) 相关指标： kube_deployment_spec_replicas 资源定义副本数 kube_deployment_status_replicas_available 正在运行副本数 kube_deployment_status_replicas_updated 更新的副本数 KubeStatefulSetReplicasMismatch 监测 StatefulSet 副本是否达到预期。表达式： ( kube_statefulset_status_replicas_ready{job=\"kube-state-metrics\"} != kube_statefulset_status_replicas{job=\"kube-state-metrics\"} ) and ( changes(kube_statefulset_status_replicas_updated{job=\"kube-state-metrics\"}[5m]) == 0 ) 相关指标： kube_statefulset_status_replicas_ready：就绪副本数 kube_statefulset_status_replicas：当前副本数 kube_statefulset_status_replicas_updated：更新的副本数 KubeStatefulSetUpdateNotRolledOut StatefulSet 更新失败且未回滚，对比版本号和副本数。表达式： max without (revision) ( kube_statefulset_status_current_revision{job=\"kube-state-metrics\"} unless kube_statefulset_status_update_revision{job=\"kube-state-metrics\"} ) * ( kube_statefulset_replicas{job=\"kube-state-metrics\"} != kube_statefulset_status_replicas_updated{job=\"kube-state-metrics\"} ) 相关指标： kube_statefulset_status_replicas：每个 StatefulSet 的副本数。 kube_statefulset_status_replicas_current：每个 StatefulSet 的当前副本数。 kube_statefulset_status_replicas_ready：每个StatefulSet 的就绪副本数。 kube_statefulset_status_replicas_updated：每个StatefulSet 的更新副本数。 kube_statefulset_status_observed_generation：StatefulSet 控制器观察到的生成。 kube_statefulset_replicas：StatefulSet 所需的副本数。 kube_statefulset_metadata_generation：表示 StatefulSet 所需状态的特定生成的序列号。 kube_statefulset_created：创建时间戳。 kube_statefulset_labels：Kubernetes 标签转换为 Prometheus 标签。 kube_statefulset_status_current_revision：指示用于按顺序(0，currentReplicas)生成 Pod 的StatefulSet 的版本。 kube_statefulset_status_update_revision：指示用于按顺序 [replicas-updatedReplicas，replicas] 生成 Pod 的 StatefulSet 的版本。 KubeDaemonSetRolloutStuck 监测 DaemonSet 是否处于就绪状态。表达式： kube_daemonset_status_number_ready{job=\"kube-state-metrics\"} / kube_daemonset_status_desired_number_scheduled{job=\"kube-state-metrics\"} \u003c 1.00 相关指标： kube_daemonset_status_number_ready：就绪的 DaemonSet kube_daemonset_status_desired_number_scheduled：应该调度的 DaemonSet 数量 KubeDaemonSetMisScheduled DaemonSet 运行在不该运行的节点上面。表达式： kube_daemonset_status_number_misscheduled{job=\"kube-state-metrics\"} \u003e 0 相关指标： kube_daemonset_status_number_misscheduled：运行在不该运行的节点状态 KubeDaemonSetNotScheduled DaemonSet 没有可调度节点去运行。表达式： kube_daemonset_status_desired_number_scheduled{job=\"kube-state-metrics\",namespace=~\".*\"} - kube_daemonset_status_current_number_scheduled{job=\"kube-state-metrics\",namespace=~\".*\"} \u003e 0 相关指标： kube_daemonset_status_desired_number_scheduled：应该调度的 DaemonSet 数量 kube_daemonset_status_current_number_scheduled: 当前调度的 Daemonset 数量 KubeContainerWaiting 监测哪些容器是在等待状态的。表达式： sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job=\"kube-state-metrics\"}) \u003e 0 相关指标： kube_pod_container_status_waiting_reason：容器声明周期过程中的状态，无论是创建成功还是失败都应该是0。 KubeJobCompletion 监控那些自动任务没有结束。表达式： kube_job_spec_completions{job=\"kube-state-metrics\",job_name=~\".*loki-weixin-noti","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:7","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"节点相关 NodeClockNotSynchronising 主机与时间服务器失联。表达式： min_over_time(node_timex_sync_status[5m]) == 0 相关指标： node_timex_sync_status：同步状态。 NodeClockSkewDetected 本地时间偏移量。表达式： (node_timex_offset_seconds \u003e 0.05 and deriv(node_timex_offset_seconds[5m]) \u003e= 0 ) or ( node_timex_offset_seconds \u003c -0.05 and deriv(node_timex_offset_seconds[5m]) \u003c= 0) 相关指标： node_timex_offset_seconds：误差 NodeHighNumberConntrackEntriesUsed 链接状态跟踪。表达式： (node_nf_conntrack_entries / node_nf_conntrack_entries_limit) \u003e 0.75 相关指标： node_nf_conntrack_entries：链接状态跟踪表分配的数量 node_nf_conntrack_entries_limit：表总量 NodeNetworkReceiveErrs 相关指标： node_network_receive_errs_total：接收错误总量 NodeNetworkTransmitErrs 网卡传输错误量。表达式： increase(node_network_transmit_errs_total[2m]) \u003e 10 相关指标： node_network_transmit_errs_total：传输错误总量 NodeFilesystemAlmostOutOfFiles inode 数量监测 表达式： ( node_filesystem_files_free{job=\"node-exporter\",fstype!=\"\"} / node_filesystem_files{job=\"node-exporter\",fstype!=\"\"} * 100 \u003c 5 and node_filesystem_readonly{job=\"node-exporter\",fstype!=\"\"} == 0 ) 相关指标： node_filesystem_files_free：空闲的 inode node_filesystem_files：inodes 总量 NodeFilesystemFilesFillingUp inode 耗尽预测，以6小时曲线变化预测接下来24小时和4小时可能使用的 inodes。表达式： (node_filesystem_files_free{job=\"node-exporter\",fstype!=\"\"} / node_filesystem_files{job=\"node-exporter\",fstype!=\"\"} * 100 \u003c 20 and predict_linear(node_filesystem_files_free{job=\"node-exporter\",fstype!=\"\"}[6h], 4*60*60) \u003c 0 and node_filesystem_readonly{job=\"node-exporter\",fstype!=\"\"} == 0) 相关指标： node_filesystem_files_free：空闲的 inode node_filesystem_files：inodes 总量 NodeFilesystemAlmostOutOfSpace 分区容量使用率。表达式： (node_filesystem_avail_bytes{job=\"node-exporter\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node-exporter\",fstype!=\"\"} * 100 \u003c 10 and node_filesystem_readonly{job=\"node-exporter\",fstype!=\"\"} == 0 ) 相关指标： node_filesystem_avail_bytes：空闲容量 node_filesystem_size_bytes：总容量 NodeFilesystemSpaceFillingUp 分区容量耗尽预测，以6小时曲线变化预测接下来24小时和4小时可能使用的容量。表达式： (node_filesystem_avail_bytes{job=\"node-exporter\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node-exporter\",fstype!=\"\"} * 100 \u003c 15 and predict_linear(node_filesystem_avail_bytes{job=\"node-exporter\",fstype!=\"\"}[6h], 4*60*60) \u003c 0 and node_filesystem_readonly{job=\"node-exporter\",fstype!=\"\"} == 0) 相关指标： node_filesystem_avail_bytes：空闲容量 node_filesystem_size_bytes：总容量 NodeMemAvaliable 物理节点可用内存。 表达式： sum(node_memory_MemAvailable_bytes / 1024/1024/1024) by (instance) NodeMemUsePresent 物理内存使用率。表达式： (sum((node_memory_MemTotal_bytes-node_memory_MemFree_bytes-node_memory_Buffers_bytes-node_memory_Cached_bytes-node_memory_Slab_bytes)/node_memory_MemTotal_bytes) by (instance))*100 \u003e 80 NodeCpuUsePresent 物理cpu使用率。表达式： 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) \u003e 80 NodeLoad 物理节点15分钟平均负载load15。表达式： sum (node_load15{instance=~\".*15.*\"}) by (instance) \u003e 10 sum (node_load15{instance!~\".*15.*\"}) by (instance) \u003e 20 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:8","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"Etcd相关 Etcdlived etcd 存活检测。表达式： up{job=\"etcd\"} \u003c 1 EtcdCluseterUnavailable etcd 集群健康检查，down 数量大于集群可允许故障数量。表达式： count(up{job=\"etcd\"} == 0) \u003e (count(up{job=\"etcd\"}) / 2 - 1) EtcdLeaderCheck 检查 leader。表达式： max(etcd_server_has_leader) != 1 EtcdBackendFsync etcd io 监测，后端提交 延时。表达式： histogram_quantile(0.99, sum(rate(etcd_disk_backend_commit_duration_seconds_bucket[5m])) by (instance, le)) \u003e 100 EtcdWalFsync etcd io 监测，文件同步到磁盘延时。表达式： histogram_quantile(0.99, sum(rate(etcd_disk_wal_fsync_duration_seconds_bucket[5m])) by (instance, le)) \u003e 100 EtcdDbSize 检测数据库大小。表达式： etcd_debugging_mvcc_db_total_size_in_bytes/1024/1024 \u003e 1024 EtcdGrpc Grpc 调用速率。表达式: sum(rate(grpc_server_handled_total{grpc_type=\"unary\"}[1m])) \u003e 100 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:9","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"CoreDNS 相关 DnsRequest DNS 查询速率，每分钟查询超过100告警。表达式： sum(irate(coredns_dns_request_count_total{zone !=\"dropped\"}[1m])) \u003e 100 相关指标： coredns_dns_request_count_total：总查询数 DnsRequestFaild 异常查询，异常状态码，不是 NOERROR。表达式： irate(coredns_dns_response_rcode_count_total{rcode!=\"NOERROR\"} [1m]) \u003e 0 相关指标： coredns_dns_response_rcode_count_total：查询返回状态码 DNS-Rcode： DNS-Rcode 作为 DNS 应答报文中有效的字段，主要用来说明 DNS 应答状态，是排查域名解析失败的重要指标。通常常见的 Rcode 值如下： Rcode 值为0，对应的 DNS 应答状态为 NOERROR，意思是成功的响应，即这个域名解析是成功 Rcode 值为2，对应的 DNS 应答状态为 SERVFAIL，意思是服务器失败，也就是这个域名的权威服务器拒绝响应或者响应 REFUSE，递归服务器返回 Rcode 值为 2 给 CLIENT Rcode 值为3，对应的 DNS 应答状态为 NXDOMAIN，意思是不存在的记录，也就是这个具体的域名在权威服务器中并不存在 Rcode 值为5，对应的 DNS 应答状态为 REFUSE，意思是拒绝，也就是这个请求源IP不在服务的范围内 DnsPanic DNS 恐慌值，可能收到攻击。表达式： irate(coredns_panic_count_total[1m]) \u003e100 ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:10","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["监控"],"content":"RabbitMq 相关 RabbitmqDown 监控 rabbitmq 服务，down 或者网络出现问题。表达式： absent(rabbitmq_up == 1) RabbitmqMessages 监控那些quese的message数量大于250，监控那些quese的message数量大于500。表达式： rabbitmq_queue_messages \u003e 250 rabbitmq_queue_messages \u003e 500 RabbitmqNotRunning 监控rabbitmq那些节点已经停止运行。表达式： rabbitmq_running != 1 RabbitmqQueueUnacknowledged 监控quese中消息未应答的数量，表达式 rabbitmq_queue_messages_unacknowledged \u003e 0 RabbitmqNodeDiskFree 监控rabbitmq可使用的磁盘空间大于5G的节点。表达式： sum(rabbitmq_node_disk_free /1024/1024/1024) by (node) \u003e5 RabbitmqFreeUsed 监控rabbitmq 使用的物理内存。表达式： sum(rabbitmq_node_mem_used /1024/1024) by (node) ","date":"2021-02-04","objectID":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/:1:11","tags":["Promethues"],"title":"Prometheus监控规则说明","uri":"/prometheus%E7%9B%91%E6%8E%A7%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E/"},{"categories":["中间件"],"content":"Nacos介绍及安装使用","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["中间件"],"content":"什么是Nacos ","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/:1:0","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["中间件"],"content":"Nacos 概览 Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 ","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/:1:1","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["中间件"],"content":"Nacos 功能 服务（Service）是 Nacos 世界的一等公民。Nacos 支持几乎所有主流类型的“服务”的发现、配置和管理： Kubernetes Service gRPC \u0026 Dubbo RPC Service Spring Cloud RESTful Service Nacos 的关键特性包括: 服务发现和服务健康监测 Nacos 支持基于 DNS 和基于 RPC 的服务发现。服务提供者使用 原生SDK、OpenAPI、或一个独立的Agent TODO注册 Service 后，服务消费者可以使用DNS TODO 或HTTP\u0026API查找和发现服务。 Nacos 提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层 (PING 或 TCP)和应用层 (如 HTTP、MySQL、用户自定义）的健康检查。 对于复杂的云环境和网络拓扑环境中（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了 agent 上报模式和服务端主动检测2种健康检查模式。Nacos 还提供了统一的健康检查仪表盘，帮助您根据健康状态管理服务的可用性及流量。 动态配置服务 动态配置服务可以让您以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。 动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。 配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。 Nacos 提供了一个简洁易用的UI (控制台样例 Demo) 帮助您管理所有的服务和应用的配置。Nacos 还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态跟踪在内的一系列开箱即用的配置管理特性，帮助您更安全地在生产环境中管理配置变更和降低配置变更带来的风险。 动态DNS服务 动态 DNS 服务支持权重路由，让您更容易地实现中间层负载均衡、更灵活的路由策略、流量控制以及数据中心内网的简单DNS解析服务。动态DNS服务还能让您更容易地实现以 DNS 协议为基础的服务发现，以帮助您消除耦合到厂商私有服务发现 API 上的风险。 Nacos 提供了一些简单的 DNS APIs TODO 帮助您管理服务的关联域名和可用的 IP:PORT 列表. 服务及其元数据管理 Nacos 能让您从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。 ","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/:1:2","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["中间件"],"content":"Nacos 架构 服务 (Service) 服务是指一个或一组软件功能（例如特定信息的检索或一组操作的执行），其目的是不同的客户端可以为不同的目的重用（例如通过跨进程的网络调用）。Nacos 支持主流的服务生态，如 Kubernetes Service、gRPC|Dubbo RPC Service 或者 Spring Cloud RESTful Service. 服务注册中心 (Service Registry) 服务注册中心，它是服务，其实例及元数据的数据库。服务实例在启动时注册到服务注册表，并在关闭时注销。服务和路由器的客户端查询服务注册表以查找服务的可用实例。服务注册中心可能会调用服务实例的健康检查 API 来验证它是否能够处理请求。 服务元数据 (Service Metadata) 服务元数据是指包括服务端点(endpoints)、服务标签、服务版本号、服务实例权重、路由规则、安全策略等描述服务的数据 服务提供方 (Service Provider) 是指提供可复用和可调用服务的应用方 服务消费方 (Service Consumer) 是指会发起对某个服务调用的应用方 配置 (Configuration) 在系统开发过程中通常会将一些需要变更的参数、变量等从代码中分离出来独立管理，以独立的配置文件的形式存在。目的是让静态的系统工件或者交付物（如 WAR，JAR 包等）更好地和实际的物理运行环境进行适配。配置管理一般包含在系统部署的过程中，由系统管理员或者运维人员完成这个步骤。配置变更是调整系统运行时的行为的有效手段之一。 配置管理 (Configuration Management) 在数据中心中，系统中所有配置的编辑、存储、分发、变更管理、历史版本管理、变更审计等所有与配置相关的活动统称为配置管理。 名字服务 (Naming Service) 提供分布式系统中所有对象(Object)、实体(Entity)的“名字”到关联的元数据之间的映射管理服务，例如 ServiceName -\u003e Endpoints Info, Distributed Lock Name -\u003e Lock Owner/Status Info, DNS Domain Name -\u003e IP List, 服务发现和 DNS 就是名字服务的2大场景。 配置服务 (Configuration Service) 在服务或者应用运行过程中，提供动态配置或者元数据以及配置管理的服务提供者。 逻辑架构及其组件 服务管理：实现服务CRUD，域名CRUD，服务健康状态检查，服务权重管理等功能 配置管理：实现配置管CRUD，版本管理，灰度管理，监听管理，推送轨迹，聚合数据等功能 元数据管理：提供元数据CURD 和打标能力 插件机制：实现三个模块可分可合能力，实现扩展点SPI机制 事件机制：实现异步化事件通知，sdk数据变化异步通知等逻辑 日志模块：管理日志分类，日志级别，日志可移植性（尤其避免冲突），日志格式，异常码+帮助文档 回调机制：sdk通知数据，通过统一的模式回调用户处理。接口和数据结构需要具备可扩展性 寻址模式：解决ip，域名，nameserver、广播等多种寻址模式，需要可扩展 推送通道：解决server与存储、server间、server与sdk间推送性能问题 容量管理：管理每个租户，分组下的容量，防止存储被写爆，影响服务可用性 流量管理：按照租户，分组等多个维度对请求频率，长链接个数，报文大小，请求流控进行控制 缓存机制：容灾目录，本地缓存，server缓存机制。容灾目录使用需要工具 启动模式：按照单机模式，配置模式，服务模式，dns模式，或者all模式，启动不同的程序+UI 一致性协议：解决不同数据，不同一致性要求情况下，不同一致性机制 存储模块：解决数据持久化、非持久化存储，解决数据分片问题 Nameserver：解决namespace到clusterid的路由问题，解决用户环境与nacos物理环境映射问题 CMDB：解决元数据存储，与三方cmdb系统对接问题，解决应用，人，资源关系 Metrics：暴露标准metrics数据，方便与三方监控系统打通 Trace：暴露标准trace，方便与SLA系统打通，日志白平化，推送轨迹等能力，并且可以和计量计费系统打通 接入管理：相当于阿里云开通服务，分配身份、容量、权限过程 用户管理：解决用户管理，登录，sso等问题 权限管理：解决身份识别，访问控制，角色管理等问题 审计系统：扩展接口方便与不同公司审计系统打通 通知系统：核心数据变更，或者操作，方便通过SMS系统打通，通知到对应人数据变更 OpenAPI：暴露标准Rest风格HTTP接口，简单易用，方便多语言集成 Console：易用控制台，做服务管理、配置管理等操作 SDK：多语言sdk Agent：dns-f类似模式，或者与mesh等方案集成 CLI：命令行对产品进行轻量化管理，像git一样好用 ","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/:1:3","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["中间件"],"content":"Nacos 部署 集群部署架构图 http://ip1:port/openAPI 直连ip模式，机器挂则需要修改ip才可以使用。 http://VIP:port/openAPI 挂载VIP模式，直连vip即可，下面挂server真实ip，可读性不好。 http://nacos.com:port/openAPI 域名 + VIP模式，可读性好，而且换ip方便，推荐模式 安装 # helm repo 下载 helm pull aliyuncs/nacos # 配置values ## 修改模式为集群模式 global: #mode: quickstart #mode: standalone mode: cluster ## 添加sc提供数据存储 persistence: enabled: false existingClaim: mysql-slave-data #existingClaim: claim: name: mysql-slave-data spec: accessModes: - ReadWriteOnce resources: requests: storage: 5G storageClassName: sc-mysql-slave ## 修改副本数 replicaCount: 3 ## 利用阿里云nas动态卷创建sc apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: annotations: meta.helm.sh/release-name: nacos meta.helm.sh/release-namespace: middleware labels: app.kubernetes.io/managed-by: Helm name: alibabacloud-nas-nacos mountOptions: - nolock,tcp,noresvport - vers=3 parameters: server: nas_server:/nacos/ volumeAs: subpath provisioner: nasplugin.csi.alibabacloud.com reclaimPolicy: Delete volumeBindingMode: Immediate # 配置mysql数据源 ## mysql 高可用集群，db.num配置为1 ng server.servlet.contextPath=${SERVER_SERVLET_CONTEXTPATH:/nacos} server.contextPath=/nacos server.port=${NACOS_APPLICATION_PORT:8848} spring.datasource.platform=${SPRING_DATASOURCE_PLATFORM:\"\"} nacos.cmdb.dumpTaskInterval=3600 nacos.cmdb.eventTaskInterval=10 nacos.cmdb.labelTaskInterval=300 nacos.cmdb.loadDataAtStart=false db.num=${MYSQL_DATABASE_NUM:1} db.url.0=jdbc:mysql://${MYSQL_SERVICE_HOST}:${MYSQL_SERVICE_PORT:3306}/${MYSQL_SERVICE_DB_NAME}?${MYSQL_SERVICE_DB_PARAM:characterEncoding=utf8\u0026connectTimeout=1000\u0026socketTimeout=3000\u0026autoReconnect=true} db.url.1=jdbc:mysql://${MYSQL_SERVICE_HOST}:${MYSQL_SERVICE_PORT:3306}/${MYSQL_SERVICE_DB_NAME}?${MYSQL_SERVICE_DB_PARAM:characterEncoding=utf8\u0026connectTimeout=1000\u0026socketTimeout=3000\u0026autoReconnect=true} db.user=${MYSQL_SERVICE_USER} db.password=${MYSQL_SERVICE_PASSWORD} # 安装 helm upgrade --install nacos aliyun/nacos -n ddyw-mmeber-test --debug 初始化数据库 /* * Copyright 1999-2018 Alibaba Group Holding Ltd. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info */ /******************************************/ CREATE TABLE `config_info` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(255) DEFAULT NULL, `content` longtext NOT NULL COMMENT 'content', `md5` varchar(32) DEFAULT NULL COMMENT 'md5', `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间', `src_user` text COMMENT 'source user', `src_ip` varchar(50) DEFAULT NULL COMMENT 'source ip', `app_name` varchar(128) DEFAULT NULL, `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段', `c_desc` varchar(256) DEFAULT NULL, `c_use` varchar(64) DEFAULT NULL, `effect` varchar(64) DEFAULT NULL, `type` varchar(64) DEFAULT NULL, `c_schema` text, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_aggr */ /******************************************/ CREATE TABLE `config_info_aggr` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` varchar(255) NOT NULL COMMENT 'data_id', `group_id` varchar(255) NOT NULL COMMENT 'group_id', `datum_id` varchar(255) NOT NULL COMMENT 'datum_id","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/:1:4","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["中间件"],"content":"Nacos 应用 接入dubbo 项目结构如下： provider 服务提供者 引入依赖 \u003c!-- 使用 Nacos 作为注册中心 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.nacos\u003c/groupId\u003e \u003cartifactId\u003enacos-client\u003c/artifactId\u003e \u003cversion\u003e1.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.dubbo\u003c/groupId\u003e \u003cartifactId\u003edubbo-registry-nacos\u003c/artifactId\u003e \u003cversion\u003e2.7.5\u003c/version\u003e \u003c/dependency\u003e # 完整pom文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.4.2\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003euser-service-provider\u003c/artifactId\u003e \u003cdependencies\u003e \u003c!-- 引入定义的 Dubbo API 接口 --\u003e \u003cdependency\u003e \u003cgroupId\u003etop.mikel.springboot.users\u003c/groupId\u003e \u003cartifactId\u003euser-service-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 引入 Spring Boot 依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- 实现对 Dubbo 的自动化配置 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.dubbo\u003c/groupId\u003e \u003cartifactId\u003edubbo\u003c/artifactId\u003e \u003cversion\u003e2.7.5\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.dubbo\u003c/groupId\u003e \u003cartifactId\u003edubbo-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.7.5\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 使用 Zookeeper 作为注册中心 --\u003e \u003c!-- \u003cdependency\u003e--\u003e \u003c!-- \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e--\u003e \u003c!-- \u003cartifactId\u003ecurator-framework\u003c/artifactId\u003e--\u003e \u003c!-- \u003cversion\u003e2.13.0\u003c/version\u003e--\u003e \u003c!-- \u003c/dependency\u003e--\u003e \u003c!-- \u003cdependency\u003e--\u003e \u003c!-- \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e--\u003e \u003c!-- \u003cartifactId\u003ecurator-recipes\u003c/artifactId\u003e--\u003e \u003c!-- \u003cversion\u003e2.13.0\u003c/version\u003e--\u003e \u003c!-- \u003c/dependency\u003e--\u003e\u003c!-- 使用 Nacos 作为注册中心 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.nacos\u003c/groupId\u003e \u003cartifactId\u003enacos-client\u003c/artifactId\u003e \u003cversion\u003e1.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.dubbo\u003c/groupId\u003e \u003cartifactId\u003edubbo-registry-nacos\u003c/artifactId\u003e \u003cversion\u003e2.7.5\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 修改配置文件 # dubbo 配置项，对应 DubboConfigurationProperties 配置类 dubbo: # Dubbo 应用配置 application: name: user-service-provider # 应用名 # Dubbo 注册中心配 registry: address: nacos://127.0.0.1:8848 # 注册中心地址。个鞥多注册中心，可见 http://dubbo.apache.org/zh-cn/docs/user/references/registry/introduction.html 文档。 # Dubbo 服务提供者协议配置 protocol: port: -1 # 协议端口。使用 -1 表示随机端口。 name: dubbo # 使用 `dubbo://` 协议。更多协议，可见 http://dubbo.apache.org/zh-cn/docs/user/references/protocol/introduction.html 文档 # Dubbo 服务提供者配置 provider: timeout: 1000 # 【重要】远程服务调用超时时间，单位：毫秒。默认为 1000 毫秒，胖友可以根据自己业务修改 UserRpcService: version: 1.0.0 # 配置扫描 Dubbo 自定义的 @Service 注解，暴露成 Dubbo 服务提供者 scan: base-packages: top.mikel.springboot.users.service.service consumer 消费者 引入依赖 \u003c!-- 使用 Nacos 作为注册中心 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.nacos\u003c/groupId\u003e \u003cartifactId\u003enacos-client\u003c/artifactId\u003e \u003cversion\u003e1.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.dubbo\u003c/groupId\u003e \u003cartifactId\u003edubbo-registry-nacos\u003c/artifactId\u003e \u003cversion\u003e2.7.5\u003c/version\u003e \u003c/dependency\u003e # 完整pom文件 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.4.2\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003euser-service-consumer\u003c/artifactId\u003e \u003cdependencies\u003e \u003c!-- 引入定义的 Dubbo API 接口 --\u003e \u003cdependency\u003e \u003cgroupId\u003etop.mikel.springboot.users\u003c/groupId\u003e \u003cartifactId\u003euser-service-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 引入 Spring Boot 依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artif","date":"2021-02-04","objectID":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/:1:5","tags":["nacos"],"title":"Nacos介绍及安装使用","uri":"/nacos%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/"},{"categories":["CICD"],"content":"Jenkins安装","date":"2021-02-04","objectID":"/jenkins%E5%AE%89%E8%A3%85/","tags":["jenkins"],"title":"Jenkins安装","uri":"/jenkins%E5%AE%89%E8%A3%85/"},{"categories":["CICD"],"content":"jenkins简介 Jenkins是一个自包含的开源自动化服务器，可用于自动化与构建，测试以及交付或部署软件有关的各种任务。 Jenkins可以通过本机系统软件包Docker安装，甚至可以由安装了Java Runtime Environment（JRE）的任何计算机独立运行。 ","date":"2021-02-04","objectID":"/jenkins%E5%AE%89%E8%A3%85/:0:1","tags":["jenkins"],"title":"Jenkins安装","uri":"/jenkins%E5%AE%89%E8%A3%85/"},{"categories":["CICD"],"content":"jenkins安装 # 物理机安装 ## 安装java环境 wget https://download.oracle.com/otn/java/jdk/8u261-b12/a4634525489241b9a9e1aa73d9e118e6/jdk-8u261-linux-x64.tar.gz?AuthParam=1597552691_67429c142927b21fadba4cd7de9df6e5 mv jdk-8u261-linux-x64.tar.gz?AuthParam=1597552691_67429c142927b21fadba4cd7de9df6e5 jdk-8u261-linux-x64.tar.gz tar zxvf jdk-8u261-linux-x64.tar.gz -C /usr/local tee \u003e /etc/profile.d/jdk.sh \u003c\u003c- 'EOF' export JAVA_HOME=/usr/local/jdk1.8.0_261 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH EOF source /etc/profile ## 安装jenkins wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key yum clean all yum makecache yum install jenkins -y ### 无法拉取官方源 yum install -y https://mirrors.tuna.tsinghua.edu.cn/jenkins/redhat-stable/jenkins-2.235.4-1.1.noarch.rpm ### 修改配置 sed -i 's/^JENKINS_USER/#JENKINS_USER/' /etc/sysconfig/jenkins sed -i 's/^JENKINS_HOME/#JENKINS_HOME/' /etc/sysconfig/jenkins sed -i 's/^JENKINS_PORT/#JENKINS_PORT/' /etc/sysconfig/jenkins tee \u003e\u003e /etc/sysconfig/jenkins \u003c\u003c- 'EOF' # jenkins configurage JENKINS_JAVA_OPTIONS=\"-Djava.awt.headless=true -Dorg.jenkinsci.plugins.gitclient.Git.timeOut=60\" JENKINS_USER=\"root\" JENKINS_HOME=\"/data/jenkins\" JENKINS_PORT=\"8080\" EOF sed -i '/candidates/a\\/usr/local/jdk1.8.0_221/bin/java' /etc/init.d/jenkins systemctl enable jenkins mkdir -pv /data/jenkins systemctl start jenkins ### 修改默认镜像源 cp /data/jenkins/hudson.model.UpdateCenter.xml /data/jenkins/hudson.model.UpdateCenter.xml.bak tee \u003e /data/jenkins/hudson.model.UpdateCenter.xml \u003c\u003c- 'EOF' \u003c?xml version='1.1' encoding='UTF-8'?\u003e \u003csites\u003e \u003csite\u003e \u003cid\u003edefault\u003c/id\u003e \u003curl\u003ehttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\u003c/url\u003e \u003c/site\u003e \u003c/sites\u003e EOF ## 访问 cat /data/jenkins/secrets/initialAdminPassword curl -v http://localhost:8080 # docker 安装 ## 制作镜像 tee \u003e Dockerfile \u003c\u003c- 'EOF' FROM jenkins/jenkins ARG dockerGid=999 ENV JENKINS_HOME=/data/jenkins USER root #清除了基础镜像设置的源，切换成腾讯云的阿里云源 RUN echo '' \u003e /etc/apt/sources.list.d/jessie-backports.list \\ \u0026\u0026 echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" \u003e /etc/apt/sources.list \\ \u0026\u0026 echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" \u003e\u003e /etc/apt/sources.list \\ \u0026\u0026 echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" \u003e\u003e /etc/apt/sources.list \\ \u0026\u0026 apt-get update \u0026\u0026 apt-get install -y libltdl7 \u0026\u0026 apt-get update \\ \u0026\u0026 echo \"docker❌${dockerGid}:jenkins\" \u003e\u003e /etc/group \\ \u0026\u0026 curl -L https://github.com/docker/compose/releases/download/1.26.2/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose \\ \u0026\u0026 chmod +x /usr/local/bin/docker-compose EOF ## 启动jenkins chown -R 1000 /data/jenkins docker run --name jenkins \\ -p 8080:8080 \\ -p 50000:50000 \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v $(which docker):/bin/docker \\ -v /data/jenkins:/data/jenkins \\ -v /etc/localtime:/etc/localtime \\ -d auto-jenkins ","date":"2021-02-04","objectID":"/jenkins%E5%AE%89%E8%A3%85/:0:2","tags":["jenkins"],"title":"Jenkins安装","uri":"/jenkins%E5%AE%89%E8%A3%85/"},{"categories":["CICD"],"content":"常用插件安装 Build Monitor View Workspace Cleanup Disk Usage Multijob plugin Build Pipeline Plugin：灰度发布 Mask Passwords Plugin：密码加密 Configuration Slicing Plugin：批量修改JOB的配置 BlueOcean Locale Zentimestamp plugin multibranch-scan-webhook-trigger Structs Pipeline: Step API Token Macro Build Timeout Credentials Plain Credentials SSH Credentials Credentials Binding SCM API Pipeline: API Timestamper Pipeline: Supporting APIs Pipeline: Nodes and Processes Snakeyaml API Jackson 2 API ECharts API JUnit Matrix Project Workspace Cleanup Ant Pipeline: SCM Step Pipeline: Groovy Pipeline: Job Pipeline: Basic Steps Gradle Pipeline: Milestone Step Pipeline: Input Step Pipeline: Stage Step Pipeline Graph Analysis Pipeline: REST API Pipeline: Stage View Pipeline: Build Step Pipeline: Model API Pipeline: Declarative Extension Points API JSch dependency Git client GIT server Pipeline: Shared Groovy Libraries Branch API Pipeline: Multibranch Pipeline: Stage Tags Metadata Pipeline: Declarative Lockable Resources Pipeline GitHub API GitHub Branch Source Pipeline: GitHub Groovy Libraries Pipeline: Stage View Git SSH Build Agents Email Extension ECharts API JUnit Matrix Project ","date":"2021-02-04","objectID":"/jenkins%E5%AE%89%E8%A3%85/:0:3","tags":["jenkins"],"title":"Jenkins安装","uri":"/jenkins%E5%AE%89%E8%A3%85/"},{"categories":["CICD"],"content":"jenkinsfile脱离代码仓库 安装插件 1、Config File Provider Plugin 2、Pipeline: Multibranch with defaults 配置jenkins // 添加default jenkinsfile #!/usr/bin/env groovy import groovy.transform.Field @Field def job_name=\"\" node() { environment { PATH = \"/usr/local/git/bin:$PATH\" } job_name=\"${env.JOB_NAME}\".replace('%2F','/').split('/') job_name=job_name[0] workspace=\"/data/jenkins/workspace/CICD\" ws(\"$workspace\") { dir('Cnblog') { git url: 'https://github.com/MikelPan/Cnblog.git' def check_groovy_file=\"kubernetes/CICD/Jenkinsfile/${job_name}/${env.BRANCH_NAME}/Jenkinsfile.groovy\" load \"${check_groovy_file}\" } } } // 在项目根目录中实现如下结构 ---Cnblog ---master ---Jenkinsfile ","date":"2021-02-04","objectID":"/jenkins%E5%AE%89%E8%A3%85/:0:4","tags":["jenkins"],"title":"Jenkins安装","uri":"/jenkins%E5%AE%89%E8%A3%85/"},{"categories":["CICD"],"content":"jenkins 忘记管理员密码 # 删除jenkins目录中的config.xml中的下面部分 \u003cuseSecurity\u003etrue\u003c/useSecurity\u003e \u003cauthorizationStrategy class=\"hudson.security.FullControlOnceLoggedInAuthorizationStrategy\"\u003e \u003cdenyAnonymousReadAccess\u003etrue\u003c/denyAnonymousReadAccess\u003e \u003c/authorizationStrategy\u003e \u003csecurityRealm class=\"hudson.security.HudsonPrivateSecurityRealm\"\u003e \u003cdisableSignup\u003etrue\u003c/disableSignup\u003e \u003cenableCaptcha\u003efalse\u003c/enableCaptcha\u003e \u003c/securityRealm\u003e # 重启Jenkins服务； # 进入首页\u003e“系统管理”\u003e“Configure Global Security”； # 勾选“启用安全”； # 点选“Jenkins专有用户数据库”，并点击“保存”； # 重新点击首页\u003e“系统管理”,发现此时出现“管理用户”； # 点击进入展示“用户列表”； # 点击右侧进入修改密码页面，修改后即可重新登录 ","date":"2021-02-04","objectID":"/jenkins%E5%AE%89%E8%A3%85/:0:5","tags":["jenkins"],"title":"Jenkins安装","uri":"/jenkins%E5%AE%89%E8%A3%85/"},{"categories":["监控"],"content":"Prometheus_operator使用","date":"2021-02-04","objectID":"/promethues_operator%E4%BD%BF%E7%94%A8/","tags":["Promethues"],"title":"Promethues_operator使用","uri":"/promethues_operator%E4%BD%BF%E7%94%A8/"},{"categories":["监控"],"content":"Prometheus Operator 使用 安装 最新的版本官方将资源https://github.com/coreos/prometheus-operator/tree/master/contrib/kube-prometheus迁移到了独立的 git 仓库中：https://github.com/coreos/kube-prometheus.git 克隆最新的代码： git clone https://github.com/coreos/kube-prometheus.git 进入到 manifests 目录下面，这个目录下面包含所有的资源清单文件，需要对其中的文件 prometheus-serviceMonitorKubelet.yaml 进行简单的修改： 将https-metrics改为http-metrics 创建对应的资源 kubectl apply -f maifests/* 告警配置 删除掉官方的告警secreet,配置对应的告警secret,yaml文件如下： cat \u003e alertmanager.yaml \u003c\u003cEOFglobal:resolve_timeout:5msmtp_smarthost:'xxxxxx'smtp_from:'xxxxxxxx'smtp_auth_username:'xxxxxxx'smtp_auth_password:'xxxxxxx'smtp_hello:'xxxxx'smtp_require_tls:falseroute:group_by:['job','alertname','severity']group_wait:30sgroup_interval:5mrepeat_interval:5hreceiver:defaultroutes:- match:alertname:CPUThrottlingHighreceiver:defaultmatch_re:alertname:^(severity|warring)$receiver:webhookreceivers:- name:'default'email_configs:- to:'xxxxxxx'send_resolved:true- name:'webhook'webhook_configs:- url:'https://oapi.dingtalk.com/robot/send?access_token=8512095dcbf2777d5521f556668a1f0c3df62737f6e244c868197f5bexxxxx'send_resolved:trueEOF 生成新的告警文件 cat \u003e reset_alertmanager_config.sh \u003c\u003cEOF kubectl delete secret alertmanager-main -n monitoring kubectl create secret generic alertmanager-main --from-file=alertmanager.yaml -n monitoring kubectl delete -f alertmanager-alertmanager.yaml;kubectl create -f alertmanager-alertmanager.yaml EOF 由于默认没有生成对应的kube-controller-manager和kube-scheduler的service,所以需要手动添加service 监控kube-controller-manager 添加kube-controller-manager的监控service文件： cat \u003e prometheus-kubeControllerManagerService.yaml \u003c\u003cEOFapiVersion:v1kind:Servicemetadata:namespace:kube-systemname:kube-controller-managerlabels:k8s-app:kube-controller-managerspec:selector:component:kube-controller-managerports:- name:http-metricsport:10251targetPort:10251protocol:TCPEOF 监控 kube-scheduler 添加监控kube-scheduler的监控yaml文件 cat \u003e prometheus-kubeSchedulerService.yaml \u003c\u003cEOFapiVersion:v1kind:Servicemetadata:namespace:kube-systemname:kube-schedulerlabels:k8s-app:kube-schedulerspec:selector:component:kube-schedulerports:- name:http-metricsport:10251targetPort:10251protocol:TCPEOF 监控etcd 由于etcd 使用的证书都对应在节点的 /etc/kubernetes/pki/etcd 这个路径下面，所以首先我们将需要使用到的证书通过 secret 对象保存到集群中去：(在 etcd 运行的节点) 创建etcd secret kubectl -n monitoring create secret generic etcd-certs --from-file=/etc/kubernetes/pki/etcd/healthcheck-client.crt --from-file=/etc/kubernetes/pki/etcd/healthcheck-client.key --from-file=/etc/kubernetes/pki/etcd/ca.crt 然后将上面创建的 etcd-certs 对象配置到 prometheus 资源对象中，直接更新 prometheus 资源对象即可 nodeSelector:kubernetes.io/os:linuxpodMonitorSelector:{}replicas:2secrets:- etcd-certs 创建 ServiceMonitor 现在 Prometheus 访问 etcd 集群的证书已经准备好了，接下来创建 ServiceMonitor 对象即可（prometheus-serviceMonitorEtcd.yaml） cat \u003e prometheus-serviceMonitorEtcd.yaml \u003c\u003cEOFapiVersion:monitoring.coreos.com/v1kind:ServiceMonitormetadata:name:etcd-k8snamespace:monitoringlabels:k8s-app:etcdspec:jobLabel:etcdendpoints:- port:portinterval:30sscheme:httpstlsConfig:caFile:/etc/prometheus/secrets/etcd-certs/ca.crtcertFile:/etc/prometheus/secrets/etcd-certs/healthcheck-client.crtkeyFile:/etc/prometheus/secrets/etcd-certs/healthcheck-client.keyinsecureSkipVerify:trueselector:matchLabels:k8s-app:etcdnamespaceSelector:matchNames:- kube-systemEOF 创建Service ServiceMonitor 创建完成了，但是现在还没有关联的对应的 Service 对象，所以需要我们去手动创建一个 Service 对象（prometheus-etcdService.yaml） etcd 部署到k8s 集群中 cat \u003e prometheus-etcdService.yaml \u003c\u003cEOFapiVersion:v1kind:Servicemetadata:name:etcd-k8snamespace:kube-systemlabels:k8s-app:etcdspec:selector:component:etcdtype:ClusterIPclusterIP:Noneports:- name:portport:2379protocol:TCPEOF etcd 部署到外部集群 cat \u003e prometheus-etcdService.yaml \u003c\u003cEOFapiVersion:v1kind:Servicemetadata:name:etcd-k8snamespace:kube-systemlabels:component:etcdspec:type:ClusterIPclusterIP:Noneports:- name:portport:2379protocol:TCP---apiVersion:v1kind:Endpointsmetadata:name:etcd-k8snamespace:kube-systemlabels:k8s-app:etcdsubsets:- addresses:- ip:172.18.12.14nodeName:pre-etcd-masterports:- name:portport:","date":"2021-02-04","objectID":"/promethues_operator%E4%BD%BF%E7%94%A8/:1:0","tags":["Promethues"],"title":"Promethues_operator使用","uri":"/promethues_operator%E4%BD%BF%E7%94%A8/"},{"categories":["监控"],"content":"Promethues监控k8s集群组件","date":"2021-02-04","objectID":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/","tags":["Promethues"],"title":"Promethues监控k8s集群组件","uri":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/"},{"categories":["监控"],"content":"容器监控 cAdvisor已经内置在了 kubelet 组件之中，所以不需要单独去安装，cAdvisor的数据路径为/api/v1/nodes//proxy/metrics，同样这里使用 node 的服务发现模式，因为每一个节点下面都有 kubelet，自然都有cAdvisor采集到的数据指标，配置如下： cat \u003e prometheus-cm.yaml\u003c\u003cEOFapiVersion:v1kind:ConfigMapmetadata:name:prometheus-confignamespace:monitoringdata:prometheus.yml:|global: scrape_interval: 15s scrape_timeout: 15s scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'kubernetes-nodes' kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__address__] regex: '(.*):10250' replacement: '${1}:9100' target_label: __address__ action: replace - action: labelmap regex: __meta_kubernetes_node_label_(.+) - job_name: 'kubelet' kubernetes_sd_configs: - role: node scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - job_name: 'kubernetes-cadvisor' kubernetes_sd_configs: - role: node scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisorEOF 上面的配置和之前配置 node-exporter 的时候几乎是一样的，区别是这里使用了 https 的协议，另外需要注意的是配置了 ca.cart 和 token 这两个文件，这两个文件是 Pod 启动后自动注入进来的，通过这两个文件可以在 Pod 中访问 apiserver，比如这里的__address__不在是 nodeip 了，而是 kubernetes 在集群中的服务地址，然后加上__metrics_path__的访问路径：/api/v1/nodes/${1}/proxy/metrics/cadvisor，现在同样更新下配置，然后查看 Targets 路径： apiserver监控 apiserver 作为 Kubernetes 最核心的组件，当然他的监控也是非常有必要的，对于 apiserver 的监控我们可以直接通过 kubernetes 的 Service 来获取： # kubectl get svc -n default NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 92d 上面这个 Service 就是集群的 apiserver 在集群内部的 Service 地址，要自动发现 Service 类型的服务，就需要用到 role 为 Endpoints 的 kubernetes_sd_configs，可以在 ConfigMap 对象中添加上一个 Endpoints 类型的服务的监控任务,需要过滤的服务是 default 这个 namespace 下面，服务名为 kubernetes 的元数据，所以这里我们就可以根据对应的__meta_kubernetes_namespace和__meta_kubernetes_service_name这两个元数据来 relabel,另外由于 kubernetes 这个服务对应的端口是443，需要使用 https 协议，所以这里我们需要使用 https 的协议，对应的就需要将对应的 ca 证书配置上，如下： 查看配置的job: - job_name:'kubernetes-apiservers'kubernetes_sd_configs:- role:endpointsscheme:httpstls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtbearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokenrelabel_configs:- source_labels:[__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]action:keepregex:default;kubernetes;https 现在重新更新配置文件、重新加载 Prometheus，切换到 Prometheus 的 Targets 路径下查看： kube-contraller监控 - job_name:'kubernetes-schedule'#任务名scrape_interval:5s #本任务的抓取间隔，覆盖全局配置static_configs:- targets:['xxxxx:10251'] kube-schedule监控 - job_name:'kubernetes-control-manager'scrape_interval:5sstatic_configs:- targets:['xxxxx:10252'] endpoints监控 查看配置文件 cat \u003e prometheus-cm.yaml\u003c\u003cEOFapiVersion:v1kind:ConfigMapmetadata:name:prometheus-confignamespace:monitoringdata:prometheus.yml:|global: scrape_interval: 15s scrape_timeout: 15s scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'kubernetes-nodes' kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__address__] regex: '(.*):10250' replacement: '${1}:9100' target_label: __address__ action: replace - action: labelmap regex: __meta_kubernetes_node_label_(.+) - job_name: 'kubernetes-kubelet' kubernetes_sd_configs: - role: node scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - action: labelmap regex: __meta_kubernet","date":"2021-02-04","objectID":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/:0:0","tags":["Promethues"],"title":"Promethues监控k8s集群组件","uri":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E7%BB%84%E4%BB%B6/"},{"categories":["监控"],"content":"Promethues监控k8s集群节点","date":"2021-02-04","objectID":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9/","tags":["Promethues"],"title":"Promethues监控k8s集群节点","uri":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9/"},{"categories":["监控"],"content":"监控k8s 集群节点 对于集群的监控一般我们需要考虑以下几个方面： Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标 内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、kubedns/coredns 等组件的详细运行状态 编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标 Kubernetes 集群的监控方案目前主要有以下几种方案： cAdvisor：cAdvisor是Google开源的容器资源监控和性能分析工具，它是专门为容器而生，本身也支持 Docker 容器，在 Kubernetes 中，我们不需要单独去安装，cAdvisor 作为 kubelet 内置的一部分程序可以直接使用。 Kube-state-metrics：kube-state-metrics通过监听 API Server 生成有关资源对象的状态指标，比如 Deployment、Node、Pod，需要注意的是 kube-state-metrics 只是简单提供一个 metrics 数据，并不会存储这些指标数据，所以我们可以使用 Prometheus 来抓取这些数据然后存储。 metrics-server：metrics-server 也是一个集群范围内的资源数据聚合工具，是 Heapster 的替代品，同样的，metrics-server 也只是显示数据，并不提供数据存储服务。 不过 kube-state-metrics 和 metrics-server 之间还是有很大不同的，二者的主要区别如下： kube-state-metrics 主要关注的是业务相关的一些元数据，比如 Deployment、Pod、副本状态等 metrics-server 主要关注的是资源度量 API 的实现，比如 CPU、文件描述符、内存、请求延时等指标。 集群节点监控 这里通过 Prometheus 来采集节点的监控指标数据，可以通过node_exporter来获取，顾名思义，node_exporter 就是抓取用于采集服务器节点的各种运行指标，目前 node_exporter 支持几乎所有常见的监控点，比如 conntrack，cpu，diskstats，filesystem，loadavg，meminfo，netstat等，详细的监控点列表可以参考其Github repo 可以通过 DaemonSet 控制器来部署该服务，这样每一个节点都会自动运行一个这样的 Pod，如果从集群中删除或者添加节点后，也会进行自动扩展. 在部署 node-exporter 的时候有一些细节需要注意，如下资源清单文件：(prome-node-exporter.yaml) cat \u003e prome-node-exporter.yaml \u003c\u003cEOFapiVersion:extensions/v1beta1kind:DaemonSetmetadata:name:node-exporternamespace:monitoringlabels:name:node-exporterspec:template:metadata:labels:name:node-exporterspec:hostPID:truehostIPC:truehostNetwork:truecontainers:- name:node-exporterimage:prom/node-exporter:v0.18.1ports:- containerPort:9100resources:requests:cpu:0.15securityContext:privileged:trueargs:- --path.procfs- /host/proc- --path.sysfs- /host/sys- --collector.filesystem.ignored-mount-points- '\"^/(sys|proc|dev|host|etc)($|/)\"'volumeMounts:- name:devmountPath:/host/dev- name:procmountPath:/host/proc- name:sysmountPath:/host/sys- name:rootfsmountPath:/rootfstolerations:- key:\"node-role.kubernetes.io/master\"operator:\"Exists\"effect:\"NoSchedule\"volumes:- name:prochostPath:path:/proc- name:devhostPath:path:/dev- name:syshostPath:path:/sys- name:rootfshostPath:path:/EOF 由于要获取到的数据是主机的监控指标数据，而node-exporter 是运行在容器中的，所以在 Pod 中需要配置一些 Pod 的安全策略，这里就添加了hostPID: true、hostIPC: true、hostNetwork: true3个策略，用来使用主机的 PID namespace、IPC namespace 以及主机网络，这些 namespace 就是用于容器隔离的关键技术，要注意这里的 namespace 和集群中的 namespace 是两个完全不相同的概念。 另外还将主机的/dev、/proc、/sys这些目录挂载到容器中，这些因为采集的很多节点数据都是通过这些文件夹下面的文件来获取到的，比如在使用top命令可以查看当前cpu使用情况，数据就来源于文件/proc/stat，使用free命令可以查看当前内存使用情况，其数据来源是来自/proc/meminfo文件. 然后直接创建上面的资源对象即可： kubectl create -f prome-node-exporter.yaml kubectl get pods -n monitoring -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES node-exporter-q7xnc 1/1 Running 0 40s 172.18.12.19 saas-pre-master-dist-sz-01 \u003cnone\u003e \u003cnone\u003e node-exporter-rbfrz 1/1 Running 0 40s 172.18.12.20 saas-pre-node-dist-sz-01 \u003cnone\u003e \u003cnone\u003e node-exporter-zvlmz 1/1 Running 0 40s 172.18.143.48 saas-pre-node-dist-sz-02 \u003cnone\u003e \u003cnone\u003e prometheus-7cb9f4dc8d-g9x75 1/1 Running 0 25m 10.0.2.134 saas-pre-node-dist-sz-02 \u003cnone\u003e \u003cnone\u003e 部署完成后，可以看到在3个节点上都运行了一个 Pod，应该怎样去获取/metrics数据呢？上面是不是指定了hostNetwork=true，所以在每个节点上就会绑定一个端口 9100，可以通过这个端口去获取到监控指标数据： # curl 127.0.0.1:9100/metrics | head -n 20 # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 1.1498e-05 go_gc_duration_seconds{quantile=\"0.25\"} 1.475e-05 go_gc_duration_seconds{quantile=\"0.5\"} 3.3738e-05 go_gc_duration_seconds{quantile=\"0.75\"} 4.21e-05 go_gc_duration_seconds{quantile=\"1\"} 0.000174304 go_gc_duration_seconds_sum 0.00027639 go_gc_duration_seconds_count 5 ####　服务发现 在 Kubernetes 下，Promethues 通过与 Kubernetes API 集成，目前主要支持5中服务发现模式，分别是：Node、Service、Pod、Endpoints、Ingress。 通过 kubectl 命令可以很方便的获取到当前集群中的所有节点信息： # kubectl get nodes NAME STATUS ROLES AGE VERSION saas-pre-master-dist-sz-01 Ready master 91d v1.15.3 saas-pre-node-dist-sz-01 Ready \u003cnone\u003e 91d v1.15.3 saas-pre-node-dist-sz-02 Ready \u003cnone\u003e 14d v1.15.3 但是要让 Prometheus 也能够获取到当前集群中的所有节点信息的话，就需要利用 Node 的服务发现模式，同样的，在 prometheus.yml 文件中配置如下的 job 任务即可： cat \u003e prome-cm.yaml\u003c\u003cEOFapiVersion:v1kind:","date":"2021-02-04","objectID":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9/:0:1","tags":["Promethues"],"title":"Promethues监控k8s集群节点","uri":"/promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9/"},{"categories":["监控"],"content":"Promethues搭建使用","date":"2021-02-04","objectID":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/","tags":["Promethues"],"title":"Promethues搭建使用","uri":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/"},{"categories":["监控"],"content":"Prometheus Server 使用 ","date":"2021-02-04","objectID":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/:1:0","tags":["Promethues"],"title":"Promethues搭建使用","uri":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/"},{"categories":["监控"],"content":"目前环境中使用的架构 ","date":"2021-02-04","objectID":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/:1:1","tags":["Promethues"],"title":"Promethues搭建使用","uri":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/"},{"categories":["监控"],"content":"安装prometheus 其中 prometheus.yml 文件的基本配置如下： global:scrape_interval:15sevaluation_interval:15srule_files:# - \"first.rules\"# - \"second.rules\"scrape_configs:- job_name:prometheusstatic_configs:- targets:['localhost:9090'] 上面这个配置文件中包含了3个模块：global、rule_files 和 scrape_configs。 其中 global 模块控制 Prometheus Server 的全局配置： scrape_interval：表示 prometheus 抓取指标数据的频率，默认是15s，我们可以覆盖这个值 evaluation_interval：用来控制评估规则的频率，prometheus 使用规则产生新的时间序列数据或者产生警报 rule_files 模块制定了规则所在的位置，prometheus 可以根据这个配置加载规则，用于生成新的时间序列数据或者报警信息，当前我们没有配置任何规则。 scrape_configs 用于控制 prometheus 监控哪些资源。由于 prometheus 通过 HTTP 的方式来暴露的它本身的监控数据，prometheus 也能够监控本身的健康情况。在默认的配置里有一个单独的 job，叫做prometheus，它采集 prometheus 服务本身的时间序列数据。这个 job 包含了一个单独的、静态配置的目标：监听 localhost 上的9090端口。prometheus 默认会通过目标的/metrics路径采集 metrics。所以，默认的 job 通过 URL：http://localhost:9090/metrics采集 metrics。收集到的时间序列包含 prometheus 服务本身的状态和性能。如果我们还有其他的资源需要监控的话，直接配置在该模块下面就可以了。 新创建一个监控的命名空间, monitoring cat \u003e monitoring_ns.yaml \u003c\u003cEOFapiVersion:v1kind:Namespacemetadata:name:monitoringEOF 将 prometheus-cm.yaml 文件用 ConfigMap 的形式进行管理： cat \u003e prometheus-cm.yaml \u003c\u003cEOFapiVersion:v1kind:ConfigMapmetadata:name:prometheus-confignamespace:monitoringdata:prometheus.yml:|global: scrape_interval: 15s scrape_timeout: 15s scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090']EOF 创建资源对象： kubectl create -f prometheus-cm.yaml 配置文件创建完成了，以后如果我们有新的资源需要被监控，我们只需要将上面的 ConfigMap 对象更新即可。现在我们来创建 prometheus 的 Pod 资源：(prometheus-deploy.yaml),由于没有创建ｐｖ,暂时先不持久化。 cat \u003e prometheus-deploy.yaml \u003c\u003cEOFapiVersion:extensions/v1beta1kind:Deploymentmetadata:name:prometheusnamespace:monitoringlabels:app:prometheusspec:template:metadata:labels:app:prometheusspec:serviceAccountName:prometheuscontainers:- image:prom/prometheus:v2.14.0name:prometheuscommand:- \"/bin/prometheus\"args:- \"--config.file=/etc/prometheus/prometheus.yml\"- \"--storage.tsdb.path=/prometheus\"- \"--storage.tsdb.retention=24h\"- \"--web.enable-admin-api\"# 控制对admin HTTP API的访问，其中包括删除时间序列等功能- \"--web.enable-lifecycle\"# 支持热更新，直接执行localhost:9090/-/reload立即生效ports:- containerPort:9090protocol:TCPname:httpvolumeMounts:- mountPath:\"/prometheus\"subPath:prometheusname:data- mountPath:\"/etc/prometheus\"name:config-volumeresources:requests:cpu:100mmemory:512Milimits:cpu:100mmemory:512MisecurityContext:runAsUser:0volumes:- name:data# persistentVolumeClaim:# claimName: prometheusemptyDir:{}- configMap:name:prometheus-configname:config-volumeEOF 在启动程序的时候，除了指定了 prometheus.yml 文件之外，还通过参数storage.tsdb.path指定了 TSDB 数据的存储路径、通过storage.tsdb.retention设置了保留多长时间的数据，还有下面的web.enable-admin-api参数可以用来开启对 admin api 的访问权限，参数web.enable-lifecycle非常重要，用来开启支持热更新的，有了这个参数之后，prometheus.yml 配置文件只要更新了，通过执行localhost:9090/-/reload就会立即生效，所以一定要加上这个参数。 除了上面的注意事项外，这里还需要配置 rbac 认证，因为需要在 prometheus 中去访问 Kubernetes 的相关信息，所以这里管理了一个名为 prometheus 的 serviceAccount 对象：(prometheus-rbac.yaml) cat \u003e prometheus-rbac.yaml \u003c\u003cEOFapiVersion:v1kind:ServiceAccountmetadata:name:prometheusnamespace:monitoring---apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:name:prometheusrules:- apiGroups:- \"\"resources:- nodes- services- endpoints- pods- nodes/proxyverbs:- get- list- watch- apiGroups:- \"\"resources:- configmaps- nodes/metricsverbs:- get- nonResourceURLs:- /metricsverbs:- get---apiVersion:rbac.authorization.k8s.io/v1beta1kind:ClusterRoleBindingmetadata:name:prometheusroleRef:apiGroup:rbac.authorization.k8s.iokind:ClusterRolename:prometheussubjects:- kind:ServiceAccountname:prometheusnamespace:monitoringEOF 由于要获取的资源信息，在每一个 namespace 下面都有可能存在，所以这里使用的是 ClusterRole 的资源对象，值得一提的是这里的权限规则声明中有一个nonResourceURLs的属性，是用来对非资源型 metrics 进行操作的权限声明，这个在以前很少遇到过，然后直接创建上面的资源对象即可： kubectl create -f prometheus-rbac.yaml 现在就可以添加 promethues 的资源对象了 kubectl create -f prometheus-deploy.yaml Pod 创建成功后，为了能够在外部访问到 prometheus 的 webui 服务，我们还需要创建一个 Service 对象：(prometheus-svc.yaml) cat \u003e prometheus-svc.yaml \u003c\u003cEOFapiVersion:v1kind:Servicemetadata:name:prometheusnamespace:monitoringlabels:app:prometheusspec:selector:app:prometheustype:NodePortports:- name:webport:9090targetPort:","date":"2021-02-04","objectID":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/:1:2","tags":["Promethues"],"title":"Promethues搭建使用","uri":"/promethues%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8/"},{"categories":["监控"],"content":"Prometheus介绍","date":"2021-02-04","objectID":"/promethues%E4%BB%8B%E7%BB%8D/","tags":["Promethues"],"title":"Promethues介绍","uri":"/promethues%E4%BB%8B%E7%BB%8D/"},{"categories":["监控"],"content":"Prometheus 简介 Prometheus 最初是 SoundCloud 构建的开源系统监控和报警工具，是一个独立的开源项目，于2016年加入了 CNCF 基金会，作为继 Kubernetes 之后的第二个托管项目。 ","date":"2021-02-04","objectID":"/promethues%E4%BB%8B%E7%BB%8D/:1:0","tags":["Promethues"],"title":"Promethues介绍","uri":"/promethues%E4%BB%8B%E7%BB%8D/"},{"categories":["监控"],"content":"特征 Prometheus 相比于其他传统监控工具主要有以下几个特点： 具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型 有一个灵活的查询语言 不依赖分布式存储，只和本地磁盘有关 通过 HTTP 的服务拉取时间序列数据 也支持推送的方式来添加时间序列数据 还支持通过服务发现或静态配置发现目标 多种图形和仪表板支持 ","date":"2021-02-04","objectID":"/promethues%E4%BB%8B%E7%BB%8D/:1:1","tags":["Promethues"],"title":"Promethues介绍","uri":"/promethues%E4%BB%8B%E7%BB%8D/"},{"categories":["监控"],"content":"组件 Prometheus 由多个组件组成，但是其中许多组件是可选的： Prometheus Server：用于抓取指标、存储时间序列数据 exporter：暴露指标让任务来抓 pushgateway：push 的方式将指标数据推送到该网关 alertmanager：处理报警的报警组件 adhoc：用于数据查询 大多数 Prometheus 组件都是用 Go 编写的，因此很容易构建和部署为静态的二进制文件。 ","date":"2021-02-04","objectID":"/promethues%E4%BB%8B%E7%BB%8D/:1:2","tags":["Promethues"],"title":"Promethues介绍","uri":"/promethues%E4%BB%8B%E7%BB%8D/"},{"categories":["监控"],"content":"架构 下图是 Prometheus 官方提供的架构及其一些相关的生态系统组件： ","date":"2021-02-04","objectID":"/promethues%E4%BB%8B%E7%BB%8D/:1:3","tags":["Promethues"],"title":"Promethues介绍","uri":"/promethues%E4%BB%8B%E7%BB%8D/"},{"categories":["监控"],"content":"prometheus 联邦使用 通过Remote Storage可以分离监控样本采集和数据存储，解决Prometheus的持久化问题。这一部分会重点讨论如何利用联邦集群特性对Promthues进行扩展，以适应不同监控规模的变化 对于大部分监控规模而言，我们只需要在每一个数据中心(例如：EC2可用区，Kubernetes集群)安装一个Prometheus Server实例，就可以在各个数据中心处理上千规模的集群。同时将Prometheus Server部署到不同的数据中心可以避免网络配置的复杂性 如上图所示，在每个数据中心部署单独的Prometheus Server，用于采集当前数据中心监控数据。并由一个中心的Prometheus Server负责聚合多个数据中心的监控数据。这一特性在Promthues中称为联邦集群。 联邦集群的核心在于每一个Prometheus Server都包含额一个用于获取当前实例中监控样本的接口/federate。对于中心Prometheus Server而言，无论是从其他的Prometheus实例还是Exporter实例中获取数据实际上并没有任何差异 scrape_configs: - job_name: 'federate' scrape_interval: 15s honor_labels: true metrics_path: '/federate' params: 'match[]': - '{job=\"prometheus\"}' - '{__name__=~\"job:.*\"}' - '{__name__=~\"node.*\"}' static_configs: - targets: - 'xxxxxxx:9090' - 'xxxxxxx:9090' 为了有效的减少不必要的时间序列，通过params参数可以用于指定只获取某些时间序列的样本数据，例如 ```bash \"http://192.168.77.11:9090/federate?match[]={job%3D\"prometheus\"}\u0026match[]={__name__%3D~\"job%3A.*\"}\u0026match[]={__name__%3D~\"node.*\"}\" 通过URL中的match[]参数指定我们可以指定需要获取的时间序列。match[]参数必须是一个瞬时向量选择器，例如up或者{job=“api-server”}。配置多个match[]参数，用于获取多组时间序列的监控数据。 horbor_labels配置true可以确保当采集到的监控指标冲突时，能够自动忽略冲突的监控数据。如果为false时，prometheus会自动将冲突的标签替换为”exported_“的形式 ","date":"2021-02-04","objectID":"/promethues%E4%BB%8B%E7%BB%8D/:1:4","tags":["Promethues"],"title":"Promethues介绍","uri":"/promethues%E4%BB%8B%E7%BB%8D/"},{"categories":["数据库"],"content":"Mongo副本集","date":"2021-02-04","objectID":"/mongo%E5%89%AF%E6%9C%AC%E9%9B%86/","tags":["Mongo"],"title":"Mongo副本集","uri":"/mongo%E5%89%AF%E6%9C%AC%E9%9B%86/"},{"categories":["数据库"],"content":"mongo 副本集搭建 MongoDB主备+仲裁的基本结构如下 主节点（Primary） 在复制集中，主节点是唯一能够接收写请求的节点。MongoDB在主节点进行写操作，并将这些操作记录到主节点的oplog中。而从节点将会从oplog复制到其本机，并将这些操作应用到自己的数据集上。（复制集最多只能拥有一个主节点） 从节点（Secondaries） 从节点通过应用主节点传来的数据变动操作来保持其数据集与主节点一致。从节点也可以通过增加额外参数配置来对应特殊需求。例如，从节点可以是non-voting或是priority 0. 仲裁节点（ARBITER） 仲裁节点即投票节点，其本身并不包含数据集，且也无法晋升为主节点。但是，旦当前的主节点不可用时，投票节点就会参与到新的主节点选举的投票中。仲裁节点使用最小的资源并且不要求硬件设备。投票节点的存在使得复制集可以以偶数个节点存在，而无需为复制集再新增节点 不要将投票节点运行在复制集的主节点或从节点机器上。 投票节点与其他 复制集节点的交流仅有：选举过程中的投票，心跳检测和配置数据。这些交互都是不加密的。 心跳检测 复制集成员每两秒向复制集中其他成员进行心跳检测。如果某个节点在10秒内没有返回，那么它将被标记为不可用。 MongoDB副本集是有故障恢复功能的主从集群，由一个primary节点和一个或多个secondary节点组成： 节点同步过程： Primary节点写入数据，Secondary通过读取Primary的oplog得到复制信息，开始复制数据并且将复制信息写入到自己的oplog。如果某个操作失败，则备份节点停止从当前数据源复制数据。如果某个备份节点由于某些原因挂掉了，当重新启动后，就会自动从oplog的最后一个操作开始同步，同步完成后，将信息写入自己的oplog，由于复制操作是先复制数据，复制完成后再写入oplog，有可能相同的操作会同步两份，不过MongoDB在设计之初就考虑到这个问题，将oplog的同一个操作执行多次，与执行一次的效果是一样的。 通俗理解：当Primary节点完成数据操作后，Secondary会做出一系列的动作保证数据的同步： 检查自己local库的oplog.rs集合，找出最近的时间戳。 检查Primary节点local库oplog.rs集合，找出大于此时间戳的记录。 将找到的记录插入到自己的oplog.rs集合中，并执行这些操作。 副本集的同步和主从同步一样，都是异步同步的过程，不同的是副本集有个自动故障转移的功能。其原理是：slave端从primary端获取日志，然后在自己身上完全顺序的执行日志所记录的各种操作（该日志是不记录查询操作的），这个日志就是local数据 库中的oplog.rs表，默认在64位机器上这个表是比较大的，占磁盘大小的5%，oplog.rs的大小可以在启动参数中设 定：–oplogSize 1000,单位是M。 部署过程如下 # 制作dockerfile 生产机器 cat \u003e Dockerfile \u003c\u003c- 'EOF' FROM centos:7 RUN yum install wget vim net-tools htop -y \\ \u0026\u0026 cp -r /etc/yum.repos.d /etc/yum.repos.d.bak \\ \u0026\u0026 rm -f /etc/yum.repos.d/*.repo \\ \u0026\u0026 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo \\ \u0026\u0026 wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo \\ \u0026\u0026 yum clean all \u0026\u0026 yum makecache \\ \u0026\u0026 yum install -y openssh-server \\ \u0026\u0026 mkdir /var/run/sshd \\ \u0026\u0026 echo 'root:123456' |chpasswd \\ \u0026\u0026 sed -ri 's/^#?PermitRootLogin\\s+.*/PermitRootLogin yes/' /etc/ssh/sshd_config \\ \u0026\u0026 mkdir /root/.ssh \\ \u0026\u0026 ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key EXPOSE 22 CMD [\"/usr/sbin/sshd\", \"-D\"] EOF docker build -t mongo_vm:v1 -f Dockerfile . # 创建机器 for i in `seq 1 3`;do docker run --rm -itd --privileged=true --name mongo_vm_$i mongo_vm:v1 /usr/sbin/init;done # 查询ip地址 for i in `seq 1 3`;do docker inspect mongo_vm_$i -f {{.NetworkSettings.Networks.bridge.IPAddress}};done # 删除机器 for i in `seq 1 3`;do docker stop mongo_vm_$i mongo_vm:v1;done # 服务器信息 mongo01 172.17.0.3 Primary mongo02 172.17.0.4 Secondary mongo03 172.17.0.5 Secondary # 清除known_hosts for i in `seq 1 3`;do docker exec -it mongo_vm_$i -- \u003e /root/.ssh/known_hosts;done # 配置ssh-key for i in `seq 3 5`;do ssh-copy-id root@172.17.0.$i;done # 安装ansible yum install -y ansible cat \u003e\u003e /etc/ansible/hosts \u003c\u003c- 'EOF' [mongo] 172.17.0.3 172.17.0.4 172.17.0.5 EOF # 编写ansible批量安装脚本 cat \u003e deploy.yml \u003c\u003c- 'EOF' --- - hosts: mongo remote_user: root gather_facts: false tasks: - name: configure hosts shell: | cat \u003e\u003e /etc/hosts \u003c\u003c- 'EOF' # mongo 172.17.0.3 mongo01 172.17.0.4 mongo02 172.17.0.5 mongo03 EOF tags: - install - name: download mongo shell: wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.4.tgz -P /usr/local/src tags: - install - name: unarchive unarchive: src: /usr/local/src/mongodb-linux-x86_64-4.0.4.tgz dest: /usr/local/src mode: 0755 copy: no tags: - install - name: mkdir dir file: path: \"{{ item }}\" state: directory with_items: - \"/usr/local/mongo\" - \"/data/mongo/db\" tags: - install - name: create log file file: path: \"{{ item }}/mongod.log\" state: touch with_items: - \"/data/mongo\" tags: - log - install - name: copy files shell: mv \"{{ item }}\"/* /usr/local/mongo/ with_items: - \"/usr/local/src/mongodb-linux-x86_64-4.0.4\" tags: - install - name: configure env shell: | echo 'export PATH=/usr/local/mongo/bin:$PATH' \u003e\u003e /etc/profile source /etc/profile tags: - env - install - name: configure conf file shell: | cat \u003e /data/mongo/mongodb.cnf \u003c\u003c- 'EOF' systemLog: destination: file logAppend: true path: /data/mongo/mongod.log net: port: 27017 bindIp: 0.0.0.0 storage: dbPath: /data/mongo/db journal: enabled: true processManagement: fork: true pidFilePath: /data/mongo/mongod.pid ","date":"2021-02-04","objectID":"/mongo%E5%89%AF%E6%9C%AC%E9%9B%86/:0:1","tags":["Mongo"],"title":"Mongo副本集","uri":"/mongo%E5%89%AF%E6%9C%AC%E9%9B%86/"},{"categories":["数据库"],"content":"Mongo安装","date":"2021-02-04","objectID":"/mongo%E5%AE%89%E8%A3%85/","tags":["Mongo"],"title":"Mongo安装","uri":"/mongo%E5%AE%89%E8%A3%85/"},{"categories":["数据库"],"content":"mongo简介及安装 mongo介绍 MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。 在高负载的情况下，添加更多的节点，可以保证服务器性能。 MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。 MongoDB 将数据存储为一个文档，数据结构由键值(key=\u003evalue)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组 { name:\"sue\", age:23, status:\"A\", groups:[\"news\",\"sports\"] } mongo安装 详情见官网 # 下载二进制文件 yum install libcurl openssl wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.4.tgz # 下载地址 https://repo.mongodb.org/yum/redhat/7/mongodb-org/4.0/x86_64/RPMS/mongodb-org-server-4.0.4-1.el7.x86_64.rpm https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.4.tgz mkdir -pv /usr/local/mongodb tar zxvf mongodb-linux-x86_64-4.0.4.tgz -C /usr/local/src mv /usr/local/src/mongodb-linux-x86_64-4.0.4 /usr/local/mongodb echo 'export PATH=/usr/local/mongodb/bin:$PATH' \u003e\u003e /etc/profile source /etc/profile # 创建mongodb数据库目录 mkdir -pv /data/mongo/db mkdir -pv /data/mongo/mongodb.cnf mkdir -pv /data/mongo/mongo.log # 创建启动配置文件 cat \u003e /data/mongo/mongodb.cnf \u003c\u003c- 'EOF' dbpath=/data/mongo/db logpath=/data/mongo/mongod.log pidfilepath=/data/mongo/mongod.pid logappend=true fork=true port=27017 # 副本集 #replSet=rs0 EOF # 启动mongo mongod --auth -f /data/mongo/mongodb.cnf # 进入mongo管理控制台 mongo # 配置开机启动 cat \u003e /etc/systemd/system/mongod.service \u003c\u003c- 'EOF' [Unit] Description=mongodb After=network.target remote-fs.target nss-lookup.target [Service] Type=forking ExecStart=/usr/local/mongodb/bin/mongod --config /servers/db/mongo/mongodb.cnf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/usr/local/mongodb/bin/mongod --shutdown --config /servers/db/mongo/mongodb.cnf PrivateTmp=true [Install] WantedBy=multi-user.target EOF systemctl enable mongod.servcie systemctl start mongod mongodb使用 # 创建数据库 use DATABASE_NAME # 插入数据 db.test.insert({\"name\":\"你家人来找你了\"}) # 删除数据库 use runoob db.dropDatabase() # 删除集合 db.createCollection(\"runoob\") show tables db.collection.drop() db.runoob.drop() show tables # 创建固定集合 db.createCollection(\"mycol\", { capped : true, autoIndexId : true, size : 6142800, max : 10000 } ) ","date":"2021-02-04","objectID":"/mongo%E5%AE%89%E8%A3%85/:0:1","tags":["Mongo"],"title":"Mongo安装","uri":"/mongo%E5%AE%89%E8%A3%85/"},{"categories":["linux"],"content":"System管理服务","date":"2021-02-04","objectID":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/","tags":["Linux"],"title":"Systemd管理服务","uri":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["linux"],"content":"Systemd 服务管理 ","date":"2021-02-04","objectID":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:1:0","tags":["Linux"],"title":"Systemd管理服务","uri":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["linux"],"content":"简介 Systemd 是一系列工具的集合，其作用也远远不仅是启动操作系统，它还接管了后台服务、结束、状态查询，以及日志归档、设备管理、电源管理、定时任务等许多职责，并支持通过特定事件（如插入特定 USB 设备）和特定端口数据触发的 On-demand（按需）任务。 ","date":"2021-02-04","objectID":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:1:1","tags":["Linux"],"title":"Systemd管理服务","uri":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["linux"],"content":"Systemd 的 Unit 文件 Systemd 可以管理所有系统资源，不同的资源统称为 Unit（单位）。 在 Systemd 的生态圈中，Unit 文件统一了过去各种不同系统资源配置格式，例如服务的启/停、定时任务、设备自动挂载、网络配置、虚拟内存配置等。而 Systemd 通过不同的文件后缀来区分这些配置文件。 Systemd 支持的 12 种 Unit 文件类型 automount：用于控制自动挂载文件系统，相当于 SysV-init 的 autofs 服务 device：对于 /dev 目录下的设备，主要用于定义设备之间的依赖关系 mount：定义系统结构层次中的一个挂载点，可以替代过去的 /etc/fstab 配置文件 path：用于监控指定目录或文件的变化，并触发其它 Unit 运行 scope：这种 Unit 文件不是用户创建的，而是 Systemd 运行时产生的，描述一些系统服务的分组信息 service：封装守护进程的启动、停止、重启和重载操作，是最常见的一种 Unit 文件 slice：用于表示一个 CGroup 的树，通常用户不会自己创建这样的 Unit 文件 snapshot：用于表示一个由 systemctl snapshot 命令创建的 Systemd Units 运行状态快照 socket：监控来自于系统或网络的数据消息，用于实现基于数据自动触发服务启动 swap：定义一个用户做虚拟内存的交换分区 target：用于对 Unit 文件进行逻辑分组，引导其它 Unit 的执行。它替代了 SysV-init 运行级别的作用，并提供更灵活的基于特定设备事件的启动方式 timer：用于配置在特定时间触发的任务，替代了 Crontab 的功能 Systemd 目录 Unit 文件按照 Systemd 约定，应该被放置指定的三个系统目录之一中。这三个目录是有优先级的，如下所示，越靠上的优先级越高。因此，在三个目录中有同名文件的时候，只有优先级最高的目录里的那个文件会被使用。 /etc/systemd/system：系统或用户自定义的配置文件 /run/systemd/system：软件运行时生成的配置文件 /usr/lib/systemd/system：系统或第三方软件安装时添加的配置文件。 Systemd 默认从目录 /etc/systemd/system/ 读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录 /usr/lib/systemd/system/，真正的配置文件存放在那个目录。 Unit 和 Target Unit 是 Systemd 管理系统资源的基本单元，可以认为每个系统资源就是一个 Unit，并使用一个 Unit 文件定义。在 Unit 文件中需要包含相应服务的描述、属性以及需要运行的命令。 Target 是 Systemd 中用于指定系统资源启动组的方式，相当于 SysV-init 中的运行级别。 简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于”状态点”，启动某个 Target 就好比启动到某种状态。 Systemd Service Unit Uint文件结构 [Unit] Description=Hello World After=docker.service Requires=docker.service [Service] TimeoutStartSec=0 ExecStartPre=-/usr/bin/docker kill busybox1 ExecStartPre=-/usr/bin/docker rm busybox1 ExecStartPre=/usr/bin/docker pull busybox ExecStart=/usr/bin/docker run --name busybox1 busybox /bin/ sh -c \"while true; do echo Hello World; sleep 1; done\" ExecStop=\"/usr/bin/docker stop busybox1\" ExecStopPost=\"/usr/bin/docker rm busybox1\" [Install] WantedBy=multi-user.target 如下所示，Systemd 服务的 Unit 文件可以分为三个配置区段： Unit 和 Install 段：所有 Unit 文件通用，用于配置服务（或其它系统资源）的描述、依赖和随系统启动的方式 Service 段：服务（Service）类型的 Unit 文件（后缀为 .service）特有的，用于定义服务的具体管理和操作方法 Unit 段 Description：描述这个 Unit 文件的信息 Documentation：指定服务的文档，可以是一个或多个文档的 URL 路径 Requires：依赖的其它 Unit 列表，列在其中的 Unit 模板会在这个服务启动时的同时被启动。并且，如果其中任意一个服务启动失败，这个服务也会被终止 Wants：与 Requires 相似，但只是在被配置的这个 Unit 启动时，触发启动列出的每个 Unit 模块，而不去考虑这些模板启动是否成功 After：与 Requires 相似，但是在后面列出的所有模块全部启动完成以后，才会启动当前的服务 Before：与 After 相反，在启动指定的任务一个模块之间，都会首先确证当前服务已经运行 Binds To：与 Requires 相似，失败时失败，成功时成功，但是在这些模板中有任意一个出现意外结束或重启时，这个服务也会跟着终止或重启 Part Of：一个 Bind To 作用的子集，仅在列出的任务模块失败或重启时，终止或重启当前服务，而不会随列出模板的启动而启动 OnFailure：当这个模板启动失败时，就会自动启动列出的每个模块 Conflicts：与这个模块有冲突的模块，如果列出的模块中有已经在运行的，这个服务就不能启动，反之亦然 Service 段 用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段分为服务生命周期和服务上下文配置两个方面 服务生命周期控制相关 Type：定义启动时的进程行为，它有以下几种值： Type=simple：默认值，执行ExecStart指定的命令，启动主进程 Type=forking：以 fork 方式从父进程创建子进程，创建后父进程会立即退出 Type=oneshot：一次性进程，Systemd 会等当前服务退出，再继续往下执行 Type=dbus：当前服务通过D-Bus启动 Type=notify：当前服务启动完毕，会通知Systemd，再继续往下执行 Type=idle：若有其他任务执行完毕，当前服务才会运行 RemainAfterExit：值为 true 或 false（默认）。当配置为 true 时，Systemd 只会负责启动服务进程，之后即便服务进程退出了，Systemd 也仍然会认为这个服务还在运行中。这个配置主要是提供给一些并非常驻内存，而是启动注册后立即退出，然后等待消息按需启动的特殊类型服务使用的。 ExecStart：启动当前服务的命令 ExecStartPre：启动当前服务之前执行的命令 ExecStartPos：启动当前服务之后执行的命令 ExecReload：重启当前服务时执行的命令 ExecStop：停止当前服务时执行的命令 ExecStopPost：停止当其服务之后执行的命令 RestartSec：自动重启当前服务间隔的秒数 Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括 always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog TimeoutStartSec：启动服务时等待的秒数，这一配置对于使用 Docker 容器而言显得尤为重要，因其第一次运行时可能需要下载镜像，严重延时会容易被 Systemd 误判为启动失败杀死。通常，对于这种服务，将此值指定为 0，从而关闭超时检测 TimeoutStopSec：停止服务时的等待秒数，如果超过这个时间仍然没有停止，Systemd 会使用 SIGKILL 信号强行杀死服务的进程 ","date":"2021-02-04","objectID":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:1:2","tags":["Linux"],"title":"Systemd管理服务","uri":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["linux"],"content":"Systemd 的资源管理 Systemctl 命令 # systemctl --help systemctl [OPTIONS...] {COMMAND} ... Query or send control commands to the systemd manager. -h --help Show this help --version Show package version --system Connect to system manager -H --host=[USER@]HOST Operate on remote host -M --machine=CONTAINER Operate on local container -t --type=TYPE List units of a particular type --state=STATE List units with particular LOAD or SUB or ACTIVE state -p --property=NAME Show only properties by this name -a --all Show all loaded units/properties, including dead/empty ones. To list all units installed on the system, use the 'list-unit-files' command instead. -l --full Don't ellipsize unit names on output -r --recursive Show unit list of host and local containers --reverse Show reverse dependencies with 'list-dependencies' --job-mode=MODE Specify how to deal with already queued jobs, when queueing a new job --show-types When showing sockets, explicitly show their type -i --ignore-inhibitors When shutting down or sleeping, ignore inhibitors --kill-who=WHO Who to send signal to -s --signal=SIGNAL Which signal to send --now Start or stop unit in addition to enabling or disabling it -q --quiet Suppress output --no-block Do not wait until operation finished --no-wall Don't send wall message before halt/power-off/reboot --no-reload Don't reload daemon after en-/dis-abling unit files --no-legend Do not print a legend (column headers and hints) --no-pager Do not pipe output into a pager --no-ask-password Do not ask for system passwords --global Enable/disable unit files globally --runtime Enable unit files only temporarily until next reboot -f --force When enabling unit files, override existing symlinks When shutting down, execute action immediately --preset-mode= Apply only enable, only disable, or all presets --root=PATH Enable unit files in the specified root directory -n --lines=INTEGER Number of journal entries to show -o --output=STRING Change journal output mode (short, short-iso, short-precise, short-monotonic, verbose, export, json, json-pretty, json-sse, cat) --plain Print unit dependencies as a list instead of a tree Unit Commands: list-units [PATTERN...] List loaded units list-sockets [PATTERN...] List loaded sockets ordered by address list-timers [PATTERN...] List loaded timers ordered by next elapse start NAME... Start (activate) one or more units stop NAME... Stop (deactivate) one or more units reload NAME... Reload one or more units restart NAME... Start or restart one or more units try-restart NAME... Restart one or more units if active reload-or-restart NAME... Reload one or more units if possible, otherwise start or restart reload-or-try-restart NAME... Reload one or more units if possible, otherwise restart if active isolate NAME Start one unit and stop all others kill NAME... Send signal to processes of a unit is-active PATTERN... Check whether units are active is-failed PATTERN... Check whether units are failed status [PATTERN...|PID...] Show runtime status of one or more units show [PATTERN...|JOB...] Show properties of one or more units/jobs or the manager cat PATTERN... Show files and drop-ins of one or more units set-property NAME ASSIGNMENT... Sets one or more properties of a unit help PATTERN...|PID... Show manual for one or more units reset-failed [PATTERN...] Reset failed state for all, one, or more units list-dependencies [NAME] Recursively show units which are required or wanted by this unit or by which this unit is required or wanted Unit File Commands: list-unit-files [PATTERN...] List installed unit files enable NAME... Enable one or more unit files disable NAME... Disable one or more unit files reenable NAME... Reenable one or more unit files preset NAME... Enable/disable one or more unit files based on preset configuration preset-all Enable/disable all unit files based on preset configuration is-enabled NAME... Check whether unit files are enabled mask NAME... Mask one or more units unmask NAME... Unmask one or more ","date":"2021-02-04","objectID":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:1:3","tags":["Linux"],"title":"Systemd管理服务","uri":"/systemd%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["分布式数据库"],"content":"TIDB使用","date":"2021-02-04","objectID":"/tidb%E4%BD%BF%E7%94%A8/","tags":["ddbs"],"title":"TIDB使用","uri":"/tidb%E4%BD%BF%E7%94%A8/"},{"categories":["分布式数据库"],"content":"TIDB 数据库集群 ","date":"2021-02-04","objectID":"/tidb%E4%BD%BF%E7%94%A8/:1:0","tags":["ddbs"],"title":"TIDB使用","uri":"/tidb%E4%BD%BF%E7%94%A8/"},{"categories":["分布式数据库"],"content":"一、TiDB数据介绍 1.1、TiDB数据简介 TiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。 TiDB 具备如下特性： 高度兼容 MySQL 大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。 水平弹性扩展 通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。 分布式事务 TiDB 100% 支持标准的 ACID 事务。 真正金融级高可用 相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。 一站式 HTAP 解决方案 TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP 解决方案，一份存储同时处理 OLTP \u0026 OLAP，无需传统繁琐的 ETL 过程。 云原生 SQL 数据库 TiDB 是为云而设计的数据库，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。 TiDB Server TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。 PD Server Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。 PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点 TiKV Server TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度 TiSpark TiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼 1.2、Tidb 数据基本操作 创建、查看和删除数据库 CREATE DATABASE db_name [options]; CREATE DATABASE IF NOT EXISTS samp_db; DROP DATABASE samp_db; DROP TABLE IF EXISTS person; CREATE INDEX person_num ON person (number); ALTER TABLE person ADD INDEX person_num (number); CREATE UNIQUE INDEX person_num ON person (number); CREATE USER 'tiuser'@'localhost' IDENTIFIED BY '123456'; GRANT SELECT ON samp_db.* TO 'tiuser'@'localhost'; SHOW GRANTS for tiuser@localhost; DROP USER 'tiuser'@'localhost'; GRANT ALL PRIVILEGES ON test.* TO 'xxxx'@'%' IDENTIFIED BY 'yyyyy'; REVOKE ALL PRIVILEGES ON `test`.* FROM 'genius'@'localhost'; SHOW GRANTS for 'root'@'%'; SELECT Insert_priv FROM mysql.user WHERE user='test' AND host='%'; FLUSH PRIVILEGES; ","date":"2021-02-04","objectID":"/tidb%E4%BD%BF%E7%94%A8/:1:1","tags":["ddbs"],"title":"TIDB使用","uri":"/tidb%E4%BD%BF%E7%94%A8/"},{"categories":["分布式数据库"],"content":"二、TiDB Ansible 部署 2.1、安装Tidb集群基础环境 使用三台物理机搭建Tidb集群，三台机器ip 为 172.16.5.50，172.16.5.51，172.16.5.10，其中172.16.5.51作为中控机。 软件安装如下： 172.16.5.51 TiDB,PD,TiKV 172.16.5.50 TiKV 172.16.5.10 TiKV 安装中控机软件 # yum -y install epel-release git curl sshpass atop vim htop net-tools # yum -y install python-pip 在中控机上创建 tidb 用户，并生成 ssh key # 创建tidb用户 useradd -m -d /home/tidb tidb \u0026\u0026 passwd tidb # 配置tidb用户sudo权限 visudo tidb ALL=(ALL) NOPASSWD: ALL # 使用tidb账户生成 ssh key su tidb \u0026\u0026 ssh-keygen -t rsa -C mikel@tidb 在中控机器上下载 TiDB-Ansible # 下载Tidb-Ansible 版本 cd /home/tidb \u0026\u0026 git clone -b release-2.0 https://github.com/pingcap/tidb-ansible.git # 安装ansible及依赖 cd /home/tidb/tidb-ansible/ \u0026\u0026 pip install -r ./requirements.txt 在中控机上配置部署机器ssh互信及sudo 规则 # 配置hosts.ini su tidb \u0026\u0026 cd /home/tidb/tidb-ansible vim hosts.ini [servers] 172.16.5.50 172.16.5.51 172.16.5.52 [all:vars] username = tidb ntp_server = pool.ntp.org # 配置ssh 互信 ansible-playbook -i hosts.ini create_users.yml -u root -k 在目标机器上安装ntp服务 # 中控机器上给目标主机安装ntp服务 cd /home/tidb/tidb-ansible ansible-playbook -i hosts.ini deploy_ntp.yml -u tidb -b 目标机器上调整cpufreq # 查看cpupower 调节模式，目前虚拟机不支持，调节10服务器cpupower cpupower frequency-info --governors analyzing CPU 0: available cpufreq governors: Not Available # 配置cpufreq调节模式 cpupower frequency-set --governor performance 目标机器上添加数据盘ext4 文件系统挂载 # 创建分区表 parted -s -a optimal /dev/nvme0n1 mklabel gpt -- mkpart primary ext4 1 -1 # 手动创建分区 parted dev/sdb mklabel gpt mkpart primary 0KB 210GB # 格式化分区 mkfs.ext4 /dev/sdb # 查看数据盘分区 UUID [root@tidb-tikv1 ~]# lsblk -f NAME FSTYPE LABEL UUID MOUNTPOINT sda ├─sda1 xfs f41c3b1b-125f-407c-81fa-5197367feb39 /boot ├─sda2 xfs 8119193b-c774-467f-a057-98329c66b3b3 / ├─sda3 └─sda5 xfs 42356bb3-911a-4dc4-b56e-815bafd08db2 /home sdb ext4 532697e9-970e-49d4-bdba-df386cac34d2 # 分别在三台机器上，编辑 /etc/fstab 文件，添加 nodelalloc 挂载参数 vim /etc/fstab UUID=8119193b-c774-467f-a057-98329c66b3b3 / xfs defaults 0 0 UUID=f41c3b1b-125f-407c-81fa-5197367feb39 /boot xfs defaults 0 0 UUID=42356bb3-911a-4dc4-b56e-815bafd08db2 /home xfs defaults 0 0 UUID=532697e9-970e-49d4-bdba-df386cac34d2 /data ext4 defaults,nodelalloc,noatime 0 2 # 挂载数据盘 mkdir /data mount -a mount -t ext4 /dev/sdb on /data type ext4 (rw,noatime,seclabel,nodelalloc,data=ordered) 分配机器资源，编辑inventory.ini 文件 # 单机Tikv实例 Name HostIP Services tidb-tikv1 172.16.5.50 PD1, TiDB1, TiKV1 tidb-tikv2 172.16.5.51 PD2, TiKV2 tidb-tikv3 172.16.5.52 PD3, TiKV3 # 编辑inventory.ini 文件 cd /home/tidb/tidb-ansible vim inventory.ini ## TiDB Cluster Part [tidb_servers] 172.16.5.50 172.16.5.51 [tikv_servers] 172.16.5.50 172.16.5.51 172.16.5.52 [pd_servers] 172.16.5.50 172.16.5.51 172.16.5.52 ## Monitoring Part # prometheus and pushgateway servers [monitoring_servers] 172.16.5.50 # node_exporter and blackbox_exporter servers [monitored_servers] 172.16.5.50 172.16.5.51 172.16.5.52 [all:vars] #deploy_dir = /home/tidb/deploy deploy_dir = /data/deploy # 检测ssh互信 [tidb@tidb-tikv1 tidb-ansible]$ ansible -i inventory.ini all -m shell -a 'whoami' 172.16.5.51 | SUCCESS | rc=0 \u003e\u003e tidb 172.16.5.52 | SUCCESS | rc=0 \u003e\u003e tidb 172.16.5.50 | SUCCESS | rc=0 \u003e\u003e tidb # 检测tidb 用户 sudo 免密码配置 [tidb@tidb-tikv1 tidb-ansible]$ ansible -i inventory.ini all -m shell -a 'whoami' -b 172.16.5.52 | SUCCESS | rc=0 \u003e\u003e root 172.16.5.51 | SUCCESS | rc=0 \u003e\u003e root 172.16.5.50 | SUCCESS | rc=0 \u003e\u003e root # 执行 local_prepare.yml playbook，联网下载 TiDB binary 到中控机 ansible-playbook local_prepare.yml # 初始化系统环境，修改内核参数 ansible-playbook bootstrap.yml 2.2、安装Tidb集群 ansible-playbook deploy.yml 2.3、启动Tidb集群 ansible-playbook start.yml 2.4、测试集群 # 使用 MySQL 客户端连接测试，TCP 4000 端口是 TiDB 服务默认端口 mysql -u root -h 172.16.5.50 -P 4000 mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | INFORMATION_SCHEMA | | PERFORMANCE_SCHEMA | | mysql | | test | +--------------------+ 4 rows in set (0.00 sec) # 通过浏览器访问监控平台 地址：http://172.16.5.51:3000 默认帐号密码是：admin/admin ","date":"2021-02-04","objectID":"/tidb%E4%BD%BF%E7%94%A8/:1:2","tags":["ddbs"],"title":"TIDB使用","uri":"/tidb%E4%BD%BF%E7%94%A8/"},{"categories":["分布式数据库"],"content":"三、TIDB集群扩容 3.1、扩容 TiDB/TiKV 节点 # 单机Tikv实例 Name HostIP Services tidb-tikv1 172.16.5.50 PD1, TiDB1, TiKV1 tidb-tikv2 172.16.5.51 PD2, TiKV2 tidb-tikv3 172.16.5.52 PD3, TiKV3 # 新增一台TIDB节点 添加一个 TiDB 节点（tidb-tikv4），IP 地址为 172.16.5.53 # 编辑inventory.ini 文件 cd /home/tidb/tidb-ansible vim inventory.ini ## TiDB Cluster Part [tidb_servers] 172.16.5.50 172.16.5.51 172.16.5.53 [tikv_servers] 172.16.5.50 172.16.5.51 172.16.5.52 [pd_servers] 172.16.5.50 172.16.5.51 172.16.5.52 ## Monitoring Part # prometheus and pushgateway servers [monitoring_servers] 172.16.5.50 # node_exporter and blackbox_exporter servers [monitored_servers] 172.16.5.50 172.16.5.51 172.16.5.52 172.16.5.53 # 拓扑结构如下 Name HostIP Services tidb-tikv1 172.16.5.50 PD1, TiDB1, TiKV1 tidb-tikv2 172.16.5.51 PD2, TiKV2 tidb-tikv3 172.16.5.52 PD3, TiKV3 tidb-tikv4 172.16.5.53 TiDB2 # 初始化新增节点 ansible-playbook bootstrap.yml -l 172.16.5.53 # 部署新增节点 ansible-playbook deploy.yml -l 172.16.5.53 # 启动新节点服务 ansible-playbook start.yml -l 172.16.5.53 # 更新 Prometheus 配置并重启 ansible-playbook rolling_update_monitor.yml --tags=prometheus 3.2、扩容PD节点 # 拓扑结构如下# 单机Tikv实例 Name HostIP Services tidb-tikv1 172.16.5.50 PD1, TiDB1, TiKV1 tidb-tikv2 172.16.5.51 PD2, TiKV2 tidb-tikv3 172.16.5.52 PD3, TiKV3 # 新增一台PD节点 添加一个 PD 节点（tidb-pd1），IP 地址为 172.16.5.54 # 编辑inventory.ini 文件 cd /home/tidb/tidb-ansible vim inventory.ini ## TiDB Cluster Part [tidb_servers] 172.16.5.50 172.16.5.51 [tikv_servers] 172.16.5.50 172.16.5.51 172.16.5.52 [pd_servers] 172.16.5.50 172.16.5.51 172.16.5.52 172.16.5.54 ## Monitoring Part # prometheus and pushgateway servers [monitoring_servers] 172.16.5.50 # node_exporter and blackbox_exporter servers [monitored_servers] 172.16.5.50 172.16.5.51 172.16.5.52 172.16.5.54 # 拓扑结构如下 Name HostIP Services tidb-tikv1 172.16.5.50 PD1, TiDB1, TiKV1 tidb-tikv2 172.16.5.51 PD2, TiKV2 tidb-tikv3 172.16.5.52 PD3, TiKV3 tidb-pd1 172.16.5.54 PD4 # 初始化新增节点 ansible-playbook bootstrap.yml -l 172.16.5.54 # 部署新增节点 ansible-playbook deploy.yml -l 172.16.5.54 # 登录新增的 PD 节点，编辑启动脚本：{deploy_dir}/scripts/run_pd.sh 1、移除 --initial-cluster=\"xxxx\" \\ 配置。 2、添加 --join=\"http://172.16.10.1:2379\" \\，IP 地址 （172.16.10.1） 可以是集群内现有 PD IP 地址中的任意一个。 3、在新增 PD 节点中手动启动 PD 服务： {deploy_dir}/scripts/start_pd.sh 4、使用 pd-ctl 检查新节点是否添加成功： /home/tidb/tidb-ansible/resources/bin/pd-ctl -u \"http://172.16.10.1:2379\" -d member # 滚动升级整个集群 ansible-playbook rolling_update.yml # 更新 Prometheus 配置并重启 ansible-playbook rolling_update_monitor.yml --tags=prometheus ","date":"2021-02-04","objectID":"/tidb%E4%BD%BF%E7%94%A8/:1:3","tags":["ddbs"],"title":"TIDB使用","uri":"/tidb%E4%BD%BF%E7%94%A8/"},{"categories":["分布式数据库"],"content":"四、tidb集群测试 4.1、sysbench基准库测试 sysbench安装 # 二进制安装 curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash sudo yum -y install sysbench 性能测试 # cpu性能测试 sysbench --test=cpu --cpu-max-prime=20000 run ----------------------------------start---------------------------------------- Number of threads: 1 Initializing random number generator from current time Prime numbers limit: 20000 Initializing worker threads... Threads started! CPU speed: events per second: 286.71 General statistics: total time: 10.0004s total number of events: 2868 Latency (ms): min: 3.46 avg: 3.49 max: 4.49 95th percentile: 3.55 sum: 9997.23 Threads fairness: events (avg/stddev): 2868.0000/0.00 execution time (avg/stddev): 9.9972/0.00 -----------------------------------end------------------------------------------- # 线程测试 sysbench --test=threads --num-threads=64 --thread-yields=100 --thread-locks=2 run ------------------------------------start----------------------------------------- Number of threads: 64 Initializing random number generator from current time Initializing worker threads... Threads started! General statistics: total time: 10.0048s total number of events: 108883 Latency (ms): min: 0.05 avg: 5.88 max: 49.15 95th percentile: 17.32 sum: 640073.32 Threads fairness: events (avg/stddev): 1701.2969/36.36 execution time (avg/stddev): 10.0011/0.00 -----------------------------------end----------------------------------------- # 磁盘IO测试 sysbench --test=fileio --num-threads=16 --file-total-size=3G --file-test-mode=rndrw prepare ----------------------------------start----------------------------------------- 128 files, 24576Kb each, 3072Mb total Creating files for the test... Extra file open flags: (none) Creating file test_file.0 Creating file test_file.1 Creating file test_file.2 Creating file test_file.3 Creating file test_file.4 Creating file test_file.5 Creating file test_file.6 Creating file test_file.7 Creating file test_file.8 Creating file test_file.9 Creating file test_file.10 Creating file test_file.11 Creating file test_file.12 Creating file test_file.13 Creating file test_file.14 Creating file test_file.15 Creating file test_file.16 Creating file test_file.17 Creating file test_file.18 Creating file test_file.19 Creating file test_file.20 Creating file test_file.21 Creating file test_file.22 Creating file test_file.23 Creating file test_file.24 Creating file test_file.25 Creating file test_file.26 Creating file test_file.27 Creating file test_file.28 Creating file test_file.29 Creating file test_file.30 Creating file test_file.31 Creating file test_file.32 Creating file test_file.33 Creating file test_file.34 Creating file test_file.35 Creating file test_file.36 Creating file test_file.37 Creating file test_file.38 Creating file test_file.39 Creating file test_file.40 Creating file test_file.41 Creating file test_file.42 Creating file test_file.43 Creating file test_file.44 Creating file test_file.45 Creating file test_file.46 Creating file test_file.47 Creating file test_file.48 Creating file test_file.49 Creating file test_file.50 Creating file test_file.51 Creating file test_file.52 Creating file test_file.53 Creating file test_file.54 Creating file test_file.55 Creating file test_file.56 Creating file test_file.57 Creating file test_file.58 Creating file test_file.59 Creating file test_file.60 Creating file test_file.61 Creating file test_file.62 Creating file test_file.63 Creating file test_file.64 Creating file test_file.65 Creating file test_file.66 Creating file test_file.67 Creating file test_file.68 Creating file test_file.69 Creating file test_file.70 Creating file test_file.71 Creating file test_file.72 Creating file test_file.73 Creating file test_file.74 Creating file test_file.75 Creating file test_file.76 Creating file test_file.77 Creating file test_file.78 Creating file test_file.79 Creating file test_file.80 Creating file test_file.81 Creating file test_file.82 Creating file test_file.83 Cre","date":"2021-02-04","objectID":"/tidb%E4%BD%BF%E7%94%A8/:1:4","tags":["ddbs"],"title":"TIDB使用","uri":"/tidb%E4%BD%BF%E7%94%A8/"},{"categories":["linux"],"content":"Shell编程基础02","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"条件表达式 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:1:0","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"文件判断 常用文件测试操作符: 常用文件测试操作符 说明 -d文件，d的全拼为directory 文件存在且为目录则为真，即测试表达式成立 -f文件，f的全拼为file 文件存在且为普通文件则为真，即测试表达式成立 -e文件，e的全拼为exist 文件存在则为真，即测试表达式成立。注意区别于“-f”，-e不辨别是目录还是文件 -r文件，r的全拼为read 文件存在且可读则为真，即测试表达式成立 -s文件，s的全拼为size 文件存在且文件大小不为0则为真，即测试表达式成立 -w文件，w的全拼为write 文件存在且可写则为真，即测试表达式成立 -x文件，x的全拼为executable 文件存在且可执行则为真，即测试表达式成立 -L文件，L的全拼为link 文件存在且为链接文件则为真，即测试表达式成立 fl -nt f2，nt 的全拼为 newer than 文件fl比文件f2新则为真，即测试表达式成立。根据文件的修改时间来计算 fl -ot f2，ot 的全拼为 older than 文件fl比文件f2旧则为真，即测试表达式成立。根据文件的修改时间来计算 判断文件是否存在 [root@kube-master ~]# [ -f /etc/hosts ] [root@kube-master ~]# echo $? 0 [root@kube-master ~]# [ -f /etc/hosts1 ] [root@kube-master ~]# echo $? 1 判断文件是否存在,返回方式 [root@kube-master ~]# [ -f /etc/hosts ] \u0026\u0026 echo \"文件存在\" || echo \"文件不存在\" 文件存在 [root@kube-master ~]# [ -f /etc/hosts1 ] \u0026\u0026 echo \"文件存在\" || echo \"文件不存在\" 文件不存在 判断目录是否存在 [root@kube-master ~]# [ -d /tmp ] \u0026\u0026 echo \"目录存在\" || echo \"目录不存在\" 目录存在 [root@kube-master ~]# [ -d /tmp1 ] \u0026\u0026 echo \"目录存在\" || echo \"目录不存在\" 目录不存在 使用变量的方法进行判断 dir=/etc1/;[ -d $dir ] \u0026\u0026 tar zcf etc.tar.gz $dir || echo \"$dir目录不存在\" ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:1:1","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"字符串判断 字符串测试操作符 常用字符串测试操作符 说明 -n “字符串” 若字符串的长度不为0,则为真，即测试表达式成立，n可以理解为no zero -Z “字符串” 若字符串的长度为0,则为真，即测试表达式成立，z可以理解为zero的缩写 “串 1”== “串 2” 若字符串1等于字符串2,则为真，即测试表达式成立，可使用\"==“代替”=\" “串 1” ！= “串 2” 若字符串1不等于字符串2,则为真，即测试表达式成立，但不能用\"!==“代替”!=\" 1.对于字符串的测试，一定要将字符串加双引号之后再进行比较。 2.空格非空 -z 判断字符串长度 [root@kube-master ~]# x= ; [ -z \"$x\" ] \u0026\u0026 echo \"输入为空\" || echo '输入有内容' 输入为空 [root@kube-master ~]# x=12 ; [ -z \"$x\" ] \u0026\u0026 echo \"输入为空\" || echo '输入有内容' 输入有内容 -n 判断字符串长度 [root@kube-master ~]# x=12 ; [ -n \"$x\" ] \u0026\u0026 echo \"输入有内容\" || echo '输入为空' 输入有内容 [root@kube-master ~]# x= ; [ -n \"$x\" ] \u0026\u0026 echo \"输入有内容\" || echo '输入为空' 输入为空 “串 1” == \" 串 2 “ 使用定义变量的方式进行判断 cmd=$1 [ \"$cmd\" == \"start\" ] \u0026\u0026 echo start # 测试 [root@kube-master ~]# cmd=start;[ \"$cmd\" == \"start\" ] \u0026\u0026 echo start start ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:1:2","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"整数判断 整数二元比较操作符参考 在[]以及test中使用的比较符号 在(())和[[]]中使用的比较符号 说明 -eq ==或= 相等，全拼为equal -ne ！= 不相等，全拼为not equal -gt \u003e 大于，全拼为greater than -ge \u003e= 大于等于，全拼为greater equal -lt \u003c 小于，全拼为less than -le \u003c= 小于等于，全拼为less equal 判断两数是否相等 [root@kube-master ~]# [ 1 -eq 1 ] [root@kube-master ~]# echo $? 0 [root@kube-master ~]# [ 1 -eq 2 ] [root@kube-master ~]# echo $? 1 大于等于 [root@kube-master ~]# [ 11 -ge 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 成立 小于 [root@kube-master ~]# [ 11 -lt 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 不成立 大于 [root@kube-master ~]# [ 11 -gt 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 成立 不等于 [root@kube-master ~]# [ 11 -ne 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 成立 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:1:3","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"逻辑符号 常用逻辑操作符 在[]和test中使用的操作符 说明 在[[]]和(())中使用的操作符 说明 -a -a[ 条件A -a 条件B ]A与B都要成立，整个表达式才成立 \u0026\u0026 and，与，两端都为真，则结果为真　 -o [ 条件A -o 条件B] A与B都不成立，整个表达式才不成立 || or，或，两端有一个为真，则结果为真 ！ ! not，非，两端相反，则结果为真 逻辑操作符与整数判断配合 [root@kube-master ~]# [ 11 -ne 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 成立 取反 [root@kube-master ~]# [ ! 11 -ne 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 不成立 两边都为真 [root@kube-master ~]# [ 11 -ne 1 -a 1 -eq 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 成立 至少有一边为真 [root@kube-master ~]# [ 11 -ne 1 -o 1 -eq 1 ] \u0026\u0026 echo \"成立\" || echo \"不成立\" 成立 感叹号的特殊用法 使用历史命令,感叹号加上history中的序号,即可执行 [root@kube-master ~]# !516 ls anaconda-ks.cfg bootime.avg setup.sh vim ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:1:4","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"if条件语句 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:2:0","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"三种语法 单分支语句 if [ -f /etc/hosts ] then echo '文件存在' fi 双分支语句 if [ -f /etc/hosts ] then echo \"文件存在\" else echo \"文件不存在\" echo \"...\" \u003e\u003e/tmp/test.log fi 多分支语句 if [ -f /etc/hosts ] then echo \" hosts文件存在\" elif [ -f /etc/host ] then echo \" host文件存在\" fi ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:2:1","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"if条件语句小结 单分支：一个条件一个结果 双分支：一个条件两个结果 多分支：多个条件多个结果 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:2:2","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"case条件结构语句 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:3:0","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"case语法结构 case \"字符串变量\" in 值1) 指令1 ;; 值2) 指令2 ;; 值*) 指令 esac ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:3:1","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"case与if的对比 case书写方式 case $name in 值1) 指令1 ;; 值2) 指令2 ;; *) 指令 esac if书写方式 if [ $name == \"值1\" ] then 指令1 elif [ $name == \"值2\" ] then 指令2 else 指令 fi ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:3:2","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"case值的书写方式 apple) echo -e \"$RED_COLORapple $RES\" ;; 也可以这样写，输入2种格式找同一个选项; apple|APPLE) echo -e \"$RED_COLORapple $RES\" ;; ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:3:3","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"case语句小结 case语句就相当于多分支的if语句。case语句的优势是更规范、易读。 case语句适合变量的值少，且为固定的数字或字符串集合。(1,2,3)或(start,stop,restart)。 系统服务启动脚本传参的判断多用case语句，多参考rpcbind/nfs/crond脚本；菜单脚本也可以使用case ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:3:4","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"其他补充说明 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:4:0","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"linux中产生随机数的方法 # 产生随机数方法一 [root@kube-master ~]# echo $RANDOM 29291 [root@kube-master ~]# echo $RANDOM 5560 [root@kube-master ~]# echo $RANDOM 2904 # 产生随机数方法二 [root@kube-master ~]#　openssl rand -base64 8 5AKtA67bdjg= # 产生随机数方法三 [root@kube-master ~]# yum install -y expect [root@kube-master ~]# man mkpasswd USAGE With no arguments, mkpasswd returns a new password. mkpasswd With a user name, mkpasswd assigns a new password to the user. mkpasswd don The passwords are randomly generated according to the flags below. FLAGS The -l flag defines the length of the password. The default is 9. The following example creates a 20 character password. mkpasswd -l 20 The -d flag defines the minimum number of digits that must be in the password. The default is 2. The following example creates a password with at least 3 digits. mkpasswd -d 3 The -c flag defines the minimum number of lowercase alphabetic characters that must be in the password. The default is 2. The -C flag defines the minimum number of uppercase alphabetic characters that must be in the password. The default is 2. The -s flag defines the minimum number of special characters that must be in the password. The default is 1. The -p flag names a program to set the password. By default, /etc/yppasswd is used if present, otherwise /bin/passwd is used. The -2 flag causes characters to be chosen so that they alternate between right and left hands (qwerty-style), making it harder for anyone watching passwords being entered. This can also make it easier for a password-guessing program. The -v flag causes the password-setting interaction to be visible. By default, it is suppressed. [root@kube-master ~]# mkpasswd -l 16 -d 2 -c 3 -C 3 -s 1 | md5sum |cut -c 2-18 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:4:1","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"echo 命令输出带颜色字符 # 彩色字体 echo -e \"\\033[30m 黑色字 clsn \\033[0m\" echo -e \"\\033[31m 红色字 clsn \\033[0m\" echo -e \"\\033[32m 绿色字 clsn \\033[0m\" echo -e \"\\033[33m 黄色字 clsn \\033[0m\" echo -e \"\\033[34m 蓝色字 clsn \\033[0m\" echo -e \"\\033[35m 紫色字 clsn \\033[0m\" echo -e \"\\033[36m 天蓝字 clsn \\033[0m\" echo -e \"\\033[37m 白色字 clsn \\033[0m\" # 彩色底纹 echo -e \"\\033[40;37m 黑底白字 clsn \\033[0m\" echo -e \"\\033[41;37m 红底白字 clsn \\033[0m\" echo -e \"\\033[42;37m 绿底白字 clsn \\033[0m\" echo -e \"\\033[43;37m 黄底白字 clsn \\033[0m\" echo -e \"\\033[44;37m 蓝底白字 clsn \\033[0m\" echo -e \"\\033[45;37m 紫底白字 clsn \\033[0m\" echo -e \"\\033[46;37m 天蓝白字 clsn \\033[0m\" # 特效字体 echo -e　\"\\033[0m 关闭所有属性\" echo -e \"\\033[1m 设置高亮度\" echo -e \"\\033[4m 下划线\" echo -e \"\\033[5m 闪烁\" echo -e \"\\033[7m 反显\" echo -e \"\\033[8m 消隐\" echo -e \"\\033[30m — \\033[37m 设置前景色\" echo -e \"\\033[40m — \\033[47m 设置背景色\" echo -e \"\\033[nA 光标上移 n 行\" echo -e \"\\033[nB 光标下移 n 行\" echo -e \"\\033[nC 光标右移 n 行\" echo -e \"\\033[nD 光标左移 n 行\" echo -e \"\\033[y;xH 设置光标位置\" echo -e \"\\033[2J 清屏\" echo -e \"\\033[K 清除从光标到行尾的内容\" echo -e \"\\033[s 保存光标位置\" echo -e \"\\033[u 恢复光标位置\" echo -e \"\\033[?25l 隐藏光标\" echo -e \"\\033[?25h 显示光标\" ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:4:2","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"显示文本中的隐藏字符 使用cat命令查看文本中的隐藏字符 [root@kube-master ~]# cat --help Usage: cat [OPTION]... [FILE]... Concatenate FILE(s), or standard input, to standard output. -A, --show-all equivalent to -vET -b, --number-nonblank number nonempty output lines, overrides -n -e equivalent to -vE -E, --show-ends display $ at end of each line -n, --number number all output lines -s, --squeeze-blank suppress repeated empty output lines -t equivalent to -vT -T, --show-tabs display TAB characters as ^I -u (ignored) -v, --show-nonprinting use ^ and M- notation, except for LFD and TAB --help display this help and exit --version output version information and exit With no FILE, or when FILE is -, read standard input. Examples: cat f - g Output f's contents, then standard input, then g's contents. cat Copy standard input to standard output. GNU coreutils online help: \u003chttp://www.gnu.org/software/coreutils/\u003e For complete documentation, run: info coreutils 'cat invocation 使用cat -A查看隐藏的字符: [root@kube-master ~]# cat -A /etc/hosts ::1^Ilocalhost^Ilocalhost.localdomain^Ilocalhost6^Ilocalhost6.localdomain6$ 127.0.0.1^Ilocalhost^Ilocalhost.localdomain^Ilocalhost4^Ilocalhost4.localdomain4$ $ 172.18.77.102^IiZwz91ivbj51belpslwpogZ^IiZwz91ivbj51belpslwpogZ$ $ $ $ $ # hostname$ 172.18.77.102 kube-master$ 49.235.236.38 kube-node$ 120.79.77.84 apiserver.cluster.local$ ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:4:3","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"shell 脚本段注释方法 方法一： \u003c\u003cEOF 内容 EOF 方法二: 一行注释方法 → : '内容' 段注释方法 ↓ :' http://blog.znix.top ' ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/:4:4","tags":["Linux"],"title":"Shell编程基础02","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8002/"},{"categories":["linux"],"content":"Shell编程基础01","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"前言 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:1:0","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"为什么学Shell Shell脚本语言是实现Linux/UNIX系统管理及自动化运维所必备的重要工具， Linux/UNIX系统的底层及基础应用软件的核心大都涉及Shell脚本的内容。每一个合格 的Linux系统管理员或运维工程师，都需要能够熟练地编写Shell脚本语言，并能够阅 读系统及各类软件附带的Shell脚本内容。只有这样才能提升运维人员的工作效率，适 应曰益复杂的工作环境，减少不必要的重复工作，从而为个人的职场发展奠定较好的基础 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:1:1","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"什么是shell Shell是一个命令解释器，它在操作系统的最外层，负责直接与用户对话，把用户的输入解释给操作系统，并处理各种各样的操作系统的输出结果，输出屏幕返回给用户。 这种对话方式可以是： 交互的方式：从键盘输入命令，通过/bin/bash的解析，可以立即得到Shell的回应. ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:1:2","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"什么是shell脚本 命令、变量和流程控制语句等有机的结合起来，shell脚本擅长处理纯文本类型的数据，而linux中，几乎所有的配置文件，日志，都是纯文本类型文件。 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:1:3","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"脚本语言的分类 一、编译型语言 定义：指用专用的编译器，针对特定的操作平台（操作系统）将某种高级语言源代码一次性翻译成可被硬件平台直接运行的二进制机器码（具有操作数，指令、及相应的格式），这个过程叫做编译（./configure make makeinstall ）；编译好的可执行性文件（.exe），可在相对应的平台上运行（移植性差，但运行效率高）。。 典型的编译型语言有， C语言、C++等。 另外，Java语言是一门很特殊的语言，Java程序需要进行编译步骤，但并不会生成特定平台的二进制机器码，它编译后生成的是一种与平台无关的字节码文件（*.class）（移植性好的原因），这种字节码自然不能被平台直接执行，运行时需要由解释器解释成相应平台的二进制机器码文件；大多数人认为Java是一种编译型语言，但我们说Java即是编译型语言，也是解释型语言也并没有错。 二、解释型语言 定义：指用专门解释器对源程序逐行解释成特定平台的机器码并立即执行的语言；相当于把编译型语言的编译链接过程混到一起同时完成的。 解释型语言执行效率较低，且不能脱离解释器运行，但它的跨平台型比较容易，只需提供特定解释器即可。 常见的解释型语言有， Python（同时是脚本语言）与Ruby等。 三、脚本语言 定义：为了缩短传统的编写-编译-链接-运行（edit-compile-link-run）过程而创建的计算机编程语言。 特点：程序代码即是最终的执行文件，只是这个过程需要解释器的参与，所以说脚本语言与解释型语言有很大的联系。脚本语言通常是被解释执行的，而且程序是文本文件。 典型的脚本语言有，JavaScript，Python，shell等。 其他常用的脚本语句种类 PHP是网页程序，也是脚本语言。是一款更专注于web页面开发（前端展示）的脚本语言，例如：Dedecms,discuz。PHP程序也可以处理系统日志，配置文件等，php也可以调用系统命令。 Perl脚本语言。比shell脚本强大很多，语法灵活、复杂，实现方式很多，不易读，团队协作困难，但仍不失为很好的脚本语言，存世大量的程序软件。MHA高可用Perl写的 Python，不但可以做脚本程序开发，也可以实现web程序以及软件的开发。近两年越来越多的公司都会要求会Python。 Shell脚本与php/perl/python语言的区别和优势？ shell脚本的优势在于处理操作系统底层的业务 （linux系统内部的应用都是shell脚本完成）因为有大量的linux系统命令为它做支撑。2000多个命令都是shell脚本编程的有力支撑，特别是grep、awk、sed等。例如：一键软件安装、优化、监控报警脚本，常规的业务应用，shell开发更简单快速，符合运维的简单、易用、高效原则. PHP、Python优势在于开发运维工具以及web界面的管理工具，web业务的开发等。处理一键软件安装、优化，报警脚本。常规业务的应用等php/python也是能够做到的。但是开发效率和复杂比用shell就差很多了。 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:1:4","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"系统中的shell cat /etc/shells /bin/sh /bin/bash /usr/bin/sh /usr/bin/bash ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:1:5","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"脚本书写规范 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:2:0","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"脚本统一存放目录 mkdir -p /services/scripts;cd /services/scripts ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:2:1","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"编辑脚本使用vim # cat ~/.vimrc autocmd BufNewFile *.py,*.go,*.sh,*.java exec \":call SetTitle()\" func SetTitle() if expand(\"%:e\") == 'sh' call setline(1,\"#!/bin/bash\") call setline(2, \"##############################################################\") call setline(3, \"# File Name: \".expand(\"%\")) call setline(4, \"# Version: V1.0\") call setline(5, \"# Author: Mikel_Pan\") call setline(6, \"# Organization: https://github.com/plyxgit/Cnblog.git\") call setline(7, \"# Created Time : \".strftime(\"%F %T\")) call setline(8, \"# Description:\") call setline(9, \"##############################################################\") call setline(10, \"\") endif endfunc ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:2:2","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"文件名规范 名字要有意义，并且结尾以 .sh 结束 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:2:3","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"开发的规范和习惯小结 放在统一的目录 脚本以.sh为扩展名 开头指定脚本解释器。 开头加版本版权等信息，可配置~/.vimrc文件自动添加。 脚本不要用中文注释，尽量用英文注释。 代码书写优秀习惯 a、成对的内容一次性写出来，防止遗漏，如[ ]、' ‘、\" “等 b、[ ]两端要有空格，先输入[ ],退格，输入2个空格，再退格写。 c、流程控制语句一次书写完，再添加内容。(if 条件 ; then 内容;fi)ddd d、通过缩进让代码易读。 f、脚本中的引号都是英文状态下的引号，其他字符也是英文状态。 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:2:4","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"shell脚本的执行 sh/bash scripts.sh chown +x ./scripts.sh \u0026\u0026 ./scripts.sh source scripts.sh . (空格) scripts.sh cat oldboyedu.sh |bash # 效率较低 source 与 .（点） 的作用 # help source |head -2 source: source 文件名 [参数] 在当前 shell 中执行一个文件中的命令。 .(点) help . |head -2 .: . 文件名 [参数] 在当前 shell 中执行一个文件中的命令。 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:3:0","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"shell 的变量 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:0","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"什么是变量 变量可以分为两类：环境变量（全局变量）和普通变量（局部变量） 环境变量也可称为全局变量，可以在创建他们的Shell及其派生出来的任意子进程shell中使用，环境变量又可分为自定义环境变量和Bash内置的环境变量 普通变量也可称为局部变量，只能在创建他们的Shell函数或Shell脚本中使用。普通变量一般是由开发者用户开发脚本程序时创建的。 特殊变量 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:1","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"环境变量 使用 env/declare/set/export -p 命令查看系统中的环境变量，这三个命令的的输出方式稍有不同。 # env XDG_SESSION_ID=6249 HOSTNAME=kube-master TERM=xterm SHELL=/bin/bash HISTSIZE=1000 SSH_CLIENT=14.103.36.188 56875 22 SSH_TTY=/dev/pts/0 USER=root 输出一个系统中的 环境变量 [root@kube-master ~]# echo $HOSTNAME kube-master ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:2","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"普通变量 本地变量在用户当前的Shell生存期的脚本中使用。例如，本地变量OLDBOY取值为bingbing，这个值在用户当前Shell生存期中有意义。如果在Shell中启动另一个进程或退出，本地变量值将无效. a=1;echo $a ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:3","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"export命令 # help export export: export [-fn] [名称[=值] ...] 或 export -p 为 shell 变量设定导出属性。 标记每个 NAME 名称为自动导出到后续命令执行的环境。如果提供了 VALUE 则导出前将 VALUE 作为赋值。 export 命令说明： 当前shell窗口及子shell窗口生效 在新开的shell窗口不会生效，生效需要写入配置文件 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:4","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"环境变量相关配置文件 /etc/proflie /etc/bashrc ~/.bashrc ~/.bash_profile /etc/proflie.d/ # 目录 文件读取顺序： ① /etc/profile ② ~/.bash_profile ③ ~/.bashrc ④ /etc/bashrc ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:5","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["linux"],"content":"环境变量的知识小结 变量名通常要大写。 变量可以在自身的Shell及子Shell中使用。 常用export来定义环境变量。 执行env默认可以显示所有的环境变量名称及对应的值。 输出时用“$变量名”，取消时用“unset变量名”。 书写crond定时任务时要注意，脚本要用到的环境变量最好先在所执行的Shell脚本中重新定义。 如果希望环境变量永久生效，则可以将其放在用户环境变量文件或全局环境变量文件里。 ","date":"2021-02-03","objectID":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/:4:6","tags":["Linux"],"title":"Shell编程基础01","uri":"/shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%8001/"},{"categories":["数据库"],"content":"Mysql检测工具使用","date":"2021-02-03","objectID":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","tags":["Mysql"],"title":"Mysql检测工具使用","uri":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"一、mysqldumpslow工具使用 1.1、修改配置文件开启慢查询 mysql 开启慢查询 systemctl stop mysqld echo -e \"# 开启慢查询\\nslow_query_log = 1\\nslow_query_log_file = /var/lib/mysql/slow-query.log\\nlong_query_time = 1\\nlog_queries_not_using_indexes = 1\" \u003e\u003e/etc/my.cnf # 重启mysql systemctl restart mysqld # 登录mysql mysql -uroot -pP@ssw0rd1 select sleep(1); 1.2、修改变量开启慢查询 set global slow_query_log='ON'; set global slow_query_log_file='/var/lib/mysql/logs/slow.log'; set global long_query_time=1; 使用mysqldumpslow 工具分析 慢查询日志 -s：排序方式，值如下 c：查询次数 t：查询时间 l：锁定时间 r：返回记录 ac：平均查询次数 al：平均锁定时间 ar：平均返回记录书 at：平均查询时间 -t：top N查询 -g：正则表达式 1、访问次数最多的5个sql语句 mysqldumpslow -s c -t 5 /var/lib/mysql/slow-query.log ----------------------------------start---------------------------------------- Reading mysql slow query log from /var/lib/mysql/slow-query.log Count: 2 Time=1.50s (3s) Lock=0.00s (0s) Rows=1.0 (2), select sleep(N) Died at /usr/bin/mysqldumpslow line 161, \u003c\u003e chunk 2. ----------------------------------end------------------------------------------- ","date":"2021-02-03","objectID":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/:0:1","tags":["Mysql"],"title":"Mysql检测工具使用","uri":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"二、mysqlsla工具使用 mysqlsla安装 wget http://hackmysql.com/scripts/mysqlsla-2.03.tar.gz tar zxvf mysqlsla-2.03.tar.gz -C /usr/local/src cd /usr/local/src/mysqlsla-2.03 yum install -y perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker yum install -y perl-DBD-MySQL perl Makefile.PL make \u0026\u0026 make install mysqlsla 分析慢查询日志 mysqlsla -lt slow -sf \"+select,update,insert\" -top 10 slow.log \u003e /root/test_time.log mysqlsla -lt slow -sf \"+select,update,insert\" -top 10 -sort c_sum -db databasename slow.log \u003e /root/test_time.log 通过mysqlsla 查询日志分析 mysqlsla -lt slow -sf \"+select\" -top 10 /var/lib/mysql/slow-query.log ---------------------------------start-------------------------------------- Report for slow logs: /var/lib/mysql/slow-query.log 2 queries total, 1 unique Sorted by 't_sum' Grand Totals: Time 3 s, Lock 0 s, Rows sent 2, Rows Examined 0 ______________________________________________________________________ 001 ___ Count : 2 (100.00%) Time : 3.001489 s total, 1.500745 s avg, 1.000509 s to 2.00098 s max (100.00%) Lock Time (s) : 0 total, 0 avg, 0 to 0 max (0.00%) Rows sent : 1 avg, 1 to 1 max (100.00%) Rows examined : 0 avg, 0 to 0 max (0.00%) Database : Users : root@localhost : 100.00% (2) of query, 100.00% (2) of all users Query abstract: SELECT sleep(N); Query sample: select sleep(1); ---------------------------------end-------------------------------------- ","date":"2021-02-03","objectID":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/:0:2","tags":["Mysql"],"title":"Mysql检测工具使用","uri":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"三、pt工具使用 1、pt 工具安装 #!/bin/bash percona-toolkit-yum-install(){ # 下载最新版percona-toolkits 包 下载地址：https://www.percona.com/downloads/ wget -P /tar https://www.percona.com/downloads/percona-toolkit/3.0.12/binary/redhat/7/x86_64/percona-toolkit-3.0.12-re3a693a-el7-x86_64-bundle.tar tar xvf /tar/percona-toolkit-3.0.12-re3a693a-el7-x86_64-bundle.tar # 安装依赖 yum install -y perl perl-DBI perl-DBD-MySQL perl-Time-HiRes perl-IO-Socket-SSL perl-Digest-MD5 rpm -ivh percona-toolkit-3.0.12-1.el7.x86_64.rpm } percona-toolkit-unline-install(){ # 安装离线安装包 rpm -ivh /percona-yum/*.rpm rpm -ivh percona-toolkit-3.0.12-1.el7.x86_64.rpm } --create-review-table 当使用--review参数把分析结果输出到表中时，如果没有表就自动创建 --create-history-table 当使用--history参数把分析结果输出到表中时，如果没有表就自动创建 --filter 对输入的慢查询按指定的字符串进行匹配过滤后再进行分析 --limit 限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时间占比从大到小排序，输出到总和达到50%位置截止。 --host mysql服务器地址 --user mysql用户名 --password mysql用户密码 --history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句，且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型查询的历史变化。 --review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。 --output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、json、json-anon，一般使用report，以便于阅读。 --since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间点，也可以是简单的一个时间值：s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。 --until 截止时间，配合—since可以分析一段时间内的慢查询 2、percona-toolkit用法 # 查看慢查询日志 pt-query-digest slow-query.log --------------------------------------start--------------------------------------- # 280ms user time, 40ms system time, 25.93M rss, 220.21M vsz # Current date: Wed Jan 2 14:51:50 2019 # Hostname: localhost.localdomain # Files: slow-query.log # Overall: 2 total, 1 unique, 0.00 QPS, 0.01x concurrency ________________ # Time range: 2018-12-29T08:56:22 to 2018-12-29T09:04:54 # Attribute total min max avg 95% stddev median # ============ ======= ======= ======= ======= ======= ======= ======= # Exec time 3s 1s 2s 2s 2s 707ms 2s # Lock time 0 0 0 0 0 0 0 # Rows sent 2 1 1 1 1 0 1 # Rows examine 0 0 0 0 0 0 0 # Query size 30 15 15 15 15 0 15 # Profile # Rank Query ID Response time Calls R/Call V/M # ==== ================================== ============= ===== ====== ===== # 1 0x59A74D08D407B5EDF9A57DD5A41825CA 3.0015 100.0% 2 1.5007 0.33 SELECT # Query 1: 0.00 QPS, 0.01x concurrency, ID 0x59A74D08D407B5EDF9A57DD5A41825CA at byte 565 # This item is included in the report because it matches --limit. # Scores: V/M = 0.33 # Time range: 2018-12-29T08:56:22 to 2018-12-29T09:04:54 # Attribute pct total min max avg 95% stddev median # ============ === ======= ======= ======= ======= ======= ======= ======= # Count 100 2 # Exec time 100 3s 1s 2s 2s 2s 707ms 2s # Lock time 0 0 0 0 0 0 0 0 # Rows sent 100 2 1 1 1 1 0 1 # Rows examine 0 0 0 0 0 0 0 0 # Query size 100 30 15 15 15 15 0 15 # String: # Hosts localhost # Users root # Query_time distribution # 1us # 10us # 100us # 1ms # 10ms # 100ms # 1s ################################################################ # 10s+ # EXPLAIN /*!50100 PARTITIONS*/ select sleep(2)\\G -------------------------------------end----------------------------------------- 3、pt分析慢查询 pt-query-digest slow.log \u003e slow_report.log pt-query-digest --since=12h slow.log \u003e slow_report2.log pt-query-digest slow.log --since '2014-04-17 09:30:00' --until '2014-04-17 10:00:00'\u003e \u003e slow_report3.log pt-query-digest--filter '$event-\u003e{fingerprint} =~ m/^select/i' slow.log\u003eslow_report4.log pt-query-digest--filter '($event-\u003e{user} || \"\") =~ m/^root/i' slow.log\u003e slow_report5.log pt-query-digest--filter '(($event-\u003e{Full_scan} || \"\") eq \"yes\") ||(($event-\u003e{Full_join} || \"\") eq \"yes\")' slow.log\u003e slow_report6.log pt-query-digest --user=root –password=abc123 --review h=localhost,D=test,t=query_review --create-review-table slow.log pt-query-digest --user=root –password=abc123 --review h=localhost,D=test,t=query_ history--create-review-table slow.log_20140401 pt-query-digest --user=root –password=abc123--review h=localhost,D=test,t=query_history--create-re","date":"2021-02-03","objectID":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/:0:3","tags":["Mysql"],"title":"Mysql检测工具使用","uri":"/mysql%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"Mysql主从复制","date":"2021-02-03","objectID":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","tags":["Mysql"],"title":"Mysql主从复制","uri":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["数据库"],"content":"一、mysql主从同步原理 Mysql主从复制也可以称为Mysql主从同步，它是构建数据库高可用集群架构的基础。它通过将一台主机的数据复制到其他一台或者多台主机上，并重新应用日志（realy log）中的SQL语句来实现复制功能。Mysql支持单向，双向，链式级联，异步复制，复制过程中一台服务器充当主库（master），而一个或者多个服务器充当从库（slave） 1.1、主从复制功能 主从复制原理：master服务器上工作线程I/O dump thread，从服务器上两个工作线程，一个是I/O thread，另一个是SQL thread。 主库把外界接收到的SQL请求记录到自己的binlog日志中，从库的I/O thread去请求主库的binlog日志，并将得到的binlog日志写到自己的Realy log（中继日志）文件中。然后在从库上重做应用中继日志中的SQL语句。主库通过I/O dump thread 给从库I/O thread 传送binlog日志。 1.2、复制中的参数详解 log-bin：搭建主从复制，必须开启二进制日志 server-id：mysql在同一组主从结构中的唯一标识 sever-uuid：存放在数据目录中的auto.cnf中 read only：设置从库为只读转态 binglog_format: 二进制日志的格式，使用row模式 log_salve_updates: 将master服务器上获取的数据信息记录到从服务器的二进制日志文件中 binglog-db-db：选择性复制数据库（在主库上使用） binglog-ignore-db： 忽略某个库的复制 gtid_mode: gtid模式是否开启，使用gtid模式，设置gtid_mode=on enforce-gtid-consistency: 使用gtid复制，开启，enforce-gtid-consistency=on ","date":"2021-02-03","objectID":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:0:1","tags":["Mysql"],"title":"Mysql主从复制","uri":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["数据库"],"content":"二、mysql主从复制（binlog） 2.1、修改主库配置文件 vim /etc/my.cnf [mysqld] ####: for binlog server-id=1 binlog_format =row # row log-bin =/data/mysqlData/binlog/mysql-bin log-bin-index =/data/mysqlData/binlog/mysql-bin.index # off binlog_rows_query_log_events =on # off log_slave_updates =on # off expire_logs_days =7 # 0 binlog_cache_size =65536 # 65536(64k) #binlog_checksum =none # CRC32 sync_binlog =0 # 1 slave-preserve-commit-order =ON # 2.2、主库上执行操作 # 创建主从复制账号 create user 'repl'@'192.168.5.%' identified by 'repl@2019#pl'; grant replication slave on *.* to 'repl'@'192.168.5.%'; flush privileges; # 导出主库数据 mysqldump --single-transaction -uroot -proot123 --master-data=2 --flush-logs --events --triggers --routines -A \u003e all.sql # 记录binlog文件和position号 head -n 30 all.sql | grep \"MASTER_LOG_FILE\" head -n 30 all.sql | grep \"MASTER_LOG_POS\" # 备份文件传递到从服务器上 scp all.sql root@slave:/root/ 2.3、修改从库的配置文件 server_id = 2 binlog-ignore-db =mysql binlog_format =row log-bin = =/data/mysqlData/binlog/slave1-bin log-bin-index =/data/mysqlData/binlog/salve1-bin.index log-slave-updates =on expire_logs_days =7 sync_binlog = 0 relay_log =/data/mysqlData/relaylog/relay-bin log_slave_updates =1 2.4、配置主从 # 导入数据 mysql -uroot -proot123 \u003c all.sql # 重置主从 reset slave all # 数据库命名执行配置 CHANGE MASTER TO MASTER_HOST='192.168.248.137', MASTER_USER='repl', MASTER_PASSWORD='repl@2019#pl', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=3034; # 开启主从 start salve # 查看主从复制状态 show slave status\\G ","date":"2021-02-03","objectID":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:0:2","tags":["Mysql"],"title":"Mysql主从复制","uri":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["数据库"],"content":"三、mysql主从复制 （gtid） 3.1、修改主库配置文件 vim /etc/my.cnf [mysqld] ####: for binlog server-id=1 binlog_format =row # row log-bin =/data/mysqlData/binlog/mysql-bin log-bin-index =/data/mysqlData/binlog/mysql-bin.index # off binlog_rows_query_log_events =on # off log_slave_updates =on # off expire_logs_days =7 # 0 binlog_cache_size =65536 # 65536(64k) #binlog_checksum =none # CRC32 sync_binlog =0 # 1 slave-preserve-commit-order =ON # ####: gitd gtid-mode = ON enforce-gtid-consistency = ON 3.2、主库上执行操作 # 创建主从复制账号 create user 'repl'@'192.168.5.%' identified by 'repl@2019#pl' grant replication slave *.* to 'repl'@'192.168.5.%' flush privileges # 导出主库数据 mysqldump --single-transaction -uroot -proot123 --opt --master-data=2 --flush-logs --events --triggers --routines -A \u003e all.sql 3.3、修改mysql从服务器配置 server_id = 2 binlog-ignore-db =mysql binlog_format =row log-bin = =/data/mysqlData/binlog/slave-bin log-bin-index =/data/mysqlData/binlog/salve-bin.index log-slave-updates =on expire_logs_days =7 sync_binlog = 0 relay_log =/data/mysqlData/relaylog/relay-bin read_only =1 log_slave_updates =1 ####: gitd gtid-mode = ON enforce-gtid-consistency = ON 3.4、配置主从 # 清空 gtid_executed reset master # 数据导入 mysql -uroot -proot123 \u003c all.sql # 配置主从 CHANGE MASTER TO MASTER_HOST='192.168.248.137', MASTER_USER='repl', MASTER_PASSWORD='repl@2019#pl', MASTER_PORT=3306, MASTER_AUTO_POSITION = 1； # 开启主从 start slave # 查看主从复制状态 show slave status\\G 3.5、跳过事务 stop slave set gtid_next='f75ae43f-3f5e-11e7-9b98-001c4297532a:20' begin commit set gtid_next='AUTOMATIC' start slave ","date":"2021-02-03","objectID":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:0:3","tags":["Mysql"],"title":"Mysql主从复制","uri":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["数据库"],"content":"四、mysql从传统模式改为gtid 4.1、修改全局变量 1、修改enforce_gtid_consistency为warn set global enforce_gtid_consistency=warn; 2、修改enforce_gtid_consistency为on set global enforce_gtid_consistency=on; 3、修改gtid模式为off_permissive set global gtid_mode=off_permissive; 4、修改gtid模式为on_permissive set global gtid_mode=on_permissive; 5、确认从库的onging_anonymous_transaction_count参数是否为0 show global status like '%ongoing_anonymous_%'; 6、开启gtid set global gtid_mode=on; 7、开启主从复制 stop slave change master to master_auto_position=1; start slave 4.2、修改my.cnf配置文件 # 主库添加配置 gtid_mode=on enforce_gtid_consistency=on # 主库添加配置 gtid_mode=on enforce_gtid_consistency=on log_slave_updates=1 4.3、数据导出导入 # 主库数据导出 mysqldump --single-transaction -uroot -proot123 --opt --master-data=2 --flush-logs --events --triggers --routines -A \u003e all.sql # 从库数据导入 systemctl restart mysqld reset mysql -uroot -p \u003c all.sql 4.4、从库开启主从 reset master # 配置msater主机信息 CHANGE MASTER TO MASTER_HOST='192.168.0.12', MASTER_USER='repl', MASTER_PASSWORD='password', MASTER_PORT=3306, MASTER_AUTO_POSITION = 1; # 开启主从 start slave 4.5、gtid跳过事件 方法一 # 查看gtid_next的值 show variables like '%next%'; # 停止从库 stop slave; # 修改gtid为下一个值 set gtid_next='6a5a698f-18eb-11e9-afa0-6c92bf45c92e:17'; begin commit SET GTID_NEXT=\"AUTOMATIC\"; start slave; show slave status; 方法二 # 重置master stop slave; reset master; SET @@GLOBAL.GTID_PURGED ='8f9e146f-0a18-11e7-810a-0050568833c8:1-4; START SLAVE; 方法三 # pt 忽略错误码 pt-slave-resetart -S /var/lib/mysql/mysql.sock —error-numbers=1062 --user=root --password='bc.123456' # pt 忽略错误信息 pt-slave-resetart -S /var/lib/mysql/mysql.sock —error-numbers=1062 --user=root --password='bc.123456' ","date":"2021-02-03","objectID":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/:0:4","tags":["Mysql"],"title":"Mysql主从复制","uri":"/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"},{"categories":["数据库"],"content":"Mysql事务详解","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"索引是什么? 索引是什么了，查阅了官方文档。官方文档写了索引的作用和没有索引会带来全表扫描，非常费时间。 Indexes are used to find rows with specific column values quickly. Without an index, MySQL must begin with the first row and then read through the entire table to find the relevant rows. 简单的说索引是提高查询速度。这个很好理解，就像是以前的英文词典，找单词如果没有前面目录的话，效率很低，得全文找一遍。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:1:0","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"索引实现原理 要搞清楚索引的实现原理，先看看索引的底层实现，MySQL索引大部分采用B-Tree实现，B-Tree又有B-树和B+树。还有一些使用Hash索引。本文主要介绍B-Tree(Balance Tree)。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:2:0","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"二叉搜索树 再说B-Tree之前，先简单了解一下二叉搜索树（Binary Search Trees）。 理解二叉搜索树，对于后面理解B-和B+树很有帮助，因为这2种有些特性跟二叉搜索树很像。二叉搜索树的特点是左孩子的值小于父亲节点的值，父亲节点的值小于右孩子的值，即按二叉树的中序遍历，刚好是一个按小到大排序的。二叉搜索树的查找就可以使用二分查找，如果要查找10，因为10比27小，所以往左孩子找，10\u003c14，还在左孩子找。最坏的情况下，查找的次数等于树的高度。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:2:1","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"B-树 通常意义上说B-Tree，一般是指B-树，也可以叫平衡多路搜索树，平衡的意思可以区了解一下平衡二叉树(它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。)，多路的意思就是非叶子节点的孩子至少有2个。 B-Tree的特征也是非常烧脑，查看了算法导论书籍，也是琢磨了很久。下图为算法导论书中一张图，浅阴影部分为查找字母R时检查过的结点。 下面算法导论书中对B-树的特征： 每个结点x有如下属性： x.n。它表示储存在 x中的关键字的个数； x.key1,x.key2,…,x.keyn。它们表示x的n个关键字，以非降序存放，即x.key1≤x.key2≤…≤x.keyn； x.leaf。它是一个布尔值，如果x是叶结点，它为TRUE；否则为FALSE； x.c1,x.c2,…,x.cn+1。它们是指向自己孩子的指针。如果该结点是叶节点，则没有这些属性。 关键字x.keyi对存储在各子树中的关键字范围进行分割，即满足：k1≤x.key1≤k2≤x.key2≤…≤x.keyn≤kn+1。其中，ki(i=1,2,….,n+1)表示任意一个储存在以x.ci为根的子树中的关键字。 每个叶结点具有相同的深度，即叶的高度h。 每个结点所包含的关键的个数有上下界。用一个被称为最小度数的固定整数t(t≥2)来表示这些界： 下界：除了根结点以外的每个结点必须至少有t−1个关键字。因此，除了根结点外的每个内部结点至少有t个孩子。 上界：每个结点至多包含2t−1个关键字。因此，一个内部结点至多可能有2t个孩子。当一个结点恰好有2t−1个关键字时，称该结点为满的(full)。 第1点是说每一个节点包括的信息：n表示结点中存储关键字的个数，比如上图上M的左孩子就存了2个关键字，D和H；x.key，说的是具体的关键字的信息，比如D，D实际是有2个部分组成，可以理解为一个map，{key: data}，x.key广义上就是表示这个map，包括了具体的key和存储的数据data，通常说是一条记录；x.leaf是说整个结点是否是叶子结点。 第2点表示如果不是叶子结点，每个结点还有一个属性，就是指向它n个孩子的指针，比如上图中的DH结点，有3个孩子，则有3个指针指向自己的孩子。 第3点表示说每个结点的关键字按小到大的顺序依次排列，同时各个结点之间也满足上面提到的二叉搜索树的特点，左孩子的值\u003c父亲节点的值\u003c右孩子的值。 第4点是说每个叶子结点高度一样，看图就可以明白，这也是平衡二字的由来。 第5点说的每个结点关键字的数量的限制，不可能每个结点可以无限存储关键字。t是最小度数，需要理解这些，可以谷歌一下度数和阶数的定义，上图是4阶的B-Tree。上图中t=2，则每个内部结点可以允许有2、3、4个孩子。孩子数范围[t, 2t]，每个结点的关键字范围[t-1, 2t-1]。这个要区分。 下面更加形象的给出4阶的B-Tree。 由于B-Tree的特性，在B-Tree中按key检索数据的算法非常高效：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败. ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:2:2","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"B+树 B+树其实是B-树变种。 与B-树最大的区别是内部结点不存储data，只存储key。如下图： 一般数据库系统中使用的B+树再上图经典的基础上再进行了优化，变成了带顺序访问指针的B+树， 如下图。这样就提高区间访问的性能，例如如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:2:3","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"B+ 树实现数据库索引 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:3:0","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"磁盘存储原理 数据导论书中开头就是说： B树是为磁盘或其他直接存取的辅助存储设备而设计的一种平衡搜索树。上面提到了辅助存储设备，那我们就来看看其中原理，到底由来是什么？ 计算机系统有主存和基于磁盘的辅存，主存通常就是我们说的RAM，也就是内存，这里不展开说它。索引文件本身很大，一般不会存在内存里，因此索引往往是以文件的形式存储在磁盘里，所以索引检索需要磁盘I/O操作。下图为一个典型的磁盘驱动器。 磁盘读取数据靠的是磁盘的机械运动。每次磁盘读取的时间有三部分：寻道时间、旋转延迟、传输时间。寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略。那么访问一次磁盘读取数据的时间，即一次磁盘I/O操作的时间约9ms左右，这相对于主存存储时间50ns高出5个数量级。看着还不错的，但是一台500 -MIPS的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。 为了缩短磁盘读取的时间，计算机做了一些优化：磁盘预读。磁盘预读是基于局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。所以磁盘I/O操作时不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。 文件很大，不可能全部存储在内存中，故要存储到磁盘上。 索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数，因为每次磁盘I/O消耗时间都是非常多的。 局部性原理与磁盘预读，预读的长度一般为页（page）的整倍数。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:3:1","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"B-/B+的查找性能 数据库系统巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。B-树也利用这一点，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一次磁盘I/O就读取了一页的数据。下面是B-树的示例图 根据B-Tree的定义，可知检索一次最多需要访问h个节点（h个树的高度）。B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。所以B-Tree作为索引效率是非常高，相比平衡二叉树、红黑树要高很多，因为这些树的h一般都比较深。 下面附一张B+树的直观图: B+树比B-树更加适合作为磁盘的索引数据结构，原因是B+树的内部结点不存储data，内部结点的出度d越大，那么渐进复杂度越小。出度d的上限取决于节点内key和data的大小： dmax=floor(pagesize/(keysize+datasize+pointsize)) 一般3层B+树可以存储上百万的数据，也就是读取上百万的数据，只需要3次磁盘I/O，可见这效率，大大提升了。如果没有索引，那每次查询一次数据项，都需要一次I/O，几百万次，可怕。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:3:2","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"不同引擎的索引实现原理 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:4:0","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"MyISAM索引实现 MyISAM的索引采用B+树实现，MyISAM的索引和数据时分开的，叶子节点data存取的是数据的地址。如下主键索引的示例图： 由图可以看出，要根据索引找到数据，先根据索引找到叶子节点，再根据叶子节点找到数据的地址，然后再根据数据地址取出数据。 MyIASM的辅助索引的实现与主键索引没有区别，如下图： ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:4:1","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"Innodb索引实现 InnoDB，在实际项目接触是非常多的，索引的实现也是使用B+树，但是实现原理跟MyISAM不同。 第一个区别是InnoDB的数据文件本身就是索引文件。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。如下图： 这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 第二个区别就是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。如下图所示 InnoDB辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录，从而能够明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。 不建议用非单调的字段作为InnoDB的主键，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时，数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，所以一般使用自增字段作为主键。 ","date":"2021-02-03","objectID":"/mysql%E7%B4%A2%E5%BC%95/:4:2","tags":["Mysql"],"title":"Mysql索引","uri":"/mysql%E7%B4%A2%E5%BC%95/"},{"categories":["数据库"],"content":"Mysql事务详解","date":"2021-02-03","objectID":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/","tags":["Mysql"],"title":"Mysql事务详解","uri":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/"},{"categories":["数据库"],"content":"Mysql 事务说明 ","date":"2021-02-03","objectID":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/:1:0","tags":["Mysql"],"title":"Mysql事务详解","uri":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/"},{"categories":["数据库"],"content":"Mysql 事务特点 1、ACID Atomicity（原子性）：一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作。 Consistency（一致性）：数据库总是从一个一致性状态转换到另一个一致状态。下面的银行列子会说到。 Isolation（隔离性）：通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。注意这里的“通常来说”，后面的事务隔离级级别会说到。 Durability（持久性）：一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。（持久性的安全性与刷新日志级别也存在一定关系，不同的级别对应不同的数据安全级别。） 示例如下，银行转账为例 START TRANSACTION; SELECT balance FROM checking WHERE customer_id = 10233276; UPDATE checking SET balance = balance - 200.00 WHERE customer_id = 10233276; UPDATE savings SET balance = balance + 200.00 WHERE customer_id = 10233276; COMMIT; 原子性：要么完全提交（10233276的checking余额减少200，savings 的余额增加200），要么完全回滚（两个表的余额都不发生变化） 一致性：这个例子的一致性体现在 200元不会因为数据库系统运行到第3行之后，第4行之前时崩溃而不翼而飞，因为事务还没有提交。 隔离性：允许在一个事务中的操作语句会与其他事务的语句隔离开，比如事务A运行到第3行之后，第4行之前，此时事务B去查询checking余额时，它仍然能够看到在事务A中被减去的200元（账户钱不变），因为事务A和B是彼此隔离的。在事务A提交之前，事务B观察不到数据的改变。 持久性：这个很好理解。 事务的隔离性是通过锁、MVCC等实现 （MySQL锁总结） 事务的原子性、一致性和持久性则是通过事务日志实现 ","date":"2021-02-03","objectID":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/:1:1","tags":["Mysql"],"title":"Mysql事务详解","uri":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/"},{"categories":["数据库"],"content":"事务隔离级别 并发带来的问题 更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题 －－最后的更新覆盖了由其他事务所做的更新。例如，两个编辑人员制作了同一 文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。 最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同 一文件，则可避免此问题。 脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务完成并提交前， 这条记录的数据就处于不一致状态； 这时， 另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做\"脏读\"。 不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读” 。 幻读 （Phantom Reads）： 一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读” 。 幻读和不可重复读的区别 不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改） 幻读的重点在于新增或者删除：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除） 并发事务带来的问题解决办法 “更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。 “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决： 一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。 另一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 MVCC 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本 SQL标准定义了4类隔离级别，每一种级别都规定了一个事务中所做的修改，哪些在事务内和事务间是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。 第1级别：Read Uncommitted(读取未提交内容) 所有事务都可以看到其他未提交事务的执行结果 本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少 该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据 -- 创建表 SET @@session.transaction_isolation = 'READ-UNCOMMITTED'; create database test; use test; create table test(id int primary key); insert into test(id) values(1); -- 开启一个终端，开启事务，更新ID为1的记录更新为2 begin; update test set id = 2 where id = 1; select * from test; -- 此时看到一条ID为2的记录 -- 开启另一个终端，开启事务，查看表中的数据 use test; begin; select * from test; -- 此时看到一条 ID 为 2 的记录 最后一步读取到了 mysql 终端 1 中未提交的事务（没有 commit 提交动作），即产生了 脏读 ，大部分业务场景都不允许脏读出现，但是此隔离级别下数据库的并发是最好的。 READ-UNCOMMITTED 中文叫未提交读，即一个事务读到了另一个未提交事务修改过的数据，整个过程如下图: 如上图，SessionA和SessionB分别开启一个事务，SessionB中的事务先将id为1的记录的name列更新为’lisi'，然后Session 中的事务再去查询这条id为1的记录，那么在未提交读的隔离级别下，查询结果由’zhangsan’变成了’lisi'，也就是说某个事务读到了另一个未提交事务修改过的记录。但是如果SessionB中的事务稍后进行了回滚，那么SessionA中的事务相当于读到了一个不存在的数据，这种现象也称为脏读。 可见READ-UNCOMMITTED是非常不安全。 第2级别：Read Committed(读取提交内容) 这是大多数数据库系统的默认隔离级别（但不是MySQL默认的） 它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变 这种隔离级别出现的问题是——不可重复读(Nonrepeatable Read)：不可重复读意味着我们在同一个事务中执行完全相同的select语句时可能看到不一样的结果。导致这种情况的原因可能有： 有一个交叉的事务有新的commit，导致了数据的改变; 一个数据库被多个实例操作时,同一事务的其他实例在该实例处理其间可能会有新的commit -- 创建表 SET @@session.transaction_isolation = 'READ-COMMITTED'; create database test; use test; create table test(id int primary key); insert into test(id) values(1); -- 开启一个终端，开启事务，更新ID为1的记录更新为2，并确认记录数变更过来 begin; update test set id = 2 where id = 1; select * from test; -- 此时看到一条记录为 2 -- 开启另一个终端，开启事务，查看表中的数据 use test; begin; select * from test; -- 此时看一条 ID 为 1 的记录 -- 登录到第一个终端，提交事务 commit; -- 切换到第二个终端 select * from test; -- 此时看到一条 ID 为 2 的记录 mysql 终端 2 在开启了一个事务之后，在第一次读取 test 表（此时 mysql 终端 1 的事务还未提交）时 ID 为 1 ，在第二次读取 test 表（此时 mysql 终端 1 的事务已经提交）时 ID 已经变为 2 ，说明在此隔离级别下已经读取到已提交的事务。 READ COMMITTED 中文叫已提交读，或者叫不可重复读。即一个事务能读到另一个已经提交事务修改后的数据，如果其他事务均对该数据进行修改并提交，该事务也能查询到最新值. 在第4步 SessionB 修改后，如果未提交，SessionA是读不到，但SessionB一旦提交后，SessionA即可读到SessionB修改的内容。 从某种程度上已提交读是违反事务的隔离性的 第3级别：Repeatable Read(可重读) 这是MySQL的默认事务隔离级别 它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行 此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行 InnoDB和Falcon存储引擎通过多版本并发控制(MVCC，Multiversion Concurrency Control)机制解决幻读问题；InnoDB还通过间隙锁解决幻读问题 REPEATABLE READ 中文叫可重复读，即事务能读到另一个已经提交的事务修改过的数据，但是第一次读过某条记录后，即使后面其他事务修改了该记录的值并且提交，该事务之后再读该条记录时，读到的仍是第一次读到的值，而不是每次都读到不同的数据. InnoDB默认是这种隔离级别，SessionB无论怎么修改id=1的值，SessionA读到依然是自己开启事务第一次读到的内容。 SERIALIZABLE 串行化 SERIALIZABLE 叫串行化， 上面三种隔离级别可以进行 读-读 或者 读-写、写-读三种并发操作，而SERIALIZABLE不允许读-写，写-读的并发操作。 SessionB 对 id=1 进行修改的时候，SessionA 读取id=1则需要等待 SessionB 提交事务。可以理解SessionB在更新的时候加了X锁。 ","date":"2021-02-03","objectID":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/:1:2","tags":["Mysql"],"title":"Mysql事务详解","uri":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/"},{"categories":["数据库"],"content":"分布式事务 分布式事务指允许多个独立的事务资源参与到一个全局的事务中。全局事务要求在其中的所有参与的事务要么都提交，要么都回滚。 InnoDB 分布式事务 InnoDB 是支持分布式事务，由一个或多个资源管理器（Resource Managers），一个事务管理器(Transaction Manager)，以及一个应用程序(Application Program)组成。 资源管理器（Resource Managers），提供访问事务资源的方法，一般一个数据库就是一个资源管理器。 事务管理器(Transaction Manager)，协调参与全局事务中的各个事务，需要和参与全局事务的所有资源管理器进行通信。 应用程序(Application Program) 定义事务的边界，指定全局事务中的操作。 如下图: 应用程序向一个或多个数据库执行事务操作，事务管理器进行管理事务，通过二段式提交，第一阶段所有参与的全局事务的节点都开始准备，告诉事务管理器都准备好了，可以提交了。第二阶段，事务管理器告诉每一个资源管理器是执行Commit 还是 Rollback。如果任何一个节点显示不能提交，则所有的节点被告知需要回滚 TCC分布式事务 InnoDB的分布式是数据库实现的，看看数据库外如何分布式事务，比较常见的是TCC分布式事务。 上图描述了TCC分布式事务的流程，假设电商业务中，支付后需要修改库存，积分，物流仓储的数据，如果一个失败则全部回滚。 TCC分布式事务，有三个阶段，Try，Confirm, Cancel。也就是说每个参与事务的服务都需要实现这三个接口，库存、积分、仓储都需要实现这三个接口。 第一阶段，Try，业务应用调取各个服务的Try接口，告诉他们给我预留一个商品，有人要购买，可以理解为冻结，每一步都不执行成功，只是标记更新状态。 第二阶段，Confirm，确认阶段，即事务协调器调取每个服务Confirm执行事务操作，如果某一个服务的Confirm失败，则有第三个阶段。如果成功则结束事务。 第三个阶段，Cancel，如果在第二个阶段有一个事务提交失败，则事务协调器调取所有业务的Cancel接口，回滚事务，将第一阶段冻结的商品恢复。 ","date":"2021-02-03","objectID":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/:1:3","tags":["Mysql"],"title":"Mysql事务详解","uri":"/mysql%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3/"},{"categories":["数据库"],"content":"Mysql执行过程","date":"2021-02-02","objectID":"/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/","tags":["Mysql"],"title":"Mysql二进制安装","uri":"/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"categories":["数据库"],"content":"mysql linux环境下安装 一、创建mysql账户和数据目录 # 创建用户 groupadd mysql useradd -r -g mysql -s /bin/false mysql # 创建数据目录 mkdir -p /data/mysql3306/{mysql,binlog,slowlog,tmp,log,run} mkdir -p /usr/local/mysql chown -R mysql. /data/mysql3306 chown -R mysql. /usr/local/mysql 二、mysql二进制下载 dir=`pwd` cd $dir yum install -y wget \u0026\u0026 wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz tar zxf mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz -C /usr/local/src cp -r /usr/local/src/mysql-5.7.26-linux-glibc2.12-x86_64/* /usr/local/mysql 三、初始化mysql # 配置环境变量 echo \"export PATH=$PATH:/usr/local/mysql/bin\" \u003e\u003e /etc/profile source /etc/profile # 初始化 mysqld --defaults-file=/data/mysql3306/config/my.cnf --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql3306/mysql # 配置ssl mysql_ssl_rsa_setup --basedir=/usr/local/mysql --datadir=/data/mysql3306/mysql # 手动启动 mysqld_safe --defaults-file=/data/mysql3307/config/my.cnf \u0026 四、mysql自启动 cp mysqld.service /usr/lib/systemd/system/mysqld.service systemctl enable mysqld systemctl start mysqld 五、登录修改密码 more error.log | grep password mysql -uroot -p ALTER USER 'root'@'localhost' IDENTIFIED BY 'Paswword1!'; flush privileges 六、mysql多实例 # 初始化 mysqld --defaults-file=/data/mysql3307/config/my.cnf --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql3307/mysql mysql_ssl_rsa_setup --basedir=/usr/local/mysql --datadir=/data/mysql3307/mysql mysqld --defaults-file=/data/mysql3307/config/my.cnf --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql3307/mysql mysql_ssl_rsa_setup --basedir=/usr/local/mysql --datadir=/data/mysql3307/mysql # 启动 cp mysqld.service /usr/lib/systemd/system/mysqld3306.service cp mysqld.service /usr/lib/systemd/system/mysqld3307.service # 修改mysqld.service启动文件 Type=forking 改为 Type=sample ExecStart启动命令改为/usr/local/bin/mysqld --defaults-file=/data/mysql3306/config/my.cnf # 启动mysql systemctl enable mysqld3306 systemctl start mysqld3306 ","date":"2021-02-02","objectID":"/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/:0:1","tags":["Mysql"],"title":"Mysql二进制安装","uri":"/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"categories":["数据库"],"content":"mysql win下安装 1、下载 mysql5.7 版本 https://dev.mysql.com/downloads/mysql/ 2、创建my.ini文件 [mysql] # 设置mysql客户端默认字符集 default-character-set=utf8 [mysqld] #设置3306端口 port = 3306 # 设置mysql的安装目录 basedir=E:\\downland\\mysql-5.7.26-winx64 # 设置mysql数据库的数据的存放目录 datadir=E:\\downland\\mysql-5.7.26-winx64/data # 允许最大连接数 max_connections=200 # 服务端使用的字符集默认为8比特编码的latin1字符集 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB 3、进入mysql bin目录下 mysqld --install mysqld --initialize-insecure net start mysql sc query mysql ","date":"2021-02-02","objectID":"/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/:0:2","tags":["Mysql"],"title":"Mysql二进制安装","uri":"/mysql%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85/"},{"categories":["数据库"],"content":"Mysql执行过程","date":"2021-02-02","objectID":"/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/","tags":["Mysql"],"title":"Mysql执行过程","uri":"/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/"},{"categories":["数据库"],"content":"Mysql 执行流程 大致流程描述: MySQL客户端通过协议将SQL语句发送给MySQL服务器。 服务器会先检查查询缓存中是否有执行过这条SQL，如果命中缓存，则将结果返回，否则进入下一个环节（查询缓存默认不开启）。 服务器端进行SQL解析，预处理，然后由查询优化器生成对应的执行计划。 服务器根据查询优化器给出的执行计划，再调用存储引擎的API执行查询。 将结果返回给客户端，如果开启查询缓存，则会备份一份到查询缓存中。 ","date":"2021-02-02","objectID":"/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/:0:1","tags":["Mysql"],"title":"Mysql执行过程","uri":"/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/"},{"categories":["数据库"],"content":"流程图详解 查询缓存 MySQL查询缓存会保存查询返回的完整结构。当查询命中该缓存时，MySQL会立刻返回结果，跳过了解析、优化和执行阶段。 但查询缓存是默认不开启的，且要求SQL和参数都是一样，同时查询缓存系统会跟踪查询中涉及的每一个表，如果这些表发生变化，则该表相关的所有缓存数据均会失效。所以命中率一般较低，生产环境中也很少用到，具体流程就不描述了。如果感兴趣的可以查阅详细资料。 解析和预处理 如果查询缓存未命中，则到解析器。解析器主要是对SQL语句进行解析，使用MySQLy语法规则进行验证和解析查询，并生成对应的解析树。 得到解析数之后，还需要做预处理，预处理则进一步检查解释树是否合法，以及进行一些优化，比如检查数据表和列是否存在，如果有计算，会将计算的结果算出来等等。 查询优化器 查询优化器是整个流程中重要的一环。查询优化器会将预处理之后的解析树转化成执行计划。一条查询可以有多种执行方法，最后均会返回相同结果。查询优化器的作用就是找到这其中最好的执行计划。 生成执行计划的过程会消耗较多的时间，特别是存在许多可选的执行计划时。如果在一条SQL语句执行的过程中将该语句对应的最终执行计划进行缓存，当相似的语句再次被输入服务器时，就可以直接使用已缓存的执行计划，从而跳过SQL语句生成执行计划的整个过程，进而可以提高语句的执行速度。 通常所讲的优化SQL，其实就是想让查询优化器，按照我们的思路,帮我们选择最优的执行方案。 查询执行计划 查询执行计划，就是MySQL查询中的执行计划，比如是执行where语句还是from语句，下面有一张执行顺序的图。 最先执行的总是FROM操作，最后执行的是LIMIT操作。其中每一个操作都会产生一张虚拟的表，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是只有最后一个虚拟的表才会被作为结果返回。如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。 FORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1 ON: 对虚表VT1进行ON筛选，只有那些符合的行才会被记录在虚表VT2中。 JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3， 如果 from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。 WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合的记录才会被插入到虚拟表VT4中。 GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5. CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6. HAVING： 对虚拟表VT6应用having过滤，只有符合的记录才会被 插入到虚拟表VT7中。 SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。 DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9. ORDER BY: 将虚拟表VT9中的记录按照\u003corder_by_list\u003e进行排序操作，产生虚拟表VT10. LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。 查询执行引擎 执行计划会传给查询执行引擎，执行引擎选择存储引擎来执行计划，到磁盘中的文件中去查询。 影响这个查询性能最根本的原因是什么? 其实是硬盘的机械运动，也就是我们平时熟悉的IO，所以一条查询语句是快还是慢，就是根据这个时间的IO来确定的。那怎么执行IO又是什么来确定的?就是传过来的这一份执行计划. ","date":"2021-02-02","objectID":"/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/:0:2","tags":["Mysql"],"title":"Mysql执行过程","uri":"/mysql%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/"}]